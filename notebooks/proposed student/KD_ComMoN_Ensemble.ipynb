{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quuo74jan6hb",
   "metadata": {
    "id": "quuo74jan6hb"
   },
   "outputs": [],
   "source": [
    "#Set path to MAIN FOLDER OF EXPERIMENT\n",
    "#cd /path/to/EXPERIMENT_FOLDER/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af33abcf",
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "af33abcf",
    "outputId": "3cd6cd5f-f178-4c5d-dd11-429d9f121984"
   },
   "outputs": [],
   "source": [
    "#LOAD DEPENDENCIES\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import talos\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#IMPORT LOSS, OPTIMIZER, CALLBACK AND LAYERS\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, KLDivergence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D\n",
    "\n",
    "#IMPORT MODEL APIs\n",
    "from tensorflow.keras.models import Model, load_model, save_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 as selected_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as student_preprocess\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as teacher_preprocess\n",
    "\n",
    "#PREVENT ERROR UNCESSARY MESSAGES\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "print(\"LIBRARIES LOADED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QilrCeOhDZey",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QilrCeOhDZey",
    "outputId": "1b4e67cc-63b8-4e05-dbd2-dd904f57b225"
   },
   "outputs": [],
   "source": [
    "#Tweakable parameters\n",
    "MODEL_KIND = \"KD_model_ENSEMBLE\"\n",
    "MODEL_NAME = \"MiniMobileNetV2\"\n",
    "\n",
    "#Models paths\n",
    "PROPOSED_MODEL_PATH = \"models/proposed_model/\" + MODEL_NAME\n",
    "HPO_PATH = \"models/hpo_model/\" + MODEL_NAME\n",
    "\n",
    "#Figures paths\n",
    "FIG_PATH = 'figures/' + MODEL_KIND + \"/\" + MODEL_NAME\n",
    "\n",
    "#Data paths\n",
    "MAIN_DATA_DIR = \"ds/\"\n",
    "TRAIN_DATA_DIR = MAIN_DATA_DIR + \"train/\"\n",
    "TEST_DATA_DIR = MAIN_DATA_DIR + \"test/\"\n",
    "VALIDATION_DATA_DIR = MAIN_DATA_DIR + \"val/\"\n",
    "\n",
    "print(\"ALL REQUERED PATHS SET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RQq1u6rdBNdE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQq1u6rdBNdE",
    "outputId": "4658db3e-9904-45e3-fd00-5d8e86a19541"
   },
   "outputs": [],
   "source": [
    "#Save Model Function\n",
    "def save_m(model, directory, model_name):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    model.save(directory + \"/\" + model_name + \".h5\")\n",
    "\n",
    "#Save History Function\n",
    "def save_h(history, directory, history_name):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    with open(directory + '/' + history_name + '.history', 'wb') as file:\n",
    "        pickle.dump(history, file)\n",
    "\n",
    "#Load model Function\n",
    "def load_m(directory, model_name):\n",
    "    if not os.path.exists(directory):\n",
    "        print(\"Model File Does Not Exist!!\")\n",
    "        return \n",
    "    model = load_model(directory + \"/\" + model_name + \".h5\")\n",
    "    return model\n",
    "\n",
    "#Load History Function\n",
    "def load_h(directory, history_name):\n",
    "    if not os.path.exists(directory):\n",
    "        print(\"History File Does Not Exist!!\")\n",
    "        return \n",
    "    with open(directory + '/' + history_name + '.history', 'rb') as file:\n",
    "        his = pickle.load(file)\n",
    "    return his\n",
    "\n",
    "def save_fig(directory, fig_name):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    plt.savefig(directory + '/' + fig_name + '.tiff', bbox_inches='tight', dpi=600, format='tiff')\n",
    "    \n",
    "print(\"ALL CUSTOM FUNCTIONS DEFIEND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zYGVjb3gB3oY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYGVjb3gB3oY",
    "outputId": "1026741c-8049-49cb-9a92-cebf285853cf"
   },
   "outputs": [],
   "source": [
    "#DATA GENERATORS\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "img_rows, img_cols = 224, 224\n",
    "INPUT_SHAPE = (img_rows, img_cols,3)\n",
    "MODEL_INPUT = Input(shape=INPUT_SHAPE)\n",
    "print(\"INPUT SIZE -->\", MODEL_INPUT.shape, \"\\n\")\n",
    "NUM_CLASSES = 199\n",
    "\n",
    "def create_data_generator(pre_process=None):\n",
    "    nb_train_samples = 0\n",
    "    nb_val_samples = 0\n",
    "    num_classes = 0\n",
    "    train_generator = None\n",
    "    validation_generator = None\n",
    "\n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=pre_process)\n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=pre_process)\n",
    "\n",
    "    if not os.path.exists(TRAIN_DATA_DIR):\n",
    "        print(\"TRAIN DATA DOES NOT EXITS!\")\n",
    "        return None, None\n",
    "    else:\n",
    "        print(\"LOAD TRAIN SAMPLES...\")\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "                TRAIN_DATA_DIR,\n",
    "                target_size=(img_rows,img_cols),\n",
    "                batch_size=BATCH_SIZE,\n",
    "                class_mode='categorical',\n",
    "                seed=42)\n",
    "        \n",
    "        #CHECK  THE NUMBER OF SAMPLES\n",
    "        nb_train_samples = len(train_generator.filenames)\n",
    "        if nb_train_samples == 0:\n",
    "            print(\"NO DATA TRAIN FOUND IN TRAIN FOLDER!\")\n",
    "            return None, None\n",
    "\n",
    "    print()\n",
    "    if not os.path.exists(TRAIN_DATA_DIR):\n",
    "        print(\"VALIDATION DATA DOES NOT EXITS!\")\n",
    "        return None, None\n",
    "    else:\n",
    "        print(\"LOAD VALIDATION SAMPLES...\")\n",
    "        validation_generator = val_datagen.flow_from_directory(\n",
    "                VALIDATION_DATA_DIR,\n",
    "                target_size=(img_rows,img_cols),\n",
    "                batch_size=BATCH_SIZE,\n",
    "                class_mode='categorical',\n",
    "                seed=42,\n",
    "                shuffle=False)\n",
    "\n",
    "        #CHECK  THE NUMBER OF SAMPLES\n",
    "        nb_validation_samples = len(validation_generator.filenames)\n",
    "        if nb_validation_samples == 0:\n",
    "            print(\"NO DATA VALIDATION FOUND IN VALIDATION FOLDER!\")\n",
    "            return None, None\n",
    "\n",
    "    print()\n",
    "    if nb_train_samples > 0 and nb_validation_samples > 0:\n",
    "        num_classes= len(train_generator.class_indices)\n",
    "        print(\"GENERATER ARE SET!\")\n",
    "        print('CLASSES TO TRAIN', num_classes, 'classes')\n",
    "    \n",
    "    return (train_generator, nb_train_samples), (validation_generator, nb_validation_samples)\n",
    "\n",
    "_, _=create_data_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec35ada5",
   "metadata": {
    "id": "ec35ada5"
   },
   "outputs": [],
   "source": [
    "#Knowledge Distiller(KD)\n",
    "\n",
    "class KDistiller(Model):\n",
    "    def __init__(self, student, teacher, student_preprocess=None, teacher_preprocess=None):\n",
    "        super(KDistiller, self).__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "        self.student_preprocess = student_preprocess\n",
    "        self.teacher_preprocess = teacher_preprocess\n",
    "\n",
    "    def compile(self, optimizer,  metrics, student_loss_fn, distillation_loss_fn, alpha, temperature):\n",
    "        super(KDistiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # UNPACK DATA\n",
    "        student_x, y = data\n",
    "        teacher_x, y = data\n",
    "\n",
    "        # PREPROCESS DATA\n",
    "        if self.student_preprocess != None: student_x = self.student_preprocess(student_x)\n",
    "        if self.teacher_preprocess != None: teacher_x = self.teacher_preprocess(teacher_x)\n",
    "        \n",
    "        # FORWARD PASS OF TEACHER\n",
    "        teacher_preds = self.teacher(teacher_x, training=False)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # FORWARD PASS OF STUDENT\n",
    "            student_preds = self.student(student_x, training=True)\n",
    "\n",
    "            # CALCULATE STUDENT LOSS\n",
    "            student_loss = self.student_loss_fn(y, student_preds)\n",
    "\n",
    "            # CALCULATE DISTISLATION LOSS\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                tf.nn.softmax(teacher_preds / self.temperature, axis=1),\n",
    "                tf.nn.softmax(student_preds / self.temperature, axis=1),\n",
    "            )\n",
    "\n",
    "            # CALCULATE TOTAL LOSS\n",
    "            total_loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
    "\n",
    "        # CALCULATE GRADIENT\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(total_loss, trainable_vars)\n",
    "\n",
    "        # SET WEIGHTS\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # SET METRICES\n",
    "        self.compiled_metrics.update_state(y, student_preds)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss, 'loss':total_loss}\n",
    "        )\n",
    "\n",
    "        return results\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # UNPACK DATA\n",
    "        x, y = data\n",
    "\n",
    "        # PREPROCESS DATA\n",
    "        x = self.student_preprocess(x)\n",
    "        \n",
    "        # GET PREDICTIONS FROM STUDENT\n",
    "        y_preds = self.student(x, training=False)\n",
    "\n",
    "        # CALCULATE STUDENT LOSS\n",
    "        student_loss = self.student_loss_fn(y, y_preds)\n",
    "\n",
    "        # SET METRICES \n",
    "        self.compiled_metrics.update_state(y, y_preds)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss})\n",
    "\n",
    "        return results\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        return self.student(inputs, training=training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kqrx0G7_7yNK",
   "metadata": {
    "id": "Kqrx0G7_7yNK"
   },
   "source": [
    "**Teacher Model :** EnsembleModel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JBlFLvKqauvU",
   "metadata": {
    "id": "JBlFLvKqauvU"
   },
   "outputs": [],
   "source": [
    "TEACHER_NAME = \"EnsembleModel\"\n",
    "TEACHER_MODEL_PATH = \"models/teacher_model/\" + TEACHER_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f340450",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f340450",
    "outputId": "64f8dd81-57b0-436f-8d56-02dceacc512f"
   },
   "outputs": [],
   "source": [
    "#PLOT THE MODEL STRUCTURE\n",
    "def get_teacher():\n",
    "    model = load_m(TEACHER_MODEL_PATH, TEACHER_NAME)\n",
    "    model.layers[-1].activation = None\n",
    "    if model != None:\n",
    "        print(\"TEACHER MODEL LOADED SUCCESSFULLY!\")\n",
    "\n",
    "    return model\n",
    "\n",
    "if get_teacher() != None: \n",
    "    print(\"PLEASE CHECK THE ENTIRE MODEL UP TO THE END\")\n",
    "    get_teacher().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f9ad21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38f9ad21",
    "outputId": "a31c3176-d2ba-45da-f3f3-6cf26cf30092"
   },
   "outputs": [],
   "source": [
    "#Sanity Checker\n",
    "#Re-Create Data Generator\n",
    "_, (validation_generator, nb_validation_samples)  = create_data_generator(pre_process=teacher_preprocess)\n",
    "\n",
    "get_teacher().evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oLZIunKTxUOw",
   "metadata": {
    "id": "oLZIunKTxUOw"
   },
   "source": [
    "**Student Model :** Mini-MNV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ipq4UZWrypfR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ipq4UZWrypfR",
    "outputId": "71da1475-c7d4-435c-8732-7a7ce1bd5ba6"
   },
   "outputs": [],
   "source": [
    "#TRANSFER LEARNING\n",
    "def get_student(model_input):\n",
    "    model = load_m(PROPOSED_MODEL_PATH, MODEL_NAME)\n",
    "    model.layers[-1].activation = None\n",
    "    if model != None:\n",
    "        print(\"STUDENT MODEL SUCESSFULLY BUILT!\")\n",
    "    return model\n",
    "\n",
    "#PLOT THE MODEL STRUCTURE\n",
    "print(\"PLEASE CHECK THE ENTIRE MODEL UP TO THE END\")\n",
    "get_student(MODEL_INPUT).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OKEhdQ64EltV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OKEhdQ64EltV",
    "outputId": "d2d3cd0c-a7b0-4088-aaac-b5f136854b03"
   },
   "outputs": [],
   "source": [
    "#FIXED HYPERPARAMETERS\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 30\n",
    "DROPOUT_RATE = 0.5\n",
    "OPTIMIZER = Adam\n",
    "\n",
    "#HPO HYPERPAMETERS\n",
    "TEMPERATURE = [5, 2, 10] \n",
    "ALPHA = [0.1, 0.3, 0.5]\n",
    "LEARNING_RATE = [0.001, 0.01, 0.0001]\n",
    "\n",
    "print(\"FIXED HYPERPARAMETERS\")\n",
    "print(\"---------------------\")\n",
    "\n",
    "print(\"BATCH_SIZE -->\", BATCH_SIZE)\n",
    "print(\"EPOCHS SET -->\", EPOCHS)\n",
    "print(\"DROPOUT_RATE -->\", DROPOUT_RATE)\n",
    "print(\"OPTIMIZER -->\", OPTIMIZER.__name__,\"\\n\")\n",
    "\n",
    "print(\"HPO HYPERPARAMETERS\")\n",
    "print(\"--------------------\")\n",
    "print(\"TEMPERATURE -->\", TEMPERATURE)\n",
    "print(\"ALPHA -->\", ALPHA)\n",
    "print(\"LEARNING_RATE -->\", LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Uz_O6RSX779P",
   "metadata": {
    "id": "Uz_O6RSX779P"
   },
   "source": [
    "**Training Student With KD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s9s8AG_Gt0aD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s9s8AG_Gt0aD",
    "outputId": "d7817308-f15a-4e35-af82-6ec111513971"
   },
   "outputs": [],
   "source": [
    "dummy_x = []\n",
    "dummy_y = []\n",
    "\n",
    "# HPO PARAMETERS\n",
    "p = {\n",
    "    'temperature':TEMPERATURE,\n",
    "    'alpha':ALPHA,\n",
    "    'lr':LEARNING_RATE\n",
    "    }\n",
    "\n",
    "def distiller_model(x_train, y_train, x_val, y_val, params):\n",
    "    print(\"\\nCURRENT PARAMETERS:\", params)\n",
    "\n",
    "    #START TIMER\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #GET NEW TEACHER AND STUDENT MODEL\n",
    "    teacher = get_teacher()\n",
    "    student = get_student(MODEL_INPUT)\n",
    "\n",
    "    #SET CALLBACK\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                              factor=0.5, \n",
    "                              patience=2,\n",
    "                              verbose=1, \n",
    "                              mode='max', \n",
    "                              min_lr=0.000001)\n",
    "\n",
    "    callbacks = [reduce_lr]\n",
    "\n",
    "    #CREATE KNOWLEDGE DISTILLER\n",
    "    distiller = KDistiller(\n",
    "        student=student,teacher=teacher,\n",
    "        student_preprocess=student_preprocess,\n",
    "        teacher_preprocess=teacher_preprocess\n",
    "    )\n",
    "\n",
    "    #COMPILE KNOWLEDGE DISTILLER\n",
    "    distiller.compile(\n",
    "        optimizer = OPTIMIZER(learning_rate=params['lr']),\n",
    "        metrics=['accuracy'],\n",
    "        student_loss_fn=CategoricalCrossentropy(from_logits=True),\n",
    "        distillation_loss_fn= KLDivergence(),\n",
    "        alpha=params['alpha'],\n",
    "        temperature=params['temperature'],\n",
    "    )\n",
    "\n",
    "    print()\n",
    "    (train_generator, nb_train_samples), (validation_generator, nb_validation_samples) = create_data_generator()\n",
    "\n",
    "    #DISTILLING\n",
    "    distiller_history = distiller.fit(train_generator,\n",
    "                                        validation_data = validation_generator,\n",
    "                                        steps_per_epoch = nb_train_samples // BATCH_SIZE,\n",
    "                                        validation_steps = nb_validation_samples // BATCH_SIZE,\n",
    "                                        epochs=EPOCHS,\n",
    "                                        callbacks=callbacks, \n",
    "                                      )\n",
    "    #STOP TIMER\n",
    "    elapsed_time = time.time() - start_time\n",
    "    train_time = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n",
    "    print('\\n\\n' + train_time, 'train_time\\n')\n",
    "    print(elapsed_time, 'Seconds\\n\\n')\n",
    "\n",
    "    print(\"MODEL SERIALIZING WAIT FOR A MOMENT...\\n\")\n",
    "    save_m(distiller.student, HPO_PATH + '/HPO(t={0},a={1},l={2})'.format(params['temperature'],params['alpha'],params['lr']), MODEL_NAME)\n",
    "    save_h(distiller_history.history, HPO_PATH + '/HPO(t={0},a={1},l={2})'.format(params['temperature'],params['alpha'],params['lr']), MODEL_NAME)\n",
    "\n",
    "    return distiller_history, distiller.student\n",
    "\n",
    "scan_object = talos.Scan(dummy_x, dummy_y,\n",
    "                         x_val=dummy_x, y_val=dummy_y, \n",
    "                         model=distiller_model,\n",
    "                         experiment_name='logs/',\n",
    "                         params=p,\n",
    "                         print_params=False,\n",
    "                         save_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qZp-sCjlEuYK",
   "metadata": {
    "id": "qZp-sCjlEuYK"
   },
   "source": [
    "**Select Best Student**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "A5yU3-F0DauE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5yU3-F0DauE",
    "outputId": "d88e81ca-3c88-487c-ffa6-b4676edb00f5"
   },
   "outputs": [],
   "source": [
    "#Re-Create Data Generator\n",
    "_, (validation_generator, nb_validation_samples)  = create_data_generator(pre_process=student_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UHjmbQQaA3Q2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHjmbQQaA3Q2",
    "outputId": "5fde7e24-e783-4e87-bbd5-906b9a0c0859"
   },
   "outputs": [],
   "source": [
    "#Select the model with highest validation accuracy\n",
    "def ChooseBest():\n",
    "    best_model = 0\n",
    "    best_temp = 0\n",
    "    best_alpha = 0\n",
    "    best_lr = 0\n",
    "    max_val_acc = 0\n",
    "\n",
    "    for a in ALPHA:\n",
    "        for t in TEMPERATURE:\n",
    "          for l in LEARNING_RATE:\n",
    "              print(\"\\nFor Temperature = {0} & alpha= {1} & lr={2}\".format(t,a,l))\n",
    "              #load trained model with temp t and alpha a\n",
    "              model_path = HPO_PATH + '/HPO(t={0},a={1},l={2})'.format(t,a,l)\n",
    "              student_model = load_m(model_path, MODEL_NAME)\n",
    "              student_model.compile(metrics=['accuracy'], loss=CategoricalCrossentropy(from_logits=True))\n",
    "              #validate model\n",
    "              val_acc = student_model.evaluate(validation_generator)[1]\n",
    "\n",
    "              #update best parameters\n",
    "              if val_acc > max_val_acc:\n",
    "                  max_val_acc = val_acc\n",
    "                  best_model = student_model\n",
    "                  best_alpha = a\n",
    "                  best_temp = t\n",
    "                  best_lr = l\n",
    "                \n",
    "    return best_alpha, best_temp, best_lr, best_model\n",
    "\n",
    "best_alpha, best_temp, best_lr, best_model = ChooseBest()\n",
    "\n",
    "print('\\nBest Temperature:', best_temp)\n",
    "print('Best Alpha:', best_alpha)\n",
    "print('Best Learning Rate:', best_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iifTjvy9SjhZ",
   "metadata": {
    "id": "iifTjvy9SjhZ"
   },
   "source": [
    "**Evaluating best student model on Validation and Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XJE1qQMzDrMu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XJE1qQMzDrMu",
    "outputId": "18b53dad-3d4c-45a2-c1d5-22794fb6f0da"
   },
   "outputs": [],
   "source": [
    "#LOAD TEST DATA\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=student_preprocess)\n",
    "\n",
    "if not os.path.exists(TEST_DATA_DIR):\n",
    "    print(\"TEST DATA DOES NOT EXITS!\")\n",
    "else:\n",
    "    print(\"LOAD TEST SAMPLES...\")\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "                TEST_DATA_DIR,\n",
    "                target_size=(img_rows,img_cols),\n",
    "                batch_size=BATCH_SIZE,\n",
    "                class_mode='categorical',\n",
    "                seed=42,\n",
    "                shuffle=False)\n",
    "\n",
    "    #CHECK  THE NUMBER OF SAMPLES\n",
    "    nb_test_samples = len(test_generator.filenames)\n",
    "    if nb_test_samples == 0:\n",
    "        print(\"NO DATA TEST FOUND IN TEST FOLDER!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7boQFDTBZUed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7boQFDTBZUed",
    "outputId": "dd8da43a-4712-4f8a-8b70-3b7a61aa7196"
   },
   "outputs": [],
   "source": [
    "#Evaluate Best Student model against Teacher model on test set\n",
    "print(\"Evaluating Best Student on validation dataset\")\n",
    "best_model.evaluate(validation_generator)\n",
    "\n",
    "print(\"\\nEvaluating Best Student on test dataset\")\n",
    "best_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EIx2PO6s9fcg",
   "metadata": {
    "id": "EIx2PO6s9fcg"
   },
   "source": [
    "**Saving Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vZMCJpbMj-Td",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vZMCJpbMj-Td",
    "outputId": "a8ffcf3e-4358-4925-866f-09cf121af46a"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "des = PROPOSED_MODEL_PATH + '-KD'\n",
    "\n",
    "#save models\n",
    "shutil.copytree(HPO_PATH + '/HPO(t={0},a={1},l={2})'.format(best_temp,best_alpha,best_lr), des)\n",
    "\n",
    "print(\"[INFO] BEST STUDENT MODEL AND HISTORY SAVED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AVOoUtenVOJv",
   "metadata": {
    "id": "AVOoUtenVOJv"
   },
   "outputs": [],
   "source": [
    "#Figure\n",
    "dpi = 1000\n",
    "plt.rcParams.update({'figure.dpi': dpi})\n",
    "figsize = (12, 12)\n",
    "\n",
    "history = load_h(PROPOSED_MODEL_PATH + '-KD', MODEL_NAME)\n",
    "\n",
    "#Markers\n",
    "marker_train_accuracy = 's'\n",
    "marker_validation_accuracy = 'x'\n",
    "marker_train_loss = 'o'\n",
    "marker_validation_loss = '|'\n",
    "marker_fillstyle_train = 'none'\n",
    "marker_fillstyle_validation = 'none'\n",
    "marker_plot_markersize = 25\n",
    "marker_plot_markerwidth = 3\n",
    "\n",
    "#Lines\n",
    "line_style_train = '-' \n",
    "line_style_validation = '--'\n",
    "line_width_train = '5'\n",
    "line_width_val = line_width_train\n",
    "line_color_train_accuracy = 'black'\n",
    "line_color_val_accuracy = 'black'\n",
    "line_color_train_loss = 'black'\n",
    "line_color_val_loss = 'black'\n",
    "\n",
    "#Labels\n",
    "train_accuracy_label = 'Train ' + 'Acc'\n",
    "validation_accuracy_label = 'Val ' + 'Acc'\n",
    "train_loss_label = 'Train ' + 'Loss'\n",
    "validation_loss_label = 'Val ' 'Loss'\n",
    "x_label_font_size = 56\n",
    "y_label_font_size = x_label_font_size\n",
    "x_label_font = 'Tahoma'\n",
    "y_label_font = x_label_font\n",
    "# x_label_fontweight = 'bold'\n",
    "# y_label_fontweight = x_label_fontweight\n",
    "\n",
    "#Ticks\n",
    "spine_axis_thickness = 4\n",
    "tick_font_size = 42\n",
    "tick_length = 12\n",
    "tick_width = spine_axis_thickness\n",
    "\n",
    "#Legend\n",
    "legend_border_pad = 0.35\n",
    "legend_line_width = 5\n",
    "legend_font_size = 50\n",
    "legend_edge_color = 'black'\n",
    "legend_label_spacing = 0.5\n",
    "legend_location = 'best'\n",
    "legend_ncol = 1\n",
    "legend_font = 'Tahoma'\n",
    "legend_has_frame = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3NGN9xplbXf4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3NGN9xplbXf4",
    "outputId": "4918584b-dcd4-4f81-966c-6423e67b06c4"
   },
   "outputs": [],
   "source": [
    "#Accuracy and Loss Graph\n",
    "epochs = EPOCHS\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plt.figure(figsize = figsize, \n",
    "           dpi = 600, \n",
    "           edgecolor = 'black', \n",
    "           facecolor = 'white', \n",
    "           linewidth = 0)\n",
    "plt.tight_layout()\n",
    "plt.rc('xtick', labelsize = tick_font_size, direction=\"in\") \n",
    "plt.rc('ytick', labelsize = tick_font_size, direction=\"in\") \n",
    "\n",
    "fig, ax = plt.subplots(figsize = figsize)\n",
    "plt.gcf().subplots_adjust(bottom = 0.15)\n",
    "plt.setp(ax.spines.values(), linewidth = spine_axis_thickness)\n",
    "\n",
    "plt.tick_params(length = tick_length, \n",
    "                width = tick_width, \n",
    "                right = True, \n",
    "                top = True)\n",
    "\n",
    "plt.plot(np.arange(1, epochs + 1), \n",
    "         history[\"accuracy\"], \n",
    "         mew = marker_plot_markerwidth, \n",
    "         color = line_color_train_accuracy, \n",
    "         lw = line_width_train, \n",
    "         marker = marker_train_accuracy, \n",
    "         markersize = marker_plot_markersize, \n",
    "         fillstyle = marker_fillstyle_train, \n",
    "         ls = line_style_train, \n",
    "         label = train_accuracy_label)\n",
    "\n",
    "plt.plot(np.arange(1, epochs + 1), \n",
    "         history[\"val_accuracy\"], \n",
    "         mew = marker_plot_markerwidth, \n",
    "         color = line_color_val_accuracy, \n",
    "         lw = line_width_val, \n",
    "         marker = marker_validation_accuracy, \n",
    "         markersize = marker_plot_markersize, \n",
    "         fillstyle = marker_fillstyle_validation, \n",
    "         ls = line_style_validation,  \n",
    "         label = validation_accuracy_label)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_fig(FIG_PATH, MODEL_NAME + '-AccuracyGraph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yDNtFoRAIfPt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yDNtFoRAIfPt",
    "outputId": "dc22aacb-4abd-404d-fcfe-e986fdd21aa8"
   },
   "outputs": [],
   "source": [
    "#Accuracy and Loss Graph\n",
    "epochs = EPOCHS\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plt.figure(figsize = figsize, \n",
    "           dpi = 600, \n",
    "           edgecolor = 'black', \n",
    "           facecolor = 'white', \n",
    "           linewidth = 0)\n",
    "plt.tight_layout()\n",
    "plt.rc('xtick', labelsize = tick_font_size, direction=\"in\") \n",
    "plt.rc('ytick', labelsize = tick_font_size, direction=\"in\") \n",
    "\n",
    "fig, ax = plt.subplots(figsize = figsize)\n",
    "plt.gcf().subplots_adjust(bottom = 0.15)\n",
    "plt.setp(ax.spines.values(), linewidth = spine_axis_thickness)\n",
    "\n",
    "plt.tick_params(length = tick_length, \n",
    "                width = tick_width, \n",
    "                right = True, \n",
    "                top = True)\n",
    "\n",
    "plt.plot(np.arange(1, epochs + 1), \n",
    "         history[\"loss\"], \n",
    "         mew = marker_plot_markerwidth, \n",
    "         color = line_color_train_loss, \n",
    "         lw = line_width_train, \n",
    "         marker = marker_train_loss, \n",
    "         markersize = marker_plot_markersize, \n",
    "         fillstyle = marker_fillstyle_train, \n",
    "         ls = line_style_train, label = train_loss_label)\n",
    "\n",
    "plt.plot(np.arange(1, epochs + 1), \n",
    "         history[\"val_student_loss\"], \n",
    "         mew = marker_plot_markerwidth, \n",
    "         color = line_color_val_loss, \n",
    "         lw = line_width_val, \n",
    "         marker = marker_validation_loss, \n",
    "         markersize = marker_plot_markersize, \n",
    "         fillstyle = marker_fillstyle_validation, \n",
    "         ls = line_style_validation,  \n",
    "         label = validation_loss_label)\n",
    "\n",
    "plt.xlabel(\"Epochs\", fontfamily = x_label_font, fontsize = x_label_font_size, color ='black')\n",
    "plt.ylabel(\"Accuracy/Loss\", fontfamily = y_label_font, fontsize = y_label_font_size, color = 'black')\n",
    "\n",
    "legend = plt.legend(loc = legend_location, \n",
    "                    ncol = legend_ncol, \n",
    "                    frameon = legend_has_frame, \n",
    "                    fontsize=legend_font_size, \n",
    "                    edgecolor=legend_edge_color, \n",
    "                    borderpad=legend_border_pad, \n",
    "                    labelspacing=legend_label_spacing)\n",
    "\n",
    "frame = legend.get_frame()\n",
    "legend.get_frame().set_linewidth(legend_line_width)\n",
    "legend.get_frame().set_edgecolor(legend_edge_color)\n",
    "plt.setp(legend.texts, family = legend_font)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_fig(FIG_PATH, MODEL_NAME + '-LossGraph')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Distiller_MiniMobileNetV2_cb.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
