{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quuo74jan6hb",
   "metadata": {
    "id": "quuo74jan6hb"
   },
   "outputs": [],
   "source": [
    "#Set path to MAIN FOLDER OF EXPERIMENT\n",
    "#cd /path/to/EXPERIMENT_FOLDER/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af33abcf",
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "af33abcf",
    "outputId": "3cd6cd5f-f178-4c5d-dd11-429d9f121984"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIBRARIES LOADED\n"
     ]
    }
   ],
   "source": [
    "#LOAD DEPENDENCIES\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import talos\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#IMPORT LOSS, OPTIMIZER, CALLBACK AND LAYERS\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, KLDivergence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D\n",
    "\n",
    "#IMPORT MODEL APIs\n",
    "from tensorflow.keras.models import Model, load_model, save_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 as selected_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as student_preprocess\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as teacher_preprocess\n",
    "\n",
    "#PREVENT ERROR UNCESSARY MESSAGES\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "print(\"LIBRARIES LOADED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "QilrCeOhDZey",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QilrCeOhDZey",
    "outputId": "1b4e67cc-63b8-4e05-dbd2-dd904f57b225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL REQUERED PATHS SET\n"
     ]
    }
   ],
   "source": [
    "#Tweakable parameters\n",
    "MODEL_KIND = \"KD_model\"\n",
    "MODEL_NAME = \"MiniMobileNetV2\"\n",
    "\n",
    "#Models paths\n",
    "PROPOSED_MODEL_PATH = \"models/proposed_model/\" + MODEL_NAME\n",
    "HPO_PATH = \"models/hpo_model/\" + MODEL_NAME\n",
    "\n",
    "#Figures paths\n",
    "FIG_PATH = 'figures/' + MODEL_KIND + \"/\" + MODEL_NAME\n",
    "\n",
    "#Data paths\n",
    "MAIN_DATA_DIR = \"ds/\"\n",
    "TRAIN_DATA_DIR = MAIN_DATA_DIR + \"train/\"\n",
    "TEST_DATA_DIR = MAIN_DATA_DIR + \"test/\"\n",
    "VALIDATION_DATA_DIR = MAIN_DATA_DIR + \"val/\"\n",
    "\n",
    "print(\"ALL REQUERED PATHS SET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "RQq1u6rdBNdE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQq1u6rdBNdE",
    "outputId": "4658db3e-9904-45e3-fd00-5d8e86a19541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL CUSTOM FUNCTIONS DEFIEND\n"
     ]
    }
   ],
   "source": [
    "#Save Model Function\n",
    "def save_m(model, directory, model_name):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    model.save(directory + \"/\" + model_name + \".h5\")\n",
    "\n",
    "#Save History Function\n",
    "def save_h(history, directory, history_name):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    with open(directory + '/' + history_name + '.history', 'wb') as file:\n",
    "        pickle.dump(history, file)\n",
    "\n",
    "#Load model Function\n",
    "def load_m(directory, model_name):\n",
    "    if not os.path.exists(directory):\n",
    "        print(\"Model File Does Not Exist!!\")\n",
    "        return \n",
    "    model = load_model(directory + \"/\" + model_name + \".h5\")\n",
    "    return model\n",
    "\n",
    "#Load History Function\n",
    "def load_h(directory, history_name):\n",
    "    if not os.path.exists(directory):\n",
    "        print(\"History File Does Not Exist!!\")\n",
    "        return \n",
    "    with open(directory + '/' + history_name + '.history', 'rb') as file:\n",
    "        his = pickle.load(file)\n",
    "    return his\n",
    "\n",
    "def save_fig(directory, fig_name):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    plt.savefig(directory + '/' + fig_name + '.tiff', bbox_inches='tight', dpi=600, format='tiff')\n",
    "    \n",
    "print(\"ALL CUSTOM FUNCTIONS DEFIEND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "zYGVjb3gB3oY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYGVjb3gB3oY",
    "outputId": "1026741c-8049-49cb-9a92-cebf285853cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SIZE --> (None, 224, 224, 3) \n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n"
     ]
    }
   ],
   "source": [
    "#DATA GENERATORS\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "img_rows, img_cols = 224, 224\n",
    "INPUT_SHAPE = (img_rows, img_cols,3)\n",
    "MODEL_INPUT = Input(shape=INPUT_SHAPE)\n",
    "print(\"INPUT SIZE -->\", MODEL_INPUT.shape, \"\\n\")\n",
    "NUM_CLASSES = 199\n",
    "\n",
    "def create_data_generator(pre_process=None):\n",
    "    nb_train_samples = 0\n",
    "    nb_val_samples = 0\n",
    "    num_classes = 0\n",
    "    train_generator = None\n",
    "    validation_generator = None\n",
    "\n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=pre_process)\n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=pre_process)\n",
    "\n",
    "    if not os.path.exists(TRAIN_DATA_DIR):\n",
    "        print(\"TRAIN DATA DOES NOT EXITS!\")\n",
    "        return None, None\n",
    "    else:\n",
    "        print(\"LOAD TRAIN SAMPLES...\")\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "                TRAIN_DATA_DIR,\n",
    "                target_size=(img_rows,img_cols),\n",
    "                batch_size=BATCH_SIZE,\n",
    "                class_mode='categorical',\n",
    "                seed=42)\n",
    "        \n",
    "        #CHECK  THE NUMBER OF SAMPLES\n",
    "        nb_train_samples = len(train_generator.filenames)\n",
    "        if nb_train_samples == 0:\n",
    "            print(\"NO DATA TRAIN FOUND IN TRAIN FOLDER!\")\n",
    "            return None, None\n",
    "\n",
    "    print()\n",
    "    if not os.path.exists(TRAIN_DATA_DIR):\n",
    "        print(\"VALIDATION DATA DOES NOT EXITS!\")\n",
    "        return None, None\n",
    "    else:\n",
    "        print(\"LOAD VALIDATION SAMPLES...\")\n",
    "        validation_generator = val_datagen.flow_from_directory(\n",
    "                VALIDATION_DATA_DIR,\n",
    "                target_size=(img_rows,img_cols),\n",
    "                batch_size=BATCH_SIZE,\n",
    "                class_mode='categorical',\n",
    "                seed=42,\n",
    "                shuffle=False)\n",
    "\n",
    "        #CHECK  THE NUMBER OF SAMPLES\n",
    "        nb_validation_samples = len(validation_generator.filenames)\n",
    "        if nb_validation_samples == 0:\n",
    "            print(\"NO DATA VALIDATION FOUND IN VALIDATION FOLDER!\")\n",
    "            return None, None\n",
    "\n",
    "    print()\n",
    "    if nb_train_samples > 0 and nb_validation_samples > 0:\n",
    "        num_classes= len(train_generator.class_indices)\n",
    "        print(\"GENERATER ARE SET!\")\n",
    "        print('CLASSES TO TRAIN', num_classes, 'classes')\n",
    "    \n",
    "    return (train_generator, nb_train_samples), (validation_generator, nb_validation_samples)\n",
    "\n",
    "_, _=create_data_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec35ada5",
   "metadata": {
    "id": "ec35ada5"
   },
   "outputs": [],
   "source": [
    "#Knowledge Distiller(KD)\n",
    "\n",
    "class KDistiller(Model):\n",
    "    def __init__(self, student, teacher, student_preprocess=None, teacher_preprocess=None):\n",
    "        super(KDistiller, self).__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "        self.student_preprocess = student_preprocess\n",
    "        self.teacher_preprocess = teacher_preprocess\n",
    "\n",
    "    def compile(self, optimizer,  metrics, student_loss_fn, distillation_loss_fn, alpha, temperature):\n",
    "        super(KDistiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # UNPACK DATA\n",
    "        student_x, y = data\n",
    "        teacher_x, y = data\n",
    "\n",
    "        # PREPROCESS DATA\n",
    "        if self.student_preprocess != None: student_x = self.student_preprocess(student_x)\n",
    "        if self.teacher_preprocess != None: teacher_x = self.teacher_preprocess(teacher_x)\n",
    "        \n",
    "        # FORWARD PASS OF TEACHER\n",
    "        teacher_preds = self.teacher(teacher_x, training=False)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # FORWARD PASS OF STUDENT\n",
    "            student_preds = self.student(student_x, training=True)\n",
    "\n",
    "            # CALCULATE STUDENT LOSS\n",
    "            student_loss = self.student_loss_fn(y, student_preds)\n",
    "\n",
    "            # CALCULATE DISTISLATION LOSS\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                tf.nn.softmax(teacher_preds / self.temperature, axis=1),\n",
    "                tf.nn.softmax(student_preds / self.temperature, axis=1),\n",
    "            )\n",
    "\n",
    "            # CALCULATE TOTAL LOSS\n",
    "            total_loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
    "\n",
    "        # CALCULATE GRADIENT\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(total_loss, trainable_vars)\n",
    "\n",
    "        # SET WEIGHTS\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # SET METRICES\n",
    "        self.compiled_metrics.update_state(y, student_preds)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss, 'loss':total_loss}\n",
    "        )\n",
    "\n",
    "        return results\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # UNPACK DATA\n",
    "        x, y = data\n",
    "\n",
    "        # PREPROCESS DATA\n",
    "        x = self.student_preprocess(x)\n",
    "        \n",
    "        # GET PREDICTIONS FROM STUDENT\n",
    "        y_preds = self.student(x, training=False)\n",
    "\n",
    "        # CALCULATE STUDENT LOSS\n",
    "        student_loss = self.student_loss_fn(y, y_preds)\n",
    "\n",
    "        # SET METRICES \n",
    "        self.compiled_metrics.update_state(y, y_preds)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss})\n",
    "\n",
    "        return results\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        return self.student(inputs, training=training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kqrx0G7_7yNK",
   "metadata": {
    "id": "Kqrx0G7_7yNK"
   },
   "source": [
    "**Teacher Model :** EnsembleModel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "JBlFLvKqauvU",
   "metadata": {
    "id": "JBlFLvKqauvU"
   },
   "outputs": [],
   "source": [
    "TEACHER_NAME = \"EfficientNetB7\"\n",
    "TEACHER_MODEL_PATH = \"models/teacher_model/\" + TEACHER_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f340450",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f340450",
    "outputId": "64f8dd81-57b0-436f-8d56-02dceacc512f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "PLEASE CHECK THE ENTIRE MODEL UP TO THE END\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "Model: \"benchmark-onelayeroff-0_0001-EfficientNetB7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rescaling (Rescaling)           (None, 224, 224, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "normalization (Normalization)   (None, 224, 224, 3)  7           rescaling[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv_pad (ZeroPadding2D)   (None, 225, 225, 3)  0           normalization[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 112, 112, 64) 1728        stem_conv_pad[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 112, 112, 64) 256         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 112, 112, 64) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 112, 112, 64) 576         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 112, 112, 64) 256         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 112, 112, 64) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 64)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 64)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 16)     1040        block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 64)     1088        block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 112, 112, 64) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 112, 112, 32) 2048        block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 112, 112, 32) 128         block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_dwconv (DepthwiseConv2D (None, 112, 112, 32) 288         block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_bn (BatchNormalization) (None, 112, 112, 32) 128         block1b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1b_activation (Activation) (None, 112, 112, 32) 0           block1b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_squeeze (GlobalAvera (None, 32)           0           block1b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_excite (Multiply)    (None, 112, 112, 32) 0           block1b_activation[0][0]         \n",
      "                                                                 block1b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_conv (Conv2D)   (None, 112, 112, 32) 1024        block1b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_bn (BatchNormal (None, 112, 112, 32) 128         block1b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_drop (Dropout)          (None, 112, 112, 32) 0           block1b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_add (Add)               (None, 112, 112, 32) 0           block1b_drop[0][0]               \n",
      "                                                                 block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_dwconv (DepthwiseConv2D (None, 112, 112, 32) 288         block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block1c_bn (BatchNormalization) (None, 112, 112, 32) 128         block1c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1c_activation (Activation) (None, 112, 112, 32) 0           block1c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_squeeze (GlobalAvera (None, 32)           0           block1c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_se_excite (Multiply)    (None, 112, 112, 32) 0           block1c_activation[0][0]         \n",
      "                                                                 block1c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_project_conv (Conv2D)   (None, 112, 112, 32) 1024        block1c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1c_project_bn (BatchNormal (None, 112, 112, 32) 128         block1c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1c_drop (Dropout)          (None, 112, 112, 32) 0           block1c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1c_add (Add)               (None, 112, 112, 32) 0           block1c_drop[0][0]               \n",
      "                                                                 block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block1d_dwconv (DepthwiseConv2D (None, 112, 112, 32) 288         block1c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block1d_bn (BatchNormalization) (None, 112, 112, 32) 128         block1d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1d_activation (Activation) (None, 112, 112, 32) 0           block1d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1d_se_squeeze (GlobalAvera (None, 32)           0           block1d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1d_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1d_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1d_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1d_se_excite (Multiply)    (None, 112, 112, 32) 0           block1d_activation[0][0]         \n",
      "                                                                 block1d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1d_project_conv (Conv2D)   (None, 112, 112, 32) 1024        block1d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1d_project_bn (BatchNormal (None, 112, 112, 32) 128         block1d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1d_drop (Dropout)          (None, 112, 112, 32) 0           block1d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1d_add (Add)               (None, 112, 112, 32) 0           block1d_drop[0][0]               \n",
      "                                                                 block1c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 112, 112, 192 6144        block1d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 112, 112, 192 768         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 112, 112, 192 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv_pad (ZeroPadding (None, 113, 113, 192 0           block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 56, 56, 192)  1728        block2a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 56, 56, 192)  768         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 56, 56, 192)  0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 192)          0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 56, 56, 192)  0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 56, 56, 48)   9216        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 56, 56, 48)   192         block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 56, 56, 288)  13824       block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 56, 56, 288)  1152        block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 56, 56, 288)  0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 56, 56, 288)  2592        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 56, 56, 288)  1152        block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 56, 56, 288)  0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 288)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 56, 56, 288)  0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 56, 56, 48)   13824       block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 56, 56, 48)   192         block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (Dropout)          (None, 56, 56, 48)   0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 56, 56, 48)   0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_conv (Conv2D)    (None, 56, 56, 288)  13824       block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_bn (BatchNormali (None, 56, 56, 288)  1152        block2c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_activation (Acti (None, 56, 56, 288)  0           block2c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_dwconv (DepthwiseConv2D (None, 56, 56, 288)  2592        block2c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2c_bn (BatchNormalization) (None, 56, 56, 288)  1152        block2c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2c_activation (Activation) (None, 56, 56, 288)  0           block2c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_squeeze (GlobalAvera (None, 288)          0           block2c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_excite (Multiply)    (None, 56, 56, 288)  0           block2c_activation[0][0]         \n",
      "                                                                 block2c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_conv (Conv2D)   (None, 56, 56, 48)   13824       block2c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_bn (BatchNormal (None, 56, 56, 48)   192         block2c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2c_drop (Dropout)          (None, 56, 56, 48)   0           block2c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_add (Add)               (None, 56, 56, 48)   0           block2c_drop[0][0]               \n",
      "                                                                 block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_conv (Conv2D)    (None, 56, 56, 288)  13824       block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_bn (BatchNormali (None, 56, 56, 288)  1152        block2d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_activation (Acti (None, 56, 56, 288)  0           block2d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_dwconv (DepthwiseConv2D (None, 56, 56, 288)  2592        block2d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2d_bn (BatchNormalization) (None, 56, 56, 288)  1152        block2d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2d_activation (Activation) (None, 56, 56, 288)  0           block2d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_squeeze (GlobalAvera (None, 288)          0           block2d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_excite (Multiply)    (None, 56, 56, 288)  0           block2d_activation[0][0]         \n",
      "                                                                 block2d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_project_conv (Conv2D)   (None, 56, 56, 48)   13824       block2d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_project_bn (BatchNormal (None, 56, 56, 48)   192         block2d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2d_drop (Dropout)          (None, 56, 56, 48)   0           block2d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_add (Add)               (None, 56, 56, 48)   0           block2d_drop[0][0]               \n",
      "                                                                 block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_conv (Conv2D)    (None, 56, 56, 288)  13824       block2d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_bn (BatchNormali (None, 56, 56, 288)  1152        block2e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2e_expand_activation (Acti (None, 56, 56, 288)  0           block2e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_dwconv (DepthwiseConv2D (None, 56, 56, 288)  2592        block2e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2e_bn (BatchNormalization) (None, 56, 56, 288)  1152        block2e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2e_activation (Activation) (None, 56, 56, 288)  0           block2e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_squeeze (GlobalAvera (None, 288)          0           block2e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_se_excite (Multiply)    (None, 56, 56, 288)  0           block2e_activation[0][0]         \n",
      "                                                                 block2e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_project_conv (Conv2D)   (None, 56, 56, 48)   13824       block2e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2e_project_bn (BatchNormal (None, 56, 56, 48)   192         block2e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2e_drop (Dropout)          (None, 56, 56, 48)   0           block2e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2e_add (Add)               (None, 56, 56, 48)   0           block2e_drop[0][0]               \n",
      "                                                                 block2d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2f_expand_conv (Conv2D)    (None, 56, 56, 288)  13824       block2e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2f_expand_bn (BatchNormali (None, 56, 56, 288)  1152        block2f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2f_expand_activation (Acti (None, 56, 56, 288)  0           block2f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2f_dwconv (DepthwiseConv2D (None, 56, 56, 288)  2592        block2f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2f_bn (BatchNormalization) (None, 56, 56, 288)  1152        block2f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2f_activation (Activation) (None, 56, 56, 288)  0           block2f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_squeeze (GlobalAvera (None, 288)          0           block2f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2f_se_excite (Multiply)    (None, 56, 56, 288)  0           block2f_activation[0][0]         \n",
      "                                                                 block2f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2f_project_conv (Conv2D)   (None, 56, 56, 48)   13824       block2f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2f_project_bn (BatchNormal (None, 56, 56, 48)   192         block2f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2f_drop (Dropout)          (None, 56, 56, 48)   0           block2f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2f_add (Add)               (None, 56, 56, 48)   0           block2f_drop[0][0]               \n",
      "                                                                 block2e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2g_expand_conv (Conv2D)    (None, 56, 56, 288)  13824       block2f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2g_expand_bn (BatchNormali (None, 56, 56, 288)  1152        block2g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2g_expand_activation (Acti (None, 56, 56, 288)  0           block2g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2g_dwconv (DepthwiseConv2D (None, 56, 56, 288)  2592        block2g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2g_bn (BatchNormalization) (None, 56, 56, 288)  1152        block2g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2g_activation (Activation) (None, 56, 56, 288)  0           block2g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2g_se_squeeze (GlobalAvera (None, 288)          0           block2g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2g_se_reshape (Reshape)    (None, 1, 1, 288)    0           block2g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2g_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block2g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2g_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block2g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2g_se_excite (Multiply)    (None, 56, 56, 288)  0           block2g_activation[0][0]         \n",
      "                                                                 block2g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2g_project_conv (Conv2D)   (None, 56, 56, 48)   13824       block2g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2g_project_bn (BatchNormal (None, 56, 56, 48)   192         block2g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2g_drop (Dropout)          (None, 56, 56, 48)   0           block2g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2g_add (Add)               (None, 56, 56, 48)   0           block2g_drop[0][0]               \n",
      "                                                                 block2f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 56, 56, 288)  13824       block2g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 56, 56, 288)  1152        block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 56, 56, 288)  0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv_pad (ZeroPadding (None, 59, 59, 288)  0           block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 28, 28, 288)  7200        block3a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 28, 28, 288)  1152        block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 28, 28, 288)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 288)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 288)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 28, 28, 288)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 28, 28, 80)   23040       block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 28, 28, 80)   320         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 28, 28, 480)  38400       block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 28, 28, 480)  1920        block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 28, 28, 480)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 28, 28, 480)  12000       block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 28, 28, 480)  1920        block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 28, 28, 480)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 480)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 28, 28, 480)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 28, 28, 80)   38400       block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 28, 28, 80)   320         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (Dropout)          (None, 28, 28, 80)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 28, 28, 80)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_conv (Conv2D)    (None, 28, 28, 480)  38400       block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_bn (BatchNormali (None, 28, 28, 480)  1920        block3c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_activation (Acti (None, 28, 28, 480)  0           block3c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_dwconv (DepthwiseConv2D (None, 28, 28, 480)  12000       block3c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3c_bn (BatchNormalization) (None, 28, 28, 480)  1920        block3c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3c_activation (Activation) (None, 28, 28, 480)  0           block3c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_squeeze (GlobalAvera (None, 480)          0           block3c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_excite (Multiply)    (None, 28, 28, 480)  0           block3c_activation[0][0]         \n",
      "                                                                 block3c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_conv (Conv2D)   (None, 28, 28, 80)   38400       block3c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_bn (BatchNormal (None, 28, 28, 80)   320         block3c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3c_drop (Dropout)          (None, 28, 28, 80)   0           block3c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_add (Add)               (None, 28, 28, 80)   0           block3c_drop[0][0]               \n",
      "                                                                 block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_conv (Conv2D)    (None, 28, 28, 480)  38400       block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_bn (BatchNormali (None, 28, 28, 480)  1920        block3d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_activation (Acti (None, 28, 28, 480)  0           block3d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_dwconv (DepthwiseConv2D (None, 28, 28, 480)  12000       block3d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3d_bn (BatchNormalization) (None, 28, 28, 480)  1920        block3d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3d_activation (Activation) (None, 28, 28, 480)  0           block3d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_squeeze (GlobalAvera (None, 480)          0           block3d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_excite (Multiply)    (None, 28, 28, 480)  0           block3d_activation[0][0]         \n",
      "                                                                 block3d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_project_conv (Conv2D)   (None, 28, 28, 80)   38400       block3d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_project_bn (BatchNormal (None, 28, 28, 80)   320         block3d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3d_drop (Dropout)          (None, 28, 28, 80)   0           block3d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_add (Add)               (None, 28, 28, 80)   0           block3d_drop[0][0]               \n",
      "                                                                 block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_conv (Conv2D)    (None, 28, 28, 480)  38400       block3d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_bn (BatchNormali (None, 28, 28, 480)  1920        block3e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3e_expand_activation (Acti (None, 28, 28, 480)  0           block3e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_dwconv (DepthwiseConv2D (None, 28, 28, 480)  12000       block3e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3e_bn (BatchNormalization) (None, 28, 28, 480)  1920        block3e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3e_activation (Activation) (None, 28, 28, 480)  0           block3e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_squeeze (GlobalAvera (None, 480)          0           block3e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_se_excite (Multiply)    (None, 28, 28, 480)  0           block3e_activation[0][0]         \n",
      "                                                                 block3e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_project_conv (Conv2D)   (None, 28, 28, 80)   38400       block3e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3e_project_bn (BatchNormal (None, 28, 28, 80)   320         block3e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3e_drop (Dropout)          (None, 28, 28, 80)   0           block3e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3e_add (Add)               (None, 28, 28, 80)   0           block3e_drop[0][0]               \n",
      "                                                                 block3d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3f_expand_conv (Conv2D)    (None, 28, 28, 480)  38400       block3e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3f_expand_bn (BatchNormali (None, 28, 28, 480)  1920        block3f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3f_expand_activation (Acti (None, 28, 28, 480)  0           block3f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3f_dwconv (DepthwiseConv2D (None, 28, 28, 480)  12000       block3f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3f_bn (BatchNormalization) (None, 28, 28, 480)  1920        block3f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3f_activation (Activation) (None, 28, 28, 480)  0           block3f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_squeeze (GlobalAvera (None, 480)          0           block3f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3f_se_excite (Multiply)    (None, 28, 28, 480)  0           block3f_activation[0][0]         \n",
      "                                                                 block3f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3f_project_conv (Conv2D)   (None, 28, 28, 80)   38400       block3f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3f_project_bn (BatchNormal (None, 28, 28, 80)   320         block3f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3f_drop (Dropout)          (None, 28, 28, 80)   0           block3f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3f_add (Add)               (None, 28, 28, 80)   0           block3f_drop[0][0]               \n",
      "                                                                 block3e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3g_expand_conv (Conv2D)    (None, 28, 28, 480)  38400       block3f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3g_expand_bn (BatchNormali (None, 28, 28, 480)  1920        block3g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3g_expand_activation (Acti (None, 28, 28, 480)  0           block3g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3g_dwconv (DepthwiseConv2D (None, 28, 28, 480)  12000       block3g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3g_bn (BatchNormalization) (None, 28, 28, 480)  1920        block3g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3g_activation (Activation) (None, 28, 28, 480)  0           block3g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3g_se_squeeze (GlobalAvera (None, 480)          0           block3g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3g_se_reshape (Reshape)    (None, 1, 1, 480)    0           block3g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3g_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block3g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3g_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block3g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3g_se_excite (Multiply)    (None, 28, 28, 480)  0           block3g_activation[0][0]         \n",
      "                                                                 block3g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3g_project_conv (Conv2D)   (None, 28, 28, 80)   38400       block3g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3g_project_bn (BatchNormal (None, 28, 28, 80)   320         block3g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3g_drop (Dropout)          (None, 28, 28, 80)   0           block3g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3g_add (Add)               (None, 28, 28, 80)   0           block3g_drop[0][0]               \n",
      "                                                                 block3f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 28, 28, 480)  38400       block3g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 28, 28, 480)  1920        block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 28, 28, 480)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv_pad (ZeroPadding (None, 29, 29, 480)  0           block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 14, 14, 480)  4320        block4a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 14, 14, 480)  1920        block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 14, 14, 480)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 480)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 14, 14, 480)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 14, 14, 160)  76800       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 14, 14, 160)  640         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 14, 14, 960)  153600      block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 14, 14, 960)  3840        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 14, 14, 960)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 14, 14, 960)  8640        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 14, 14, 960)  3840        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 14, 14, 960)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 960)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 14, 14, 960)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 14, 14, 160)  153600      block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 14, 14, 160)  640         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (Dropout)          (None, 14, 14, 160)  0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 14, 14, 160)  0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 14, 14, 960)  153600      block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 14, 14, 960)  3840        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 14, 14, 960)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 14, 14, 960)  8640        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 14, 14, 960)  3840        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 14, 14, 960)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 960)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 14, 14, 960)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 14, 14, 160)  153600      block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 14, 14, 160)  640         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (Dropout)          (None, 14, 14, 160)  0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 14, 14, 160)  0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_conv (Conv2D)    (None, 14, 14, 960)  153600      block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_bn (BatchNormali (None, 14, 14, 960)  3840        block4d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_activation (Acti (None, 14, 14, 960)  0           block4d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_dwconv (DepthwiseConv2D (None, 14, 14, 960)  8640        block4d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4d_bn (BatchNormalization) (None, 14, 14, 960)  3840        block4d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4d_activation (Activation) (None, 14, 14, 960)  0           block4d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_squeeze (GlobalAvera (None, 960)          0           block4d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_excite (Multiply)    (None, 14, 14, 960)  0           block4d_activation[0][0]         \n",
      "                                                                 block4d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_conv (Conv2D)   (None, 14, 14, 160)  153600      block4d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_bn (BatchNormal (None, 14, 14, 160)  640         block4d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4d_drop (Dropout)          (None, 14, 14, 160)  0           block4d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_add (Add)               (None, 14, 14, 160)  0           block4d_drop[0][0]               \n",
      "                                                                 block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_conv (Conv2D)    (None, 14, 14, 960)  153600      block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_bn (BatchNormali (None, 14, 14, 960)  3840        block4e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_activation (Acti (None, 14, 14, 960)  0           block4e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_dwconv (DepthwiseConv2D (None, 14, 14, 960)  8640        block4e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4e_bn (BatchNormalization) (None, 14, 14, 960)  3840        block4e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4e_activation (Activation) (None, 14, 14, 960)  0           block4e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_squeeze (GlobalAvera (None, 960)          0           block4e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_excite (Multiply)    (None, 14, 14, 960)  0           block4e_activation[0][0]         \n",
      "                                                                 block4e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_conv (Conv2D)   (None, 14, 14, 160)  153600      block4e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_bn (BatchNormal (None, 14, 14, 160)  640         block4e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4e_drop (Dropout)          (None, 14, 14, 160)  0           block4e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_add (Add)               (None, 14, 14, 160)  0           block4e_drop[0][0]               \n",
      "                                                                 block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_conv (Conv2D)    (None, 14, 14, 960)  153600      block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_bn (BatchNormali (None, 14, 14, 960)  3840        block4f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_activation (Acti (None, 14, 14, 960)  0           block4f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_dwconv (DepthwiseConv2D (None, 14, 14, 960)  8640        block4f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4f_bn (BatchNormalization) (None, 14, 14, 960)  3840        block4f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4f_activation (Activation) (None, 14, 14, 960)  0           block4f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_squeeze (GlobalAvera (None, 960)          0           block4f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_excite (Multiply)    (None, 14, 14, 960)  0           block4f_activation[0][0]         \n",
      "                                                                 block4f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_project_conv (Conv2D)   (None, 14, 14, 160)  153600      block4f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_project_bn (BatchNormal (None, 14, 14, 160)  640         block4f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4f_drop (Dropout)          (None, 14, 14, 160)  0           block4f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_add (Add)               (None, 14, 14, 160)  0           block4f_drop[0][0]               \n",
      "                                                                 block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_conv (Conv2D)    (None, 14, 14, 960)  153600      block4f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_bn (BatchNormali (None, 14, 14, 960)  3840        block4g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4g_expand_activation (Acti (None, 14, 14, 960)  0           block4g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_dwconv (DepthwiseConv2D (None, 14, 14, 960)  8640        block4g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4g_bn (BatchNormalization) (None, 14, 14, 960)  3840        block4g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4g_activation (Activation) (None, 14, 14, 960)  0           block4g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_squeeze (GlobalAvera (None, 960)          0           block4g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_se_excite (Multiply)    (None, 14, 14, 960)  0           block4g_activation[0][0]         \n",
      "                                                                 block4g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_project_conv (Conv2D)   (None, 14, 14, 160)  153600      block4g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4g_project_bn (BatchNormal (None, 14, 14, 160)  640         block4g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4g_drop (Dropout)          (None, 14, 14, 160)  0           block4g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4g_add (Add)               (None, 14, 14, 160)  0           block4g_drop[0][0]               \n",
      "                                                                 block4f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4h_expand_conv (Conv2D)    (None, 14, 14, 960)  153600      block4g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4h_expand_bn (BatchNormali (None, 14, 14, 960)  3840        block4h_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4h_expand_activation (Acti (None, 14, 14, 960)  0           block4h_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4h_dwconv (DepthwiseConv2D (None, 14, 14, 960)  8640        block4h_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4h_bn (BatchNormalization) (None, 14, 14, 960)  3840        block4h_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4h_activation (Activation) (None, 14, 14, 960)  0           block4h_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_squeeze (GlobalAvera (None, 960)          0           block4h_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4h_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4h_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4h_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4h_se_excite (Multiply)    (None, 14, 14, 960)  0           block4h_activation[0][0]         \n",
      "                                                                 block4h_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4h_project_conv (Conv2D)   (None, 14, 14, 160)  153600      block4h_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4h_project_bn (BatchNormal (None, 14, 14, 160)  640         block4h_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4h_drop (Dropout)          (None, 14, 14, 160)  0           block4h_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4h_add (Add)               (None, 14, 14, 160)  0           block4h_drop[0][0]               \n",
      "                                                                 block4g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4i_expand_conv (Conv2D)    (None, 14, 14, 960)  153600      block4h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4i_expand_bn (BatchNormali (None, 14, 14, 960)  3840        block4i_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4i_expand_activation (Acti (None, 14, 14, 960)  0           block4i_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4i_dwconv (DepthwiseConv2D (None, 14, 14, 960)  8640        block4i_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4i_bn (BatchNormalization) (None, 14, 14, 960)  3840        block4i_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4i_activation (Activation) (None, 14, 14, 960)  0           block4i_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4i_se_squeeze (GlobalAvera (None, 960)          0           block4i_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4i_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4i_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4i_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4i_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4i_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4i_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4i_se_excite (Multiply)    (None, 14, 14, 960)  0           block4i_activation[0][0]         \n",
      "                                                                 block4i_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4i_project_conv (Conv2D)   (None, 14, 14, 160)  153600      block4i_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4i_project_bn (BatchNormal (None, 14, 14, 160)  640         block4i_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4i_drop (Dropout)          (None, 14, 14, 160)  0           block4i_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4i_add (Add)               (None, 14, 14, 160)  0           block4i_drop[0][0]               \n",
      "                                                                 block4h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4j_expand_conv (Conv2D)    (None, 14, 14, 960)  153600      block4i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4j_expand_bn (BatchNormali (None, 14, 14, 960)  3840        block4j_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4j_expand_activation (Acti (None, 14, 14, 960)  0           block4j_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4j_dwconv (DepthwiseConv2D (None, 14, 14, 960)  8640        block4j_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4j_bn (BatchNormalization) (None, 14, 14, 960)  3840        block4j_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4j_activation (Activation) (None, 14, 14, 960)  0           block4j_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4j_se_squeeze (GlobalAvera (None, 960)          0           block4j_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4j_se_reshape (Reshape)    (None, 1, 1, 960)    0           block4j_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4j_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block4j_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4j_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block4j_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4j_se_excite (Multiply)    (None, 14, 14, 960)  0           block4j_activation[0][0]         \n",
      "                                                                 block4j_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4j_project_conv (Conv2D)   (None, 14, 14, 160)  153600      block4j_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4j_project_bn (BatchNormal (None, 14, 14, 160)  640         block4j_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4j_drop (Dropout)          (None, 14, 14, 160)  0           block4j_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4j_add (Add)               (None, 14, 14, 160)  0           block4j_drop[0][0]               \n",
      "                                                                 block4i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 14, 14, 960)  153600      block4j_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 14, 14, 960)  3840        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 14, 14, 960)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 14, 14, 960)  24000       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 14, 14, 960)  3840        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 14, 14, 960)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 960)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 960)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 14, 14, 960)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 14, 14, 224)  215040      block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 14, 14, 224)  896         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 14, 14, 1344) 301056      block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 14, 14, 1344) 5376        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 14, 14, 1344) 0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 14, 14, 1344) 33600       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 14, 14, 1344) 5376        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 14, 14, 1344) 0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 1344)         0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 14, 14, 1344) 0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 14, 14, 224)  301056      block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 14, 14, 224)  896         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (Dropout)          (None, 14, 14, 224)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 14, 14, 224)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 14, 14, 1344) 301056      block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 14, 14, 1344) 5376        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 14, 14, 1344) 0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 14, 14, 1344) 33600       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 14, 14, 1344) 5376        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 14, 14, 1344) 0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 1344)         0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 14, 14, 1344) 0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 14, 14, 224)  301056      block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 14, 14, 224)  896         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (Dropout)          (None, 14, 14, 224)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 14, 14, 224)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_conv (Conv2D)    (None, 14, 14, 1344) 301056      block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_bn (BatchNormali (None, 14, 14, 1344) 5376        block5d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_activation (Acti (None, 14, 14, 1344) 0           block5d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_dwconv (DepthwiseConv2D (None, 14, 14, 1344) 33600       block5d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5d_bn (BatchNormalization) (None, 14, 14, 1344) 5376        block5d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5d_activation (Activation) (None, 14, 14, 1344) 0           block5d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_squeeze (GlobalAvera (None, 1344)         0           block5d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_excite (Multiply)    (None, 14, 14, 1344) 0           block5d_activation[0][0]         \n",
      "                                                                 block5d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_conv (Conv2D)   (None, 14, 14, 224)  301056      block5d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_bn (BatchNormal (None, 14, 14, 224)  896         block5d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5d_drop (Dropout)          (None, 14, 14, 224)  0           block5d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_add (Add)               (None, 14, 14, 224)  0           block5d_drop[0][0]               \n",
      "                                                                 block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_conv (Conv2D)    (None, 14, 14, 1344) 301056      block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_bn (BatchNormali (None, 14, 14, 1344) 5376        block5e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_activation (Acti (None, 14, 14, 1344) 0           block5e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_dwconv (DepthwiseConv2D (None, 14, 14, 1344) 33600       block5e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5e_bn (BatchNormalization) (None, 14, 14, 1344) 5376        block5e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5e_activation (Activation) (None, 14, 14, 1344) 0           block5e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_squeeze (GlobalAvera (None, 1344)         0           block5e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_excite (Multiply)    (None, 14, 14, 1344) 0           block5e_activation[0][0]         \n",
      "                                                                 block5e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_conv (Conv2D)   (None, 14, 14, 224)  301056      block5e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_bn (BatchNormal (None, 14, 14, 224)  896         block5e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5e_drop (Dropout)          (None, 14, 14, 224)  0           block5e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_add (Add)               (None, 14, 14, 224)  0           block5e_drop[0][0]               \n",
      "                                                                 block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_conv (Conv2D)    (None, 14, 14, 1344) 301056      block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_bn (BatchNormali (None, 14, 14, 1344) 5376        block5f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_activation (Acti (None, 14, 14, 1344) 0           block5f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_dwconv (DepthwiseConv2D (None, 14, 14, 1344) 33600       block5f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5f_bn (BatchNormalization) (None, 14, 14, 1344) 5376        block5f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5f_activation (Activation) (None, 14, 14, 1344) 0           block5f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_squeeze (GlobalAvera (None, 1344)         0           block5f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_excite (Multiply)    (None, 14, 14, 1344) 0           block5f_activation[0][0]         \n",
      "                                                                 block5f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_project_conv (Conv2D)   (None, 14, 14, 224)  301056      block5f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_project_bn (BatchNormal (None, 14, 14, 224)  896         block5f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5f_drop (Dropout)          (None, 14, 14, 224)  0           block5f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_add (Add)               (None, 14, 14, 224)  0           block5f_drop[0][0]               \n",
      "                                                                 block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_conv (Conv2D)    (None, 14, 14, 1344) 301056      block5f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_bn (BatchNormali (None, 14, 14, 1344) 5376        block5g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5g_expand_activation (Acti (None, 14, 14, 1344) 0           block5g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_dwconv (DepthwiseConv2D (None, 14, 14, 1344) 33600       block5g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5g_bn (BatchNormalization) (None, 14, 14, 1344) 5376        block5g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5g_activation (Activation) (None, 14, 14, 1344) 0           block5g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_squeeze (GlobalAvera (None, 1344)         0           block5g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_se_excite (Multiply)    (None, 14, 14, 1344) 0           block5g_activation[0][0]         \n",
      "                                                                 block5g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_project_conv (Conv2D)   (None, 14, 14, 224)  301056      block5g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5g_project_bn (BatchNormal (None, 14, 14, 224)  896         block5g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5g_drop (Dropout)          (None, 14, 14, 224)  0           block5g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5g_add (Add)               (None, 14, 14, 224)  0           block5g_drop[0][0]               \n",
      "                                                                 block5f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5h_expand_conv (Conv2D)    (None, 14, 14, 1344) 301056      block5g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5h_expand_bn (BatchNormali (None, 14, 14, 1344) 5376        block5h_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5h_expand_activation (Acti (None, 14, 14, 1344) 0           block5h_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5h_dwconv (DepthwiseConv2D (None, 14, 14, 1344) 33600       block5h_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5h_bn (BatchNormalization) (None, 14, 14, 1344) 5376        block5h_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5h_activation (Activation) (None, 14, 14, 1344) 0           block5h_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_squeeze (GlobalAvera (None, 1344)         0           block5h_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5h_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5h_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5h_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5h_se_excite (Multiply)    (None, 14, 14, 1344) 0           block5h_activation[0][0]         \n",
      "                                                                 block5h_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5h_project_conv (Conv2D)   (None, 14, 14, 224)  301056      block5h_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5h_project_bn (BatchNormal (None, 14, 14, 224)  896         block5h_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5h_drop (Dropout)          (None, 14, 14, 224)  0           block5h_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5h_add (Add)               (None, 14, 14, 224)  0           block5h_drop[0][0]               \n",
      "                                                                 block5g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5i_expand_conv (Conv2D)    (None, 14, 14, 1344) 301056      block5h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5i_expand_bn (BatchNormali (None, 14, 14, 1344) 5376        block5i_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5i_expand_activation (Acti (None, 14, 14, 1344) 0           block5i_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5i_dwconv (DepthwiseConv2D (None, 14, 14, 1344) 33600       block5i_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5i_bn (BatchNormalization) (None, 14, 14, 1344) 5376        block5i_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5i_activation (Activation) (None, 14, 14, 1344) 0           block5i_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5i_se_squeeze (GlobalAvera (None, 1344)         0           block5i_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5i_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5i_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5i_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5i_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5i_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5i_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5i_se_excite (Multiply)    (None, 14, 14, 1344) 0           block5i_activation[0][0]         \n",
      "                                                                 block5i_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5i_project_conv (Conv2D)   (None, 14, 14, 224)  301056      block5i_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5i_project_bn (BatchNormal (None, 14, 14, 224)  896         block5i_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5i_drop (Dropout)          (None, 14, 14, 224)  0           block5i_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5i_add (Add)               (None, 14, 14, 224)  0           block5i_drop[0][0]               \n",
      "                                                                 block5h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5j_expand_conv (Conv2D)    (None, 14, 14, 1344) 301056      block5i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5j_expand_bn (BatchNormali (None, 14, 14, 1344) 5376        block5j_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5j_expand_activation (Acti (None, 14, 14, 1344) 0           block5j_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5j_dwconv (DepthwiseConv2D (None, 14, 14, 1344) 33600       block5j_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5j_bn (BatchNormalization) (None, 14, 14, 1344) 5376        block5j_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5j_activation (Activation) (None, 14, 14, 1344) 0           block5j_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5j_se_squeeze (GlobalAvera (None, 1344)         0           block5j_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5j_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block5j_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5j_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block5j_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5j_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block5j_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5j_se_excite (Multiply)    (None, 14, 14, 1344) 0           block5j_activation[0][0]         \n",
      "                                                                 block5j_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5j_project_conv (Conv2D)   (None, 14, 14, 224)  301056      block5j_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5j_project_bn (BatchNormal (None, 14, 14, 224)  896         block5j_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5j_drop (Dropout)          (None, 14, 14, 224)  0           block5j_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5j_add (Add)               (None, 14, 14, 224)  0           block5j_drop[0][0]               \n",
      "                                                                 block5i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 14, 14, 1344) 301056      block5j_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 14, 14, 1344) 5376        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 14, 14, 1344) 0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv_pad (ZeroPadding (None, 17, 17, 1344) 0           block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 7, 7, 1344)   33600       block6a_dwconv_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 7, 7, 1344)   5376        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 7, 7, 1344)   0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 1344)         0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 1344)   0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 56)     75320       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 1344)   76608       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 7, 7, 1344)   0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 7, 7, 384)    516096      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 7, 7, 384)    1536        block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 7, 7, 2304)   884736      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 7, 7, 2304)   9216        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 7, 7, 2304)   0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 7, 7, 2304)   57600       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 7, 7, 2304)   9216        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 7, 7, 2304)   0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 2304)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 7, 7, 2304)   0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 7, 7, 384)    884736      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 7, 7, 384)    1536        block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (Dropout)          (None, 7, 7, 384)    0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 7, 7, 384)    0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 7, 7, 2304)   884736      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 7, 7, 2304)   9216        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 7, 7, 2304)   0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 7, 7, 2304)   57600       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 7, 7, 2304)   9216        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 7, 7, 2304)   0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 2304)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 7, 7, 2304)   0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 7, 7, 384)    884736      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 7, 7, 384)    1536        block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (Dropout)          (None, 7, 7, 384)    0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 7, 7, 384)    0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 7, 7, 2304)   884736      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 7, 7, 2304)   9216        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 7, 7, 2304)   0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 7, 7, 2304)   57600       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 7, 7, 2304)   9216        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 7, 7, 2304)   0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 2304)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 7, 7, 2304)   0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 7, 7, 384)    884736      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 7, 7, 384)    1536        block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (Dropout)          (None, 7, 7, 384)    0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 7, 7, 384)    0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_conv (Conv2D)    (None, 7, 7, 2304)   884736      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_bn (BatchNormali (None, 7, 7, 2304)   9216        block6e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_activation (Acti (None, 7, 7, 2304)   0           block6e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_dwconv (DepthwiseConv2D (None, 7, 7, 2304)   57600       block6e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6e_bn (BatchNormalization) (None, 7, 7, 2304)   9216        block6e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6e_activation (Activation) (None, 7, 7, 2304)   0           block6e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_squeeze (GlobalAvera (None, 2304)         0           block6e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_excite (Multiply)    (None, 7, 7, 2304)   0           block6e_activation[0][0]         \n",
      "                                                                 block6e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_conv (Conv2D)   (None, 7, 7, 384)    884736      block6e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_bn (BatchNormal (None, 7, 7, 384)    1536        block6e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6e_drop (Dropout)          (None, 7, 7, 384)    0           block6e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_add (Add)               (None, 7, 7, 384)    0           block6e_drop[0][0]               \n",
      "                                                                 block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_conv (Conv2D)    (None, 7, 7, 2304)   884736      block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_bn (BatchNormali (None, 7, 7, 2304)   9216        block6f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_activation (Acti (None, 7, 7, 2304)   0           block6f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_dwconv (DepthwiseConv2D (None, 7, 7, 2304)   57600       block6f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6f_bn (BatchNormalization) (None, 7, 7, 2304)   9216        block6f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6f_activation (Activation) (None, 7, 7, 2304)   0           block6f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_squeeze (GlobalAvera (None, 2304)         0           block6f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_excite (Multiply)    (None, 7, 7, 2304)   0           block6f_activation[0][0]         \n",
      "                                                                 block6f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_conv (Conv2D)   (None, 7, 7, 384)    884736      block6f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_bn (BatchNormal (None, 7, 7, 384)    1536        block6f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6f_drop (Dropout)          (None, 7, 7, 384)    0           block6f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_add (Add)               (None, 7, 7, 384)    0           block6f_drop[0][0]               \n",
      "                                                                 block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_conv (Conv2D)    (None, 7, 7, 2304)   884736      block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_bn (BatchNormali (None, 7, 7, 2304)   9216        block6g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_activation (Acti (None, 7, 7, 2304)   0           block6g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_dwconv (DepthwiseConv2D (None, 7, 7, 2304)   57600       block6g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6g_bn (BatchNormalization) (None, 7, 7, 2304)   9216        block6g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6g_activation (Activation) (None, 7, 7, 2304)   0           block6g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_squeeze (GlobalAvera (None, 2304)         0           block6g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_excite (Multiply)    (None, 7, 7, 2304)   0           block6g_activation[0][0]         \n",
      "                                                                 block6g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_project_conv (Conv2D)   (None, 7, 7, 384)    884736      block6g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_project_bn (BatchNormal (None, 7, 7, 384)    1536        block6g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6g_drop (Dropout)          (None, 7, 7, 384)    0           block6g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_add (Add)               (None, 7, 7, 384)    0           block6g_drop[0][0]               \n",
      "                                                                 block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_conv (Conv2D)    (None, 7, 7, 2304)   884736      block6g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_bn (BatchNormali (None, 7, 7, 2304)   9216        block6h_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_activation (Acti (None, 7, 7, 2304)   0           block6h_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_dwconv (DepthwiseConv2D (None, 7, 7, 2304)   57600       block6h_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6h_bn (BatchNormalization) (None, 7, 7, 2304)   9216        block6h_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6h_activation (Activation) (None, 7, 7, 2304)   0           block6h_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_squeeze (GlobalAvera (None, 2304)         0           block6h_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6h_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6h_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6h_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_excite (Multiply)    (None, 7, 7, 2304)   0           block6h_activation[0][0]         \n",
      "                                                                 block6h_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_project_conv (Conv2D)   (None, 7, 7, 384)    884736      block6h_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_project_bn (BatchNormal (None, 7, 7, 384)    1536        block6h_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6h_drop (Dropout)          (None, 7, 7, 384)    0           block6h_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_add (Add)               (None, 7, 7, 384)    0           block6h_drop[0][0]               \n",
      "                                                                 block6g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_conv (Conv2D)    (None, 7, 7, 2304)   884736      block6h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_bn (BatchNormali (None, 7, 7, 2304)   9216        block6i_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6i_expand_activation (Acti (None, 7, 7, 2304)   0           block6i_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_dwconv (DepthwiseConv2D (None, 7, 7, 2304)   57600       block6i_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6i_bn (BatchNormalization) (None, 7, 7, 2304)   9216        block6i_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6i_activation (Activation) (None, 7, 7, 2304)   0           block6i_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_squeeze (GlobalAvera (None, 2304)         0           block6i_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6i_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6i_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6i_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_se_excite (Multiply)    (None, 7, 7, 2304)   0           block6i_activation[0][0]         \n",
      "                                                                 block6i_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_project_conv (Conv2D)   (None, 7, 7, 384)    884736      block6i_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6i_project_bn (BatchNormal (None, 7, 7, 384)    1536        block6i_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6i_drop (Dropout)          (None, 7, 7, 384)    0           block6i_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6i_add (Add)               (None, 7, 7, 384)    0           block6i_drop[0][0]               \n",
      "                                                                 block6h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6j_expand_conv (Conv2D)    (None, 7, 7, 2304)   884736      block6i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6j_expand_bn (BatchNormali (None, 7, 7, 2304)   9216        block6j_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6j_expand_activation (Acti (None, 7, 7, 2304)   0           block6j_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6j_dwconv (DepthwiseConv2D (None, 7, 7, 2304)   57600       block6j_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6j_bn (BatchNormalization) (None, 7, 7, 2304)   9216        block6j_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6j_activation (Activation) (None, 7, 7, 2304)   0           block6j_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_squeeze (GlobalAvera (None, 2304)         0           block6j_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6j_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6j_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6j_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6j_se_excite (Multiply)    (None, 7, 7, 2304)   0           block6j_activation[0][0]         \n",
      "                                                                 block6j_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6j_project_conv (Conv2D)   (None, 7, 7, 384)    884736      block6j_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6j_project_bn (BatchNormal (None, 7, 7, 384)    1536        block6j_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6j_drop (Dropout)          (None, 7, 7, 384)    0           block6j_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6j_add (Add)               (None, 7, 7, 384)    0           block6j_drop[0][0]               \n",
      "                                                                 block6i_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6k_expand_conv (Conv2D)    (None, 7, 7, 2304)   884736      block6j_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6k_expand_bn (BatchNormali (None, 7, 7, 2304)   9216        block6k_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6k_expand_activation (Acti (None, 7, 7, 2304)   0           block6k_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6k_dwconv (DepthwiseConv2D (None, 7, 7, 2304)   57600       block6k_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6k_bn (BatchNormalization) (None, 7, 7, 2304)   9216        block6k_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6k_activation (Activation) (None, 7, 7, 2304)   0           block6k_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_squeeze (GlobalAvera (None, 2304)         0           block6k_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6k_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6k_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6k_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6k_se_excite (Multiply)    (None, 7, 7, 2304)   0           block6k_activation[0][0]         \n",
      "                                                                 block6k_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6k_project_conv (Conv2D)   (None, 7, 7, 384)    884736      block6k_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6k_project_bn (BatchNormal (None, 7, 7, 384)    1536        block6k_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6k_drop (Dropout)          (None, 7, 7, 384)    0           block6k_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6k_add (Add)               (None, 7, 7, 384)    0           block6k_drop[0][0]               \n",
      "                                                                 block6j_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6l_expand_conv (Conv2D)    (None, 7, 7, 2304)   884736      block6k_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6l_expand_bn (BatchNormali (None, 7, 7, 2304)   9216        block6l_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6l_expand_activation (Acti (None, 7, 7, 2304)   0           block6l_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6l_dwconv (DepthwiseConv2D (None, 7, 7, 2304)   57600       block6l_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6l_bn (BatchNormalization) (None, 7, 7, 2304)   9216        block6l_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6l_activation (Activation) (None, 7, 7, 2304)   0           block6l_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6l_se_squeeze (GlobalAvera (None, 2304)         0           block6l_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6l_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6l_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6l_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6l_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6l_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6l_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6l_se_excite (Multiply)    (None, 7, 7, 2304)   0           block6l_activation[0][0]         \n",
      "                                                                 block6l_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6l_project_conv (Conv2D)   (None, 7, 7, 384)    884736      block6l_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6l_project_bn (BatchNormal (None, 7, 7, 384)    1536        block6l_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6l_drop (Dropout)          (None, 7, 7, 384)    0           block6l_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6l_add (Add)               (None, 7, 7, 384)    0           block6l_drop[0][0]               \n",
      "                                                                 block6k_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6m_expand_conv (Conv2D)    (None, 7, 7, 2304)   884736      block6l_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6m_expand_bn (BatchNormali (None, 7, 7, 2304)   9216        block6m_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6m_expand_activation (Acti (None, 7, 7, 2304)   0           block6m_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6m_dwconv (DepthwiseConv2D (None, 7, 7, 2304)   57600       block6m_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6m_bn (BatchNormalization) (None, 7, 7, 2304)   9216        block6m_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6m_activation (Activation) (None, 7, 7, 2304)   0           block6m_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6m_se_squeeze (GlobalAvera (None, 2304)         0           block6m_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6m_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block6m_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6m_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block6m_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6m_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block6m_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6m_se_excite (Multiply)    (None, 7, 7, 2304)   0           block6m_activation[0][0]         \n",
      "                                                                 block6m_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6m_project_conv (Conv2D)   (None, 7, 7, 384)    884736      block6m_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6m_project_bn (BatchNormal (None, 7, 7, 384)    1536        block6m_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6m_drop (Dropout)          (None, 7, 7, 384)    0           block6m_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6m_add (Add)               (None, 7, 7, 384)    0           block6m_drop[0][0]               \n",
      "                                                                 block6l_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 7, 7, 2304)   884736      block6m_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 7, 7, 2304)   9216        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 7, 7, 2304)   0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 7, 7, 2304)   20736       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 7, 7, 2304)   9216        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 7, 7, 2304)   0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 2304)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 7, 7, 2304)   0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 7, 7, 640)    1474560     block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 7, 7, 640)    2560        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_conv (Conv2D)    (None, 7, 7, 3840)   2457600     block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_bn (BatchNormali (None, 7, 7, 3840)   15360       block7b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_activation (Acti (None, 7, 7, 3840)   0           block7b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_dwconv (DepthwiseConv2D (None, 7, 7, 3840)   34560       block7b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7b_bn (BatchNormalization) (None, 7, 7, 3840)   15360       block7b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7b_activation (Activation) (None, 7, 7, 3840)   0           block7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_squeeze (GlobalAvera (None, 3840)         0           block7b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reshape (Reshape)    (None, 1, 1, 3840)   0           block7b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reduce (Conv2D)      (None, 1, 1, 160)    614560      block7b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_expand (Conv2D)      (None, 1, 1, 3840)   618240      block7b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_excite (Multiply)    (None, 7, 7, 3840)   0           block7b_activation[0][0]         \n",
      "                                                                 block7b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_conv (Conv2D)   (None, 7, 7, 640)    2457600     block7b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_bn (BatchNormal (None, 7, 7, 640)    2560        block7b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_drop (Dropout)          (None, 7, 7, 640)    0           block7b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_add (Add)               (None, 7, 7, 640)    0           block7b_drop[0][0]               \n",
      "                                                                 block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_conv (Conv2D)    (None, 7, 7, 3840)   2457600     block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_bn (BatchNormali (None, 7, 7, 3840)   15360       block7c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7c_expand_activation (Acti (None, 7, 7, 3840)   0           block7c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_dwconv (DepthwiseConv2D (None, 7, 7, 3840)   34560       block7c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7c_bn (BatchNormalization) (None, 7, 7, 3840)   15360       block7c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7c_activation (Activation) (None, 7, 7, 3840)   0           block7c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_squeeze (GlobalAvera (None, 3840)         0           block7c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_reshape (Reshape)    (None, 1, 1, 3840)   0           block7c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_reduce (Conv2D)      (None, 1, 1, 160)    614560      block7c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_expand (Conv2D)      (None, 1, 1, 3840)   618240      block7c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_se_excite (Multiply)    (None, 7, 7, 3840)   0           block7c_activation[0][0]         \n",
      "                                                                 block7c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_project_conv (Conv2D)   (None, 7, 7, 640)    2457600     block7c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7c_project_bn (BatchNormal (None, 7, 7, 640)    2560        block7c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7c_drop (Dropout)          (None, 7, 7, 640)    0           block7c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7c_add (Add)               (None, 7, 7, 640)    0           block7c_drop[0][0]               \n",
      "                                                                 block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7d_expand_conv (Conv2D)    (None, 7, 7, 3840)   2457600     block7c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7d_expand_bn (BatchNormali (None, 7, 7, 3840)   15360       block7d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7d_expand_activation (Acti (None, 7, 7, 3840)   0           block7d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7d_dwconv (DepthwiseConv2D (None, 7, 7, 3840)   34560       block7d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7d_bn (BatchNormalization) (None, 7, 7, 3840)   15360       block7d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7d_activation (Activation) (None, 7, 7, 3840)   0           block7d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7d_se_squeeze (GlobalAvera (None, 3840)         0           block7d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7d_se_reshape (Reshape)    (None, 1, 1, 3840)   0           block7d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7d_se_reduce (Conv2D)      (None, 1, 1, 160)    614560      block7d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7d_se_expand (Conv2D)      (None, 1, 1, 3840)   618240      block7d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7d_se_excite (Multiply)    (None, 7, 7, 3840)   0           block7d_activation[0][0]         \n",
      "                                                                 block7d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7d_project_conv (Conv2D)   (None, 7, 7, 640)    2457600     block7d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7d_project_bn (BatchNormal (None, 7, 7, 640)    2560        block7d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7d_drop (Dropout)          (None, 7, 7, 640)    0           block7d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7d_add (Add)               (None, 7, 7, 640)    0           block7d_drop[0][0]               \n",
      "                                                                 block7c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 7, 7, 2560)   1638400     block7d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 7, 7, 2560)   10240       top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 7, 7, 2560)   0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "GAP-benchmark-onelayeroff-0_000 (None, 2560)         0           top_activation[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Dropout-benchmark-onelayeroff-0 (None, 2560)         0           GAP-benchmark-onelayeroff-0_0001E\n",
      "__________________________________________________________________________________________________\n",
      "Softmax-EfficientNetB7 (Dense)  (None, 199)          509639      Dropout-benchmark-onelayeroff-0_0\n",
      "==================================================================================================\n",
      "Total params: 64,607,326\n",
      "Trainable params: 64,296,599\n",
      "Non-trainable params: 310,727\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#PLOT THE MODEL STRUCTURE\n",
    "def get_teacher():\n",
    "    model = load_m(TEACHER_MODEL_PATH, TEACHER_NAME)\n",
    "    model.layers[-1].activation = None\n",
    "    if model != None:\n",
    "        print(\"TEACHER MODEL LOADED SUCCESSFULLY!\")\n",
    "\n",
    "    return model\n",
    "\n",
    "if get_teacher() != None: \n",
    "    print(\"PLEASE CHECK THE ENTIRE MODEL UP TO THE END\")\n",
    "    get_teacher().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f9ad21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38f9ad21",
    "outputId": "a31c3176-d2ba-45da-f3f3-6cf26cf30092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "299/299 [==============================] - 24s 56ms/step - loss: 15.4561 - accuracy: 0.9054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[15.456077575683594, 0.9053601622581482]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity Checker\n",
    "#Re-Create Data Generator\n",
    "_, (validation_generator, nb_validation_samples)  = create_data_generator(pre_process=teacher_preprocess)\n",
    "\n",
    "get_teacher().evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oLZIunKTxUOw",
   "metadata": {
    "id": "oLZIunKTxUOw"
   },
   "source": [
    "**Student Model :** Mini-MNV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ipq4UZWrypfR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ipq4UZWrypfR",
    "outputId": "71da1475-c7d4-435c-8732-7a7ce1bd5ba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLEASE CHECK THE ENTIRE MODEL UP TO THE END\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "Model: \"ablation_final-PROPOSEDMiniMobileNetV2-39\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 112, 112, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "GAP-ablation_finalPROPOSEDMiniM (None, 96)           0           block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Dropout-ablation_finalPROPOSEDM (None, 96)           0           GAP-ablation_finalPROPOSEDMiniMob\n",
      "__________________________________________________________________________________________________\n",
      "Softmax-PROPOSEDMiniMobileNetV2 (None, 199)          19303       Dropout-ablation_finalPROPOSEDMin\n",
      "==================================================================================================\n",
      "Total params: 577,959\n",
      "Trainable params: 561,831\n",
      "Non-trainable params: 16,128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#TRANSFER LEARNING\n",
    "def get_student(model_input):\n",
    "    model = load_m(PROPOSED_MODEL_PATH, MODEL_NAME)\n",
    "    model.layers[-1].activation = None\n",
    "    if model != None:\n",
    "        print(\"STUDENT MODEL SUCESSFULLY BUILT!\")\n",
    "    return model\n",
    "\n",
    "#PLOT THE MODEL STRUCTURE\n",
    "print(\"PLEASE CHECK THE ENTIRE MODEL UP TO THE END\")\n",
    "get_student(MODEL_INPUT).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "OKEhdQ64EltV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OKEhdQ64EltV",
    "outputId": "d2d3cd0c-a7b0-4088-aaac-b5f136854b03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIXED HYPERPARAMETERS\n",
      "---------------------\n",
      "BATCH_SIZE --> 4\n",
      "EPOCHS SET --> 30\n",
      "DROPOUT_RATE --> 0.5\n",
      "OPTIMIZER --> Adam \n",
      "\n",
      "HPO HYPERPARAMETERS\n",
      "--------------------\n",
      "TEMPERATURE --> [5, 2, 10]\n",
      "ALPHA --> [0.1, 0.3, 0.5]\n",
      "LEARNING_RATE --> [0.001, 0.01, 0.0001]\n"
     ]
    }
   ],
   "source": [
    "#FIXED HYPERPARAMETERS\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 30\n",
    "DROPOUT_RATE = 0.5\n",
    "OPTIMIZER = Adam\n",
    "\n",
    "#HPO HYPERPAMETERS\n",
    "TEMPERATURE = [5, 2, 10] \n",
    "ALPHA = [0.1, 0.3, 0.5]\n",
    "LEARNING_RATE = [0.001, 0.01, 0.0001]\n",
    "\n",
    "print(\"FIXED HYPERPARAMETERS\")\n",
    "print(\"---------------------\")\n",
    "\n",
    "print(\"BATCH_SIZE -->\", BATCH_SIZE)\n",
    "print(\"EPOCHS SET -->\", EPOCHS)\n",
    "print(\"DROPOUT_RATE -->\", DROPOUT_RATE)\n",
    "print(\"OPTIMIZER -->\", OPTIMIZER.__name__,\"\\n\")\n",
    "\n",
    "print(\"HPO HYPERPARAMETERS\")\n",
    "print(\"--------------------\")\n",
    "print(\"TEMPERATURE -->\", TEMPERATURE)\n",
    "print(\"ALPHA -->\", ALPHA)\n",
    "print(\"LEARNING_RATE -->\", LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Uz_O6RSX779P",
   "metadata": {
    "id": "Uz_O6RSX779P"
   },
   "source": [
    "**Training Student With KD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s9s8AG_Gt0aD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s9s8AG_Gt0aD",
    "outputId": "d7817308-f15a-4e35-af82-6ec111513971"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.1, 'lr': 0.001, 'temperature': 5}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 55s 97ms/step - accuracy: 0.0534 - student_loss: 4.8583 - distillation_loss: 0.3580 - loss: 0.8080 - val_accuracy: 0.0050 - val_student_loss: 44.9399\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 46s 92ms/step - accuracy: 0.1858 - student_loss: 3.5706 - distillation_loss: 0.3203 - loss: 0.6453 - val_accuracy: 0.0352 - val_student_loss: 43.4513\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 46s 92ms/step - accuracy: 0.3827 - student_loss: 2.5954 - distillation_loss: 0.2933 - loss: 0.5235 - val_accuracy: 0.0822 - val_student_loss: 33.8619\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 45s 91ms/step - accuracy: 0.5227 - student_loss: 1.8737 - distillation_loss: 0.2731 - loss: 0.4331 - val_accuracy: 0.1477 - val_student_loss: 23.0641\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 45s 91ms/step - accuracy: 0.6425 - student_loss: 1.4187 - distillation_loss: 0.2592 - loss: 0.3751 - val_accuracy: 0.1787 - val_student_loss: 11.3410\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 46s 92ms/step - accuracy: 0.7538 - student_loss: 1.0597 - distillation_loss: 0.2468 - loss: 0.3281 - val_accuracy: 0.2970 - val_student_loss: 8.5766\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 45s 91ms/step - accuracy: 0.8026 - student_loss: 0.8684 - distillation_loss: 0.2366 - loss: 0.2998 - val_accuracy: 0.5369 - val_student_loss: 0.8456\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 46s 92ms/step - accuracy: 0.8419 - student_loss: 0.7154 - distillation_loss: 0.2292 - loss: 0.2779 - val_accuracy: 0.5688 - val_student_loss: 4.5291\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 46s 93ms/step - accuracy: 0.8812 - student_loss: 0.5823 - distillation_loss: 0.2217 - loss: 0.2577 - val_accuracy: 0.5352 - val_student_loss: 6.5267\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 45s 90ms/step - accuracy: 0.8953 - student_loss: 0.5327 - distillation_loss: 0.2165 - loss: 0.2481 - val_accuracy: 0.7701 - val_student_loss: 3.0071\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 46s 92ms/step - accuracy: 0.9320 - student_loss: 0.4008 - distillation_loss: 0.2071 - loss: 0.2265 - val_accuracy: 0.7013 - val_student_loss: 4.2643\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 47s 94ms/step - accuracy: 0.9215 - student_loss: 0.4217 - distillation_loss: 0.2065 - loss: 0.2281 - val_accuracy: 0.7131 - val_student_loss: 2.7518\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.9617 - student_loss: 0.2697 - distillation_loss: 0.1906 - loss: 0.1985 - val_accuracy: 0.8633 - val_student_loss: 0.1824\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 46s 92ms/step - accuracy: 0.9653 - student_loss: 0.2500 - distillation_loss: 0.1859 - loss: 0.1923 - val_accuracy: 0.8792 - val_student_loss: 0.2358\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 46s 93ms/step - accuracy: 0.9799 - student_loss: 0.2064 - distillation_loss: 0.1811 - loss: 0.1837 - val_accuracy: 0.8305 - val_student_loss: 0.2941\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 46s 93ms/step - accuracy: 0.9804 - student_loss: 0.1915 - distillation_loss: 0.1774 - loss: 0.1788 - val_accuracy: 0.8549 - val_student_loss: 0.3912\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 46s 93ms/step - accuracy: 0.9859 - student_loss: 0.1657 - distillation_loss: 0.1723 - loss: 0.1717 - val_accuracy: 0.8700 - val_student_loss: 0.4216\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 46s 92ms/step - accuracy: 0.9849 - student_loss: 0.1575 - distillation_loss: 0.1697 - loss: 0.1685 - val_accuracy: 0.8582 - val_student_loss: 0.7505\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 46s 93ms/step - accuracy: 0.9894 - student_loss: 0.1328 - distillation_loss: 0.1647 - loss: 0.1615 - val_accuracy: 0.8700 - val_student_loss: 0.3784\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 44s 89ms/step - accuracy: 0.9889 - student_loss: 0.1246 - distillation_loss: 0.1638 - loss: 0.1599 - val_accuracy: 0.8767 - val_student_loss: 0.5311\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 46s 92ms/step - accuracy: 0.9935 - student_loss: 0.1146 - distillation_loss: 0.1615 - loss: 0.1568 - val_accuracy: 0.8784 - val_student_loss: 0.7899\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 45s 90ms/step - accuracy: 0.9909 - student_loss: 0.1338 - distillation_loss: 0.1609 - loss: 0.1582 - val_accuracy: 0.8767 - val_student_loss: 0.7853\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 45s 90ms/step - accuracy: 0.9924 - student_loss: 0.1282 - distillation_loss: 0.1607 - loss: 0.1574 - val_accuracy: 0.8851 - val_student_loss: 0.8359\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 46s 92ms/step - accuracy: 0.9919 - student_loss: 0.1141 - distillation_loss: 0.1599 - loss: 0.1553 - val_accuracy: 0.8893 - val_student_loss: 0.7637\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 45s 91ms/step - accuracy: 0.9950 - student_loss: 0.1150 - distillation_loss: 0.1583 - loss: 0.1540 - val_accuracy: 0.8918 - val_student_loss: 0.8317\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 46s 93ms/step - accuracy: 0.9904 - student_loss: 0.1229 - distillation_loss: 0.1593 - loss: 0.1556 - val_accuracy: 0.8901 - val_student_loss: 0.8982\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 46s 92ms/step - accuracy: 0.9950 - student_loss: 0.1104 - distillation_loss: 0.1580 - loss: 0.1532 - val_accuracy: 0.8909 - val_student_loss: 0.8564\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 46s 92ms/step - accuracy: 0.9940 - student_loss: 0.1158 - distillation_loss: 0.1581 - loss: 0.1538 - val_accuracy: 0.8918 - val_student_loss: 0.8106\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 46s 93ms/step - accuracy: 0.9930 - student_loss: 0.1208 - distillation_loss: 0.1577 - loss: 0.1540 - val_accuracy: 0.8943 - val_student_loss: 0.8358\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 47s 94ms/step - accuracy: 0.9940 - student_loss: 0.1092 - distillation_loss: 0.1560 - loss: 0.1513 - val_accuracy: 0.8926 - val_student_loss: 0.8056\n",
      "\n",
      "\n",
      "00:23:09 train_time\n",
      "\n",
      "1389.108068227768 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|██▉                                                                           | 1/27 [23:09<10:02:07, 1389.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.1, 'lr': 0.001, 'temperature': 2}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 52s 93ms/step - accuracy: 0.0287 - student_loss: 5.0462 - distillation_loss: 4.4375 - loss: 4.4984 - val_accuracy: 0.0159 - val_student_loss: 51.6682\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 46s 92ms/step - accuracy: 0.1138 - student_loss: 4.0137 - distillation_loss: 3.6406 - loss: 3.6779 - val_accuracy: 0.0210 - val_student_loss: 76.7497\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 45s 91ms/step - accuracy: 0.2392 - student_loss: 3.1276 - distillation_loss: 2.9281 - loss: 2.9480 - val_accuracy: 0.0092 - val_student_loss: 45.0405\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 46s 93ms/step - accuracy: 0.3706 - student_loss: 2.3587 - distillation_loss: 2.3189 - loss: 2.3229 - val_accuracy: 0.0210 - val_student_loss: 39.7653\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 46s 93ms/step - accuracy: 0.5524 - student_loss: 1.5447 - distillation_loss: 1.7379 - loss: 1.7185 - val_accuracy: 0.2735 - val_student_loss: 14.4384\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 46s 92ms/step - accuracy: 0.6485 - student_loss: 1.2033 - distillation_loss: 1.4373 - loss: 1.4139 - val_accuracy: 0.3716 - val_student_loss: 7.1052\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 45s 91ms/step - accuracy: 0.6939 - student_loss: 1.0164 - distillation_loss: 1.2902 - loss: 1.2628 - val_accuracy: 0.6267 - val_student_loss: 3.3953\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 46s 94ms/step - accuracy: 0.7412 - student_loss: 0.8593 - distillation_loss: 1.1323 - loss: 1.1050 - val_accuracy: 0.6275 - val_student_loss: 4.8008\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 46s 93ms/step - accuracy: 0.7971 - student_loss: 0.6903 - distillation_loss: 0.9790 - loss: 0.9501 - val_accuracy: 0.7072 - val_student_loss: 5.3455\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 46s 92ms/step - accuracy: 0.8061 - student_loss: 0.6294 - distillation_loss: 0.9336 - loss: 0.9032 - val_accuracy: 0.7273 - val_student_loss: 2.8814\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 46s 93ms/step - accuracy: 0.8384 - student_loss: 0.4931 - distillation_loss: 0.8000 - loss: 0.7693 - val_accuracy: 0.7450 - val_student_loss: 0.5999\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8515 - student_loss: 0.4933 - distillation_loss: 0.7999 - loss: 0.7693 - val_accuracy: 0.7634 - val_student_loss: 2.1787\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.8792 - student_loss: 0.3889 - distillation_loss: 0.7086 - loss: 0.6766 - val_accuracy: 0.6351 - val_student_loss: 0.0148\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.8892 - student_loss: 0.3564 - distillation_loss: 0.6686 - loss: 0.6374 - val_accuracy: 0.6242 - val_student_loss: 7.0231\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.9209 - student_loss: 0.2633 - distillation_loss: 0.5758 - loss: 0.5446 - val_accuracy: 0.7466 - val_student_loss: 5.0678\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 47s 94ms/step - accuracy: 0.9386 - student_loss: 0.2060 - distillation_loss: 0.5274 - loss: 0.4953 - val_accuracy: 0.7953 - val_student_loss: 1.1912\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 47s 94ms/step - accuracy: 0.9461 - student_loss: 0.1874 - distillation_loss: 0.4952 - loss: 0.4644 - val_accuracy: 0.8213 - val_student_loss: 0.7609\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 46s 93ms/step - accuracy: 0.9361 - student_loss: 0.2042 - distillation_loss: 0.5206 - loss: 0.4890 - val_accuracy: 0.7508 - val_student_loss: 0.2262\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 46s 93ms/step - accuracy: 0.9416 - student_loss: 0.1866 - distillation_loss: 0.4943 - loss: 0.4635 - val_accuracy: 0.8163 - val_student_loss: 0.0963\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 46s 92ms/step - accuracy: 0.9512 - student_loss: 0.1560 - distillation_loss: 0.4491 - loss: 0.4198 - val_accuracy: 0.8146 - val_student_loss: 0.6008\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 46s 93ms/step - accuracy: 0.9678 - student_loss: 0.1210 - distillation_loss: 0.4305 - loss: 0.3996 - val_accuracy: 0.8230 - val_student_loss: 0.0849\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 46s 92ms/step - accuracy: 0.9658 - student_loss: 0.1262 - distillation_loss: 0.4272 - loss: 0.3971 - val_accuracy: 0.8364 - val_student_loss: 0.0727\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 46s 92ms/step - accuracy: 0.9587 - student_loss: 0.1363 - distillation_loss: 0.4267 - loss: 0.3976 - val_accuracy: 0.8263 - val_student_loss: 0.0852\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 46s 92ms/step - accuracy: 0.9658 - student_loss: 0.1213 - distillation_loss: 0.4112 - loss: 0.3822 - val_accuracy: 0.8381 - val_student_loss: 0.0897\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 47s 94ms/step - accuracy: 0.9678 - student_loss: 0.1079 - distillation_loss: 0.3983 - loss: 0.3692 - val_accuracy: 0.8406 - val_student_loss: 0.6278\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 45s 91ms/step - accuracy: 0.9728 - student_loss: 0.1005 - distillation_loss: 0.3929 - loss: 0.3637 - val_accuracy: 0.8263 - val_student_loss: 0.2798\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 47s 94ms/step - accuracy: 0.9718 - student_loss: 0.1046 - distillation_loss: 0.3985 - loss: 0.3691 - val_accuracy: 0.8557 - val_student_loss: 0.3733\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 46s 92ms/step - accuracy: 0.9748 - student_loss: 0.0951 - distillation_loss: 0.3958 - loss: 0.3657 - val_accuracy: 0.8423 - val_student_loss: 0.1225\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 46s 93ms/step - accuracy: 0.9743 - student_loss: 0.1055 - distillation_loss: 0.3932 - loss: 0.3644 - val_accuracy: 0.8523 - val_student_loss: 0.5872\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.9758 - student_loss: 0.0791 - distillation_loss: 0.3614 - loss: 0.3331 - val_accuracy: 0.8633 - val_student_loss: 0.3322\n",
      "\n",
      "\n",
      "00:23:27 train_time\n",
      "\n",
      "1407.1363642215729 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▊                                                                         | 2/27 [46:37<9:43:28, 1400.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.1, 'lr': 0.001, 'temperature': 10}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 53s 94ms/step - accuracy: 0.0312 - student_loss: 4.9729 - distillation_loss: 0.0405 - loss: 0.5337 - val_accuracy: 0.0050 - val_student_loss: 27.9840\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 47s 95ms/step - accuracy: 0.1551 - student_loss: 3.8515 - distillation_loss: 0.0393 - loss: 0.4205 - val_accuracy: 0.0126 - val_student_loss: 47.8639\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 47s 95ms/step - accuracy: 0.3157 - student_loss: 2.8124 - distillation_loss: 0.0403 - loss: 0.3175 - val_accuracy: 0.0310 - val_student_loss: 34.3126\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 47s 94ms/step - accuracy: 0.4839 - student_loss: 2.0564 - distillation_loss: 0.0422 - loss: 0.2436 - val_accuracy: 0.1174 - val_student_loss: 12.1245\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.6229 - student_loss: 1.5238 - distillation_loss: 0.0435 - loss: 0.1915 - val_accuracy: 0.1435 - val_student_loss: 11.7978\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 46s 93ms/step - accuracy: 0.7170 - student_loss: 1.1834 - distillation_loss: 0.0443 - loss: 0.1582 - val_accuracy: 0.4027 - val_student_loss: 13.2133\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 46s 93ms/step - accuracy: 0.7754 - student_loss: 0.9622 - distillation_loss: 0.0448 - loss: 0.1365 - val_accuracy: 0.4698 - val_student_loss: 8.2316\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 47s 94ms/step - accuracy: 0.8313 - student_loss: 0.7661 - distillation_loss: 0.0452 - loss: 0.1173 - val_accuracy: 0.5982 - val_student_loss: 5.3273\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 47s 95ms/step - accuracy: 0.8429 - student_loss: 0.6812 - distillation_loss: 0.0451 - loss: 0.1087 - val_accuracy: 0.5285 - val_student_loss: 7.9975\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 46s 92ms/step - accuracy: 0.8827 - student_loss: 0.5942 - distillation_loss: 0.0448 - loss: 0.0997 - val_accuracy: 0.5604 - val_student_loss: 6.3262\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 46s 93ms/step - accuracy: 0.9361 - student_loss: 0.3831 - distillation_loss: 0.0442 - loss: 0.0781 - val_accuracy: 0.7810 - val_student_loss: 2.8222\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.9436 - student_loss: 0.3603 - distillation_loss: 0.0431 - loss: 0.0748 - val_accuracy: 0.8398 - val_student_loss: 0.4601\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 47s 94ms/step - accuracy: 0.9537 - student_loss: 0.3196 - distillation_loss: 0.0423 - loss: 0.0700 - val_accuracy: 0.7953 - val_student_loss: 1.0444\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.9562 - student_loss: 0.3099 - distillation_loss: 0.0419 - loss: 0.0687 - val_accuracy: 0.8414 - val_student_loss: 0.5717\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.9642 - student_loss: 0.2691 - distillation_loss: 0.0417 - loss: 0.0644 - val_accuracy: 0.8087 - val_student_loss: 2.2614\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.9698 - student_loss: 0.2622 - distillation_loss: 0.0412 - loss: 0.0633 - val_accuracy: 0.8297 - val_student_loss: 0.3119\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.9748 - student_loss: 0.2244 - distillation_loss: 0.0406 - loss: 0.0590 - val_accuracy: 0.8448 - val_student_loss: 1.4773\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.9829 - student_loss: 0.2054 - distillation_loss: 0.0400 - loss: 0.0565 - val_accuracy: 0.8750 - val_student_loss: 2.5245\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.9834 - student_loss: 0.1935 - distillation_loss: 0.0394 - loss: 0.0548 - val_accuracy: 0.8616 - val_student_loss: 0.3895\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.9884 - student_loss: 0.1882 - distillation_loss: 0.0390 - loss: 0.0539 - val_accuracy: 0.8817 - val_student_loss: 0.5537\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.9844 - student_loss: 0.1798 - distillation_loss: 0.0382 - loss: 0.0524 - val_accuracy: 0.8591 - val_student_loss: 0.4255\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.9864 - student_loss: 0.1708 - distillation_loss: 0.0381 - loss: 0.0514 - val_accuracy: 0.8633 - val_student_loss: 0.2970\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.9884 - student_loss: 0.1689 - distillation_loss: 0.0374 - loss: 0.0505 - val_accuracy: 0.8817 - val_student_loss: 0.3903\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.9930 - student_loss: 0.1408 - distillation_loss: 0.0371 - loss: 0.0475 - val_accuracy: 0.8792 - val_student_loss: 0.7564\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.9945 - student_loss: 0.1387 - distillation_loss: 0.0368 - loss: 0.0470 - val_accuracy: 0.8876 - val_student_loss: 0.7627\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.9930 - student_loss: 0.1390 - distillation_loss: 0.0363 - loss: 0.0466 - val_accuracy: 0.8876 - val_student_loss: 0.5952\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.9940 - student_loss: 0.1320 - distillation_loss: 0.0363 - loss: 0.0459 - val_accuracy: 0.8867 - val_student_loss: 0.9147\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.9940 - student_loss: 0.1374 - distillation_loss: 0.0363 - loss: 0.0464 - val_accuracy: 0.8909 - val_student_loss: 0.9933\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.9950 - student_loss: 0.1335 - distillation_loss: 0.0363 - loss: 0.0460 - val_accuracy: 0.8901 - val_student_loss: 1.1047\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.9950 - student_loss: 0.1227 - distillation_loss: 0.0359 - loss: 0.0446 - val_accuracy: 0.8935 - val_student_loss: 1.0659\n",
      "\n",
      "\n",
      "00:24:07 train_time\n",
      "\n",
      "1447.33056306839 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████████▌                                                                    | 3/27 [1:10:45<9:28:51, 1422.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.1, 'lr': 0.01, 'temperature': 5}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 55s 97ms/step - accuracy: 0.0116 - student_loss: 5.2307 - distillation_loss: 0.3696 - loss: 0.8557 - val_accuracy: 0.0050 - val_student_loss: 235.0770\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.0373 - student_loss: 4.6511 - distillation_loss: 0.3538 - loss: 0.7835 - val_accuracy: 0.0050 - val_student_loss: 224.0062\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.0851 - student_loss: 4.1207 - distillation_loss: 0.3432 - loss: 0.7209 - val_accuracy: 0.0050 - val_student_loss: 222.9656\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.1974 - student_loss: 3.2673 - distillation_loss: 0.3243 - loss: 0.6186 - val_accuracy: 0.0092 - val_student_loss: 68.6248\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.2946 - student_loss: 2.7167 - distillation_loss: 0.3143 - loss: 0.5545 - val_accuracy: 0.0227 - val_student_loss: 27.0508\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.3741 - student_loss: 2.3198 - distillation_loss: 0.3036 - loss: 0.5052 - val_accuracy: 0.0218 - val_student_loss: 14.6625\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.4733 - student_loss: 1.9771 - distillation_loss: 0.2952 - loss: 0.4634 - val_accuracy: 0.0570 - val_student_loss: 19.0008\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.5645 - student_loss: 1.6719 - distillation_loss: 0.2871 - loss: 0.4256 - val_accuracy: 0.1351 - val_student_loss: 11.4591\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.6229 - student_loss: 1.4597 - distillation_loss: 0.2795 - loss: 0.3975 - val_accuracy: 0.0914 - val_student_loss: 13.1039\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.6652 - student_loss: 1.2893 - distillation_loss: 0.2730 - loss: 0.3746 - val_accuracy: 0.1258 - val_student_loss: 14.4738\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.7835 - student_loss: 0.9253 - distillation_loss: 0.2556 - loss: 0.3226 - val_accuracy: 0.2685 - val_student_loss: 5.2426\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.8072 - student_loss: 0.8390 - distillation_loss: 0.2516 - loss: 0.3103 - val_accuracy: 0.2685 - val_student_loss: 5.5799\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.8439 - student_loss: 0.7118 - distillation_loss: 0.2437 - loss: 0.2905 - val_accuracy: 0.4446 - val_student_loss: 1.7788\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.8505 - student_loss: 0.6689 - distillation_loss: 0.2399 - loss: 0.2828 - val_accuracy: 0.4815 - val_student_loss: 1.2401\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.8751 - student_loss: 0.6200 - distillation_loss: 0.2370 - loss: 0.2753 - val_accuracy: 0.4547 - val_student_loss: 3.4092\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.8827 - student_loss: 0.5743 - distillation_loss: 0.2327 - loss: 0.2669 - val_accuracy: 0.3104 - val_student_loss: 3.6866\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.9209 - student_loss: 0.4451 - distillation_loss: 0.2231 - loss: 0.2453 - val_accuracy: 0.5831 - val_student_loss: 2.6898\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.9255 - student_loss: 0.4285 - distillation_loss: 0.2207 - loss: 0.2415 - val_accuracy: 0.6527 - val_student_loss: 2.0352\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.9320 - student_loss: 0.3865 - distillation_loss: 0.2167 - loss: 0.2337 - val_accuracy: 0.6955 - val_student_loss: 0.6537\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.9396 - student_loss: 0.3721 - distillation_loss: 0.2150 - loss: 0.2307 - val_accuracy: 0.6653 - val_student_loss: 1.2839\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.9386 - student_loss: 0.3677 - distillation_loss: 0.2119 - loss: 0.2275 - val_accuracy: 0.6720 - val_student_loss: 3.8691\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.9527 - student_loss: 0.3265 - distillation_loss: 0.2061 - loss: 0.2182 - val_accuracy: 0.7458 - val_student_loss: 3.0298\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.9562 - student_loss: 0.3059 - distillation_loss: 0.2053 - loss: 0.2154 - val_accuracy: 0.7357 - val_student_loss: 4.5160\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.9587 - student_loss: 0.2917 - distillation_loss: 0.2043 - loss: 0.2131 - val_accuracy: 0.7282 - val_student_loss: 3.3928\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.9663 - student_loss: 0.2685 - distillation_loss: 0.1990 - loss: 0.2060 - val_accuracy: 0.7844 - val_student_loss: 3.2605\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.9607 - student_loss: 0.2831 - distillation_loss: 0.2006 - loss: 0.2088 - val_accuracy: 0.7886 - val_student_loss: 3.4361\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.9668 - student_loss: 0.2590 - distillation_loss: 0.1982 - loss: 0.2043 - val_accuracy: 0.8029 - val_student_loss: 3.4333\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.9698 - student_loss: 0.2541 - distillation_loss: 0.1978 - loss: 0.2034 - val_accuracy: 0.8045 - val_student_loss: 3.6200\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 47s 94ms/step - accuracy: 0.9663 - student_loss: 0.2644 - distillation_loss: 0.1972 - loss: 0.2039 - val_accuracy: 0.7911 - val_student_loss: 3.2599\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.9809 - student_loss: 0.2200 - distillation_loss: 0.1942 - loss: 0.1968 - val_accuracy: 0.8263 - val_student_loss: 2.9602\n",
      "\n",
      "\n",
      "00:24:22 train_time\n",
      "\n",
      "1462.6823916435242 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|███████████▍                                                                 | 4/27 [1:35:09<9:11:25, 1438.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.1, 'lr': 0.01, 'temperature': 2}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 55s 98ms/step - accuracy: 0.0101 - student_loss: 5.5149 - distillation_loss: 4.6224 - loss: 4.7116 - val_accuracy: 0.0050 - val_student_loss: 266.9503\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.0267 - student_loss: 5.1754 - distillation_loss: 4.2226 - loss: 4.3179 - val_accuracy: 0.0059 - val_student_loss: 134.3954\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.0634 - student_loss: 4.7598 - distillation_loss: 3.8074 - loss: 3.9026 - val_accuracy: 0.0050 - val_student_loss: 136.7345\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.1133 - student_loss: 4.2939 - distillation_loss: 3.3765 - loss: 3.4682 - val_accuracy: 0.0076 - val_student_loss: 57.1678\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.1702 - student_loss: 3.8065 - distillation_loss: 3.0139 - loss: 3.0931 - val_accuracy: 0.0092 - val_student_loss: 103.5468\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.2377 - student_loss: 3.3776 - distillation_loss: 2.6744 - loss: 2.7447 - val_accuracy: 0.0050 - val_student_loss: 84.3319\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.3172 - student_loss: 3.0330 - distillation_loss: 2.4197 - loss: 2.4811 - val_accuracy: 0.0277 - val_student_loss: 58.8606\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.3802 - student_loss: 2.6574 - distillation_loss: 2.1578 - loss: 2.2077 - val_accuracy: 0.0076 - val_student_loss: 66.8131\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.4446 - student_loss: 2.3657 - distillation_loss: 1.9673 - loss: 2.0072 - val_accuracy: 0.0336 - val_student_loss: 60.9871\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.4668 - student_loss: 2.2390 - distillation_loss: 1.8687 - loss: 1.9057 - val_accuracy: 0.0176 - val_student_loss: 38.2577\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 48s 98ms/step - accuracy: 0.5242 - student_loss: 1.9649 - distillation_loss: 1.6802 - loss: 1.7087 - val_accuracy: 0.0201 - val_student_loss: 40.6451\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.6344 - student_loss: 1.4053 - distillation_loss: 1.3675 - loss: 1.3712 - val_accuracy: 0.1158 - val_student_loss: 30.3136\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.6858 - student_loss: 1.0930 - distillation_loss: 1.1754 - loss: 1.1672 - val_accuracy: 0.1342 - val_student_loss: 26.9222\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.7276 - student_loss: 1.0220 - distillation_loss: 1.1140 - loss: 1.1048 - val_accuracy: 0.2357 - val_student_loss: 15.5050\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.7251 - student_loss: 0.9541 - distillation_loss: 1.0781 - loss: 1.0657 - val_accuracy: 0.4430 - val_student_loss: 10.8925\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 47s 94ms/step - accuracy: 0.7528 - student_loss: 0.9166 - distillation_loss: 1.0316 - loss: 1.0201 - val_accuracy: 0.4060 - val_student_loss: 9.4967\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.7568 - student_loss: 0.8686 - distillation_loss: 1.0145 - loss: 0.9999 - val_accuracy: 0.3935 - val_student_loss: 19.2082\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.7941 - student_loss: 0.6651 - distillation_loss: 0.8754 - loss: 0.8544 - val_accuracy: 0.5134 - val_student_loss: 10.7187\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.8197 - student_loss: 0.5713 - distillation_loss: 0.8155 - loss: 0.7910 - val_accuracy: 0.5210 - val_student_loss: 12.9268\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.8525 - student_loss: 0.4930 - distillation_loss: 0.7688 - loss: 0.7412 - val_accuracy: 0.5461 - val_student_loss: 13.7748\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.8424 - student_loss: 0.5320 - distillation_loss: 0.7794 - loss: 0.7547 - val_accuracy: 0.5831 - val_student_loss: 5.4888\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.8364 - student_loss: 0.5232 - distillation_loss: 0.7674 - loss: 0.7429 - val_accuracy: 0.5973 - val_student_loss: 2.5650\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.8691 - student_loss: 0.4428 - distillation_loss: 0.7194 - loss: 0.6917 - val_accuracy: 0.6225 - val_student_loss: 9.8314\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.8615 - student_loss: 0.4425 - distillation_loss: 0.7195 - loss: 0.6918 - val_accuracy: 0.5327 - val_student_loss: 6.7641\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.8771 - student_loss: 0.4042 - distillation_loss: 0.6895 - loss: 0.6610 - val_accuracy: 0.6065 - val_student_loss: 10.1897\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.8862 - student_loss: 0.3565 - distillation_loss: 0.6464 - loss: 0.6174 - val_accuracy: 0.6779 - val_student_loss: 10.5804\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.8943 - student_loss: 0.3300 - distillation_loss: 0.6307 - loss: 0.6006 - val_accuracy: 0.7122 - val_student_loss: 6.1717\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.9094 - student_loss: 0.2896 - distillation_loss: 0.6087 - loss: 0.5767 - val_accuracy: 0.6678 - val_student_loss: 10.5189\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.9114 - student_loss: 0.2988 - distillation_loss: 0.6145 - loss: 0.5829 - val_accuracy: 0.7349 - val_student_loss: 5.1535\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.9084 - student_loss: 0.2782 - distillation_loss: 0.5851 - loss: 0.5544 - val_accuracy: 0.7022 - val_student_loss: 6.6407\n",
      "\n",
      "\n",
      "00:24:18 train_time\n",
      "\n",
      "1458.7489001750946 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|██████████████▎                                                              | 5/27 [1:59:28<8:50:14, 1446.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.1, 'lr': 0.01, 'temperature': 10}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 56s 98ms/step - accuracy: 0.0111 - student_loss: 5.3129 - distillation_loss: 0.0417 - loss: 0.5688 - val_accuracy: 0.0050 - val_student_loss: 149.8640\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 47s 94ms/step - accuracy: 0.0307 - student_loss: 4.7831 - distillation_loss: 0.0426 - loss: 0.5166 - val_accuracy: 0.0050 - val_student_loss: 156.1295\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 47s 95ms/step - accuracy: 0.0665 - student_loss: 4.2846 - distillation_loss: 0.0446 - loss: 0.4686 - val_accuracy: 0.0050 - val_student_loss: 235.5710\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.1672 - student_loss: 3.4327 - distillation_loss: 0.0479 - loss: 0.3864 - val_accuracy: 0.0050 - val_student_loss: 119.3511\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.2759 - student_loss: 2.8990 - distillation_loss: 0.0510 - loss: 0.3358 - val_accuracy: 0.0109 - val_student_loss: 11.1616\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.3369 - student_loss: 2.5133 - distillation_loss: 0.0526 - loss: 0.2987 - val_accuracy: 0.0050 - val_student_loss: 38.0294\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.4084 - student_loss: 2.2104 - distillation_loss: 0.0539 - loss: 0.2695 - val_accuracy: 0.0050 - val_student_loss: 16.4339\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 47s 95ms/step - accuracy: 0.5468 - student_loss: 1.6737 - distillation_loss: 0.0550 - loss: 0.2169 - val_accuracy: 0.1518 - val_student_loss: 4.3418\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 47s 94ms/step - accuracy: 0.6133 - student_loss: 1.4244 - distillation_loss: 0.0554 - loss: 0.1923 - val_accuracy: 0.2282 - val_student_loss: 1.9524\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 47s 94ms/step - accuracy: 0.6521 - student_loss: 1.2779 - distillation_loss: 0.0564 - loss: 0.1786 - val_accuracy: 0.1065 - val_student_loss: 7.7735\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 47s 95ms/step - accuracy: 0.7004 - student_loss: 1.1176 - distillation_loss: 0.0566 - loss: 0.1627 - val_accuracy: 0.2928 - val_student_loss: 2.1565\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.7226 - student_loss: 1.0689 - distillation_loss: 0.0560 - loss: 0.1573 - val_accuracy: 0.3012 - val_student_loss: 9.1885\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.7633 - student_loss: 0.9380 - distillation_loss: 0.0560 - loss: 0.1442 - val_accuracy: 0.3482 - val_student_loss: 2.8065\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.7870 - student_loss: 0.8399 - distillation_loss: 0.0558 - loss: 0.1342 - val_accuracy: 0.2894 - val_student_loss: 2.2862\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 47s 95ms/step - accuracy: 0.8102 - student_loss: 0.7978 - distillation_loss: 0.0553 - loss: 0.1296 - val_accuracy: 0.1904 - val_student_loss: 6.8218\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.8434 - student_loss: 0.6441 - distillation_loss: 0.0540 - loss: 0.1130 - val_accuracy: 0.4807 - val_student_loss: 3.2944\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 47s 95ms/step - accuracy: 0.8721 - student_loss: 0.5874 - distillation_loss: 0.0531 - loss: 0.1065 - val_accuracy: 0.5159 - val_student_loss: 3.4243\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 47s 95ms/step - accuracy: 0.8771 - student_loss: 0.5692 - distillation_loss: 0.0526 - loss: 0.1043 - val_accuracy: 0.4975 - val_student_loss: 2.5277\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.8902 - student_loss: 0.5433 - distillation_loss: 0.0516 - loss: 0.1008 - val_accuracy: 0.4849 - val_student_loss: 5.8769\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.9089 - student_loss: 0.4746 - distillation_loss: 0.0514 - loss: 0.0937 - val_accuracy: 0.6208 - val_student_loss: 4.1007\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.9089 - student_loss: 0.4489 - distillation_loss: 0.0511 - loss: 0.0909 - val_accuracy: 0.6401 - val_student_loss: 4.1521\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.9245 - student_loss: 0.4280 - distillation_loss: 0.0507 - loss: 0.0884 - val_accuracy: 0.6569 - val_student_loss: 5.3233\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.9320 - student_loss: 0.4180 - distillation_loss: 0.0501 - loss: 0.0869 - val_accuracy: 0.6653 - val_student_loss: 4.9232\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.9391 - student_loss: 0.3852 - distillation_loss: 0.0501 - loss: 0.0836 - val_accuracy: 0.6888 - val_student_loss: 5.1559\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.9340 - student_loss: 0.3935 - distillation_loss: 0.0494 - loss: 0.0838 - val_accuracy: 0.6359 - val_student_loss: 4.1810\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.9366 - student_loss: 0.3773 - distillation_loss: 0.0492 - loss: 0.0820 - val_accuracy: 0.6988 - val_student_loss: 4.3913\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.9386 - student_loss: 0.3781 - distillation_loss: 0.0485 - loss: 0.0815 - val_accuracy: 0.7097 - val_student_loss: 3.4706\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.9451 - student_loss: 0.3599 - distillation_loss: 0.0485 - loss: 0.0796 - val_accuracy: 0.6435 - val_student_loss: 3.7800\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.9366 - student_loss: 0.3651 - distillation_loss: 0.0484 - loss: 0.0801 - val_accuracy: 0.6636 - val_student_loss: 3.6966\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.9522 - student_loss: 0.3127 - distillation_loss: 0.0476 - loss: 0.0741 - val_accuracy: 0.7181 - val_student_loss: 3.4913\n",
      "\n",
      "\n",
      "00:24:13 train_time\n",
      "\n",
      "1453.5725905895233 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████                                                            | 6/27 [2:23:43<8:27:08, 1448.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.1, 'lr': 0.0001, 'temperature': 5}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 56s 100ms/step - accuracy: 0.0171 - student_loss: 5.2504 - distillation_loss: 0.3707 - loss: 0.8586 - val_accuracy: 0.0101 - val_student_loss: 5.3968\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.0519 - student_loss: 4.8971 - distillation_loss: 0.3602 - loss: 0.8139 - val_accuracy: 0.0193 - val_student_loss: 5.8534\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.0785 - student_loss: 4.5619 - distillation_loss: 0.3498 - loss: 0.7710 - val_accuracy: 0.0512 - val_student_loss: 4.0267\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.1501 - student_loss: 4.1878 - distillation_loss: 0.3392 - loss: 0.7240 - val_accuracy: 0.0419 - val_student_loss: 3.8650\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.2080 - student_loss: 3.8467 - distillation_loss: 0.3297 - loss: 0.6814 - val_accuracy: 0.1552 - val_student_loss: 2.4865\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 49s 100ms/step - accuracy: 0.2664 - student_loss: 3.4858 - distillation_loss: 0.3196 - loss: 0.6363 - val_accuracy: 0.2005 - val_student_loss: 3.3036\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.3298 - student_loss: 3.1735 - distillation_loss: 0.3113 - loss: 0.5975 - val_accuracy: 0.2508 - val_student_loss: 3.1167\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.3983 - student_loss: 2.8818 - distillation_loss: 0.3035 - loss: 0.5614 - val_accuracy: 0.3607 - val_student_loss: 1.2673\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 49s 100ms/step - accuracy: 0.4758 - student_loss: 2.5916 - distillation_loss: 0.2943 - loss: 0.5240 - val_accuracy: 0.2802 - val_student_loss: 2.3594\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.5025 - student_loss: 2.4123 - distillation_loss: 0.2890 - loss: 0.5013 - val_accuracy: 0.3180 - val_student_loss: 2.4898\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.5811 - student_loss: 2.0998 - distillation_loss: 0.2788 - loss: 0.4609 - val_accuracy: 0.4740 - val_student_loss: 1.9071\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.5821 - student_loss: 2.0329 - distillation_loss: 0.2778 - loss: 0.4533 - val_accuracy: 0.5227 - val_student_loss: 2.2464\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.6380 - student_loss: 1.9091 - distillation_loss: 0.2737 - loss: 0.4373 - val_accuracy: 0.5621 - val_student_loss: 1.7602\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.6813 - student_loss: 1.7722 - distillation_loss: 0.2693 - loss: 0.4196 - val_accuracy: 0.4673 - val_student_loss: 3.5032\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.7049 - student_loss: 1.6447 - distillation_loss: 0.2653 - loss: 0.4032 - val_accuracy: 0.6107 - val_student_loss: 2.6282\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.7090 - student_loss: 1.6124 - distillation_loss: 0.2646 - loss: 0.3994 - val_accuracy: 0.5948 - val_student_loss: 2.5688\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7356 - student_loss: 1.5147 - distillation_loss: 0.2604 - loss: 0.3858 - val_accuracy: 0.6527 - val_student_loss: 1.9236\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.7528 - student_loss: 1.4545 - distillation_loss: 0.2587 - loss: 0.3783 - val_accuracy: 0.4941 - val_student_loss: 3.0869\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.7578 - student_loss: 1.3837 - distillation_loss: 0.2563 - loss: 0.3691 - val_accuracy: 0.6586 - val_student_loss: 2.1457\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 48s 96ms/step - accuracy: 0.7840 - student_loss: 1.2834 - distillation_loss: 0.2530 - loss: 0.3561 - val_accuracy: 0.5906 - val_student_loss: 2.4002\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.8066 - student_loss: 1.2083 - distillation_loss: 0.2490 - loss: 0.3449 - val_accuracy: 0.4740 - val_student_loss: 3.7202\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 52s 105ms/step - accuracy: 0.8127 - student_loss: 1.1379 - distillation_loss: 0.2463 - loss: 0.3355 - val_accuracy: 0.6913 - val_student_loss: 1.5023\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 52s 105ms/step - accuracy: 0.8313 - student_loss: 1.0936 - distillation_loss: 0.2451 - loss: 0.3299 - val_accuracy: 0.7190 - val_student_loss: 1.3485\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 52s 105ms/step - accuracy: 0.8369 - student_loss: 1.0660 - distillation_loss: 0.2440 - loss: 0.3262 - val_accuracy: 0.6745 - val_student_loss: 1.4872\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 52s 105ms/step - accuracy: 0.8525 - student_loss: 1.0171 - distillation_loss: 0.2422 - loss: 0.3197 - val_accuracy: 0.6988 - val_student_loss: 2.0811\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 52s 105ms/step - accuracy: 0.8530 - student_loss: 0.9871 - distillation_loss: 0.2401 - loss: 0.3148 - val_accuracy: 0.7181 - val_student_loss: 1.8580\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 52s 105ms/step - accuracy: 0.8535 - student_loss: 0.9903 - distillation_loss: 0.2414 - loss: 0.3163 - val_accuracy: 0.6904 - val_student_loss: 2.0701\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 52s 106ms/step - accuracy: 0.8570 - student_loss: 0.9573 - distillation_loss: 0.2394 - loss: 0.3112 - val_accuracy: 0.7039 - val_student_loss: 1.7928\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 53s 106ms/step - accuracy: 0.8535 - student_loss: 0.9696 - distillation_loss: 0.2392 - loss: 0.3122 - val_accuracy: 0.7198 - val_student_loss: 1.6779\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 52s 104ms/step - accuracy: 0.8666 - student_loss: 0.9467 - distillation_loss: 0.2388 - loss: 0.3096 - val_accuracy: 0.7215 - val_student_loss: 1.5981\n",
      "\n",
      "\n",
      "00:25:15 train_time\n",
      "\n",
      "1515.9642758369446 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|███████████████████▉                                                         | 7/27 [2:49:00<8:10:23, 1471.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.1, 'lr': 0.0001, 'temperature': 2}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 59s 105ms/step - accuracy: 0.0116 - student_loss: 5.2900 - distillation_loss: 4.6385 - loss: 4.7037 - val_accuracy: 0.0101 - val_student_loss: 6.2827\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 52s 105ms/step - accuracy: 0.0468 - student_loss: 4.9210 - distillation_loss: 4.4485 - loss: 4.4958 - val_accuracy: 0.0176 - val_student_loss: 6.2073\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 52s 105ms/step - accuracy: 0.0700 - student_loss: 4.5458 - distillation_loss: 4.2307 - loss: 4.2622 - val_accuracy: 0.0319 - val_student_loss: 5.9486\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 52s 104ms/step - accuracy: 0.1108 - student_loss: 4.2119 - distillation_loss: 4.0144 - loss: 4.0341 - val_accuracy: 0.0898 - val_student_loss: 6.0387\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 52s 104ms/step - accuracy: 0.1606 - student_loss: 3.8753 - distillation_loss: 3.7941 - loss: 3.8022 - val_accuracy: 0.0747 - val_student_loss: 5.9511\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 52s 105ms/step - accuracy: 0.2130 - student_loss: 3.5392 - distillation_loss: 3.5659 - loss: 3.5632 - val_accuracy: 0.0512 - val_student_loss: 7.3004\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 52s 105ms/step - accuracy: 0.2422 - student_loss: 3.2497 - distillation_loss: 3.3784 - loss: 3.3656 - val_accuracy: 0.0973 - val_student_loss: 3.6622\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 52s 104ms/step - accuracy: 0.2815 - student_loss: 3.0722 - distillation_loss: 3.2587 - loss: 3.2401 - val_accuracy: 0.1636 - val_student_loss: 3.2004\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 52s 104ms/step - accuracy: 0.3102 - student_loss: 2.8915 - distillation_loss: 3.1290 - loss: 3.1052 - val_accuracy: 0.1351 - val_student_loss: 5.7540\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 52s 104ms/step - accuracy: 0.3197 - student_loss: 2.7940 - distillation_loss: 3.0632 - loss: 3.0363 - val_accuracy: 0.2190 - val_student_loss: 3.9696\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 52s 105ms/step - accuracy: 0.3656 - student_loss: 2.6166 - distillation_loss: 2.9373 - loss: 2.9053 - val_accuracy: 0.1871 - val_student_loss: 5.8371\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 52s 104ms/step - accuracy: 0.3882 - student_loss: 2.5550 - distillation_loss: 2.8749 - loss: 2.8430 - val_accuracy: 0.2668 - val_student_loss: 1.5914\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 52s 104ms/step - accuracy: 0.4048 - student_loss: 2.4017 - distillation_loss: 2.7630 - loss: 2.7269 - val_accuracy: 0.2995 - val_student_loss: 1.8316\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 52s 104ms/step - accuracy: 0.4416 - student_loss: 2.2979 - distillation_loss: 2.6862 - loss: 2.6474 - val_accuracy: 0.3591 - val_student_loss: 1.3165\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 52s 105ms/step - accuracy: 0.4481 - student_loss: 2.2027 - distillation_loss: 2.5973 - loss: 2.5579 - val_accuracy: 0.2802 - val_student_loss: 2.5930\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 52s 104ms/step - accuracy: 0.4642 - student_loss: 2.1156 - distillation_loss: 2.5448 - loss: 2.5019 - val_accuracy: 0.4606 - val_student_loss: 2.0782\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 52s 104ms/step - accuracy: 0.5025 - student_loss: 1.9313 - distillation_loss: 2.4191 - loss: 2.3703 - val_accuracy: 0.2114 - val_student_loss: 4.2954\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 52s 104ms/step - accuracy: 0.5171 - student_loss: 1.8810 - distillation_loss: 2.3652 - loss: 2.3168 - val_accuracy: 0.4379 - val_student_loss: 2.5707\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 52s 105ms/step - accuracy: 0.5478 - student_loss: 1.7887 - distillation_loss: 2.2897 - loss: 2.2396 - val_accuracy: 0.4849 - val_student_loss: 1.8895\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 52s 105ms/step - accuracy: 0.5634 - student_loss: 1.6839 - distillation_loss: 2.2011 - loss: 2.1494 - val_accuracy: 0.5285 - val_student_loss: 1.3578\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 52s 104ms/step - accuracy: 0.5745 - student_loss: 1.6158 - distillation_loss: 2.1529 - loss: 2.0992 - val_accuracy: 0.5227 - val_student_loss: 1.4237\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 52s 104ms/step - accuracy: 0.5891 - student_loss: 1.5900 - distillation_loss: 2.1246 - loss: 2.0711 - val_accuracy: 0.5008 - val_student_loss: 1.1899\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 52s 104ms/step - accuracy: 0.6042 - student_loss: 1.5597 - distillation_loss: 2.1072 - loss: 2.0525 - val_accuracy: 0.5738 - val_student_loss: 1.4066\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 52s 104ms/step - accuracy: 0.6118 - student_loss: 1.5322 - distillation_loss: 2.0820 - loss: 2.0270 - val_accuracy: 0.6065 - val_student_loss: 1.4459\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 53s 106ms/step - accuracy: 0.6052 - student_loss: 1.5002 - distillation_loss: 2.0533 - loss: 1.9980 - val_accuracy: 0.5923 - val_student_loss: 1.7477\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 52s 104ms/step - accuracy: 0.5972 - student_loss: 1.5240 - distillation_loss: 2.0602 - loss: 2.0066 - val_accuracy: 0.6057 - val_student_loss: 1.5143\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 52s 104ms/step - accuracy: 0.6133 - student_loss: 1.4651 - distillation_loss: 2.0189 - loss: 1.9635 - val_accuracy: 0.6116 - val_student_loss: 1.6438\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 52s 104ms/step - accuracy: 0.6057 - student_loss: 1.4684 - distillation_loss: 2.0188 - loss: 1.9637 - val_accuracy: 0.5982 - val_student_loss: 1.6832\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 52s 104ms/step - accuracy: 0.6208 - student_loss: 1.4580 - distillation_loss: 2.0121 - loss: 1.9567 - val_accuracy: 0.6057 - val_student_loss: 1.6199\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 52s 104ms/step - accuracy: 0.6536 - student_loss: 1.3782 - distillation_loss: 1.9573 - loss: 1.8994 - val_accuracy: 0.6074 - val_student_loss: 1.6475\n",
      "\n",
      "\n",
      "00:26:09 train_time\n",
      "\n",
      "1569.1877455711365 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██████████████████████▊                                                      | 8/27 [3:15:10<7:55:50, 1502.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.1, 'lr': 0.0001, 'temperature': 10}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 58s 105ms/step - accuracy: 0.0111 - student_loss: 5.2634 - distillation_loss: 0.0411 - loss: 0.5633 - val_accuracy: 0.0134 - val_student_loss: 5.1845\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 53s 106ms/step - accuracy: 0.0433 - student_loss: 4.9145 - distillation_loss: 0.0399 - loss: 0.5274 - val_accuracy: 0.0193 - val_student_loss: 5.2144\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 52s 104ms/step - accuracy: 0.0937 - student_loss: 4.6088 - distillation_loss: 0.0392 - loss: 0.4962 - val_accuracy: 0.0604 - val_student_loss: 4.6370\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 52s 105ms/step - accuracy: 0.1370 - student_loss: 4.2400 - distillation_loss: 0.0386 - loss: 0.4588 - val_accuracy: 0.0755 - val_student_loss: 4.6356\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.1903 - student_loss: 3.9290 - distillation_loss: 0.0383 - loss: 0.4274 - val_accuracy: 0.0965 - val_student_loss: 3.9054\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.2659 - student_loss: 3.5539 - distillation_loss: 0.0380 - loss: 0.3896 - val_accuracy: 0.1133 - val_student_loss: 3.7478\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.3102 - student_loss: 3.2842 - distillation_loss: 0.0377 - loss: 0.3624 - val_accuracy: 0.1200 - val_student_loss: 4.4121\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.3933 - student_loss: 2.9533 - distillation_loss: 0.0376 - loss: 0.3291 - val_accuracy: 0.1426 - val_student_loss: 4.7928\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.4512 - student_loss: 2.7079 - distillation_loss: 0.0374 - loss: 0.3044 - val_accuracy: 0.1258 - val_student_loss: 6.7046\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.4985 - student_loss: 2.5040 - distillation_loss: 0.0374 - loss: 0.2841 - val_accuracy: 0.3826 - val_student_loss: 3.9477\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.5559 - student_loss: 2.2437 - distillation_loss: 0.0371 - loss: 0.2577 - val_accuracy: 0.4161 - val_student_loss: 4.2934\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.5982 - student_loss: 2.0558 - distillation_loss: 0.0373 - loss: 0.2392 - val_accuracy: 0.3859 - val_student_loss: 3.7845\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.6450 - student_loss: 1.8651 - distillation_loss: 0.0374 - loss: 0.2202 - val_accuracy: 0.3901 - val_student_loss: 3.7695\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6853 - student_loss: 1.6713 - distillation_loss: 0.0372 - loss: 0.2006 - val_accuracy: 0.4815 - val_student_loss: 2.7868\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7382 - student_loss: 1.5152 - distillation_loss: 0.0372 - loss: 0.1850 - val_accuracy: 0.5302 - val_student_loss: 2.8077\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7341 - student_loss: 1.4763 - distillation_loss: 0.0373 - loss: 0.1812 - val_accuracy: 0.5671 - val_student_loss: 3.2804\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.7588 - student_loss: 1.4188 - distillation_loss: 0.0372 - loss: 0.1753 - val_accuracy: 0.6401 - val_student_loss: 2.1325\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7759 - student_loss: 1.3583 - distillation_loss: 0.0374 - loss: 0.1695 - val_accuracy: 0.6032 - val_student_loss: 2.6175\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7784 - student_loss: 1.2809 - distillation_loss: 0.0372 - loss: 0.1616 - val_accuracy: 0.5948 - val_student_loss: 2.4191\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8197 - student_loss: 1.1686 - distillation_loss: 0.0371 - loss: 0.1503 - val_accuracy: 0.6879 - val_student_loss: 1.8545\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8218 - student_loss: 1.1259 - distillation_loss: 0.0372 - loss: 0.1460 - val_accuracy: 0.6997 - val_student_loss: 1.9496\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8187 - student_loss: 1.1327 - distillation_loss: 0.0372 - loss: 0.1468 - val_accuracy: 0.7215 - val_student_loss: 2.4449\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.8343 - student_loss: 1.0749 - distillation_loss: 0.0372 - loss: 0.1409 - val_accuracy: 0.6971 - val_student_loss: 3.0960\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8469 - student_loss: 1.0347 - distillation_loss: 0.0372 - loss: 0.1370 - val_accuracy: 0.6938 - val_student_loss: 3.2451\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8590 - student_loss: 0.9803 - distillation_loss: 0.0371 - loss: 0.1315 - val_accuracy: 0.7198 - val_student_loss: 2.4985\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8540 - student_loss: 0.9826 - distillation_loss: 0.0372 - loss: 0.1317 - val_accuracy: 0.7332 - val_student_loss: 2.4615\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8661 - student_loss: 0.9778 - distillation_loss: 0.0372 - loss: 0.1313 - val_accuracy: 0.7248 - val_student_loss: 2.1176\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8580 - student_loss: 0.9722 - distillation_loss: 0.0372 - loss: 0.1307 - val_accuracy: 0.7332 - val_student_loss: 2.0876\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.8701 - student_loss: 0.9646 - distillation_loss: 0.0373 - loss: 0.1300 - val_accuracy: 0.7366 - val_student_loss: 2.2349\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8741 - student_loss: 0.9390 - distillation_loss: 0.0371 - loss: 0.1273 - val_accuracy: 0.7357 - val_student_loss: 2.1596\n",
      "\n",
      "\n",
      "00:25:25 train_time\n",
      "\n",
      "1525.5726511478424 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|█████████████████████████▋                                                   | 9/27 [3:40:36<7:33:02, 1510.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.3, 'lr': 0.001, 'temperature': 5}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 57s 101ms/step - accuracy: 0.0342 - student_loss: 4.9359 - distillation_loss: 0.3607 - loss: 1.7332 - val_accuracy: 0.0143 - val_student_loss: 14.3319\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.1490 - student_loss: 3.7714 - distillation_loss: 0.3270 - loss: 1.3603 - val_accuracy: 0.0327 - val_student_loss: 28.1458\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.3374 - student_loss: 2.7269 - distillation_loss: 0.3003 - loss: 1.0283 - val_accuracy: 0.0537 - val_student_loss: 16.0644\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.5010 - student_loss: 1.9775 - distillation_loss: 0.2838 - loss: 0.7919 - val_accuracy: 0.0864 - val_student_loss: 11.5133\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.6143 - student_loss: 1.4951 - distillation_loss: 0.2739 - loss: 0.6402 - val_accuracy: 0.0990 - val_student_loss: 19.2172\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.7130 - student_loss: 1.1373 - distillation_loss: 0.2664 - loss: 0.5277 - val_accuracy: 0.3339 - val_student_loss: 12.7968\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.7472 - student_loss: 0.9582 - distillation_loss: 0.2613 - loss: 0.4704 - val_accuracy: 0.4195 - val_student_loss: 6.4786\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.8036 - student_loss: 0.7871 - distillation_loss: 0.2561 - loss: 0.4154 - val_accuracy: 0.3666 - val_student_loss: 16.1918\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8374 - student_loss: 0.6780 - distillation_loss: 0.2540 - loss: 0.3812 - val_accuracy: 0.6216 - val_student_loss: 6.4820\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.8575 - student_loss: 0.6077 - distillation_loss: 0.2484 - loss: 0.3562 - val_accuracy: 0.6779 - val_student_loss: 6.4105\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9033 - student_loss: 0.4645 - distillation_loss: 0.2406 - loss: 0.3077 - val_accuracy: 0.6837 - val_student_loss: 6.1336\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.8822 - student_loss: 0.5109 - distillation_loss: 0.2426 - loss: 0.3231 - val_accuracy: 0.5436 - val_student_loss: 5.6329\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9114 - student_loss: 0.4053 - distillation_loss: 0.2395 - loss: 0.2893 - val_accuracy: 0.6393 - val_student_loss: 8.1274\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9406 - student_loss: 0.3144 - distillation_loss: 0.2276 - loss: 0.2536 - val_accuracy: 0.8490 - val_student_loss: 3.0005\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9502 - student_loss: 0.2543 - distillation_loss: 0.2212 - loss: 0.2311 - val_accuracy: 0.8641 - val_student_loss: 0.7616\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9632 - student_loss: 0.2338 - distillation_loss: 0.2154 - loss: 0.2209 - val_accuracy: 0.8398 - val_student_loss: 1.4233\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9758 - student_loss: 0.1972 - distillation_loss: 0.2132 - loss: 0.2084 - val_accuracy: 0.8641 - val_student_loss: 1.4144\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9778 - student_loss: 0.1777 - distillation_loss: 0.2099 - loss: 0.2002 - val_accuracy: 0.8809 - val_student_loss: 0.8514\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9763 - student_loss: 0.1644 - distillation_loss: 0.2053 - loss: 0.1930 - val_accuracy: 0.8683 - val_student_loss: 0.7235\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9879 - student_loss: 0.1369 - distillation_loss: 0.2016 - loss: 0.1822 - val_accuracy: 0.8624 - val_student_loss: 1.0808\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9874 - student_loss: 0.1226 - distillation_loss: 0.1972 - loss: 0.1748 - val_accuracy: 0.8691 - val_student_loss: 1.0020\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9884 - student_loss: 0.1381 - distillation_loss: 0.1969 - loss: 0.1793 - val_accuracy: 0.8742 - val_student_loss: 1.1478\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9940 - student_loss: 0.1148 - distillation_loss: 0.1946 - loss: 0.1706 - val_accuracy: 0.8834 - val_student_loss: 0.8482\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9909 - student_loss: 0.1124 - distillation_loss: 0.1932 - loss: 0.1690 - val_accuracy: 0.8884 - val_student_loss: 0.8886\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9935 - student_loss: 0.1092 - distillation_loss: 0.1924 - loss: 0.1674 - val_accuracy: 0.8867 - val_student_loss: 0.8474\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9874 - student_loss: 0.1185 - distillation_loss: 0.1927 - loss: 0.1704 - val_accuracy: 0.8859 - val_student_loss: 0.8674\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9904 - student_loss: 0.1066 - distillation_loss: 0.1913 - loss: 0.1659 - val_accuracy: 0.8851 - val_student_loss: 0.8064\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9919 - student_loss: 0.1169 - distillation_loss: 0.1908 - loss: 0.1686 - val_accuracy: 0.8851 - val_student_loss: 0.7866\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9955 - student_loss: 0.0997 - distillation_loss: 0.1902 - loss: 0.1631 - val_accuracy: 0.8884 - val_student_loss: 0.7357\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9960 - student_loss: 0.1021 - distillation_loss: 0.1888 - loss: 0.1628 - val_accuracy: 0.8876 - val_student_loss: 0.8081\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "\n",
      "00:25:08 train_time\n",
      "\n",
      "1508.931765794754 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|████████████████████████████▏                                               | 10/27 [4:05:46<7:07:50, 1510.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.3, 'lr': 0.001, 'temperature': 2}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 57s 101ms/step - accuracy: 0.0408 - student_loss: 4.9934 - distillation_loss: 4.4365 - loss: 4.6036 - val_accuracy: 0.0117 - val_student_loss: 31.8037\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 50s 102ms/step - accuracy: 0.1319 - student_loss: 3.8992 - distillation_loss: 3.6659 - loss: 3.7359 - val_accuracy: 0.0101 - val_student_loss: 34.9337\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.2739 - student_loss: 2.9526 - distillation_loss: 2.9524 - loss: 2.9524 - val_accuracy: 0.0143 - val_student_loss: 43.4034\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.4119 - student_loss: 2.1650 - distillation_loss: 2.3275 - loss: 2.2787 - val_accuracy: 0.0235 - val_student_loss: 44.3699\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.5373 - student_loss: 1.5842 - distillation_loss: 1.8412 - loss: 1.7641 - val_accuracy: 0.0554 - val_student_loss: 36.9160\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6123 - student_loss: 1.3141 - distillation_loss: 1.5745 - loss: 1.4964 - val_accuracy: 0.1451 - val_student_loss: 21.9410\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.6853 - student_loss: 1.0211 - distillation_loss: 1.3090 - loss: 1.2226 - val_accuracy: 0.1225 - val_student_loss: 27.6715\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.7346 - student_loss: 0.8519 - distillation_loss: 1.1412 - loss: 1.0544 - val_accuracy: 0.3112 - val_student_loss: 1.4066\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7941 - student_loss: 0.6891 - distillation_loss: 0.9934 - loss: 0.9021 - val_accuracy: 0.4245 - val_student_loss: 4.5345\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.8077 - student_loss: 0.6581 - distillation_loss: 0.9447 - loss: 0.8587 - val_accuracy: 0.4530 - val_student_loss: 4.3005\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.8464 - student_loss: 0.4686 - distillation_loss: 0.7866 - loss: 0.6912 - val_accuracy: 0.5176 - val_student_loss: 4.8678\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8223 - student_loss: 0.5771 - distillation_loss: 0.8473 - loss: 0.7662 - val_accuracy: 0.6904 - val_student_loss: 1.8296\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.8721 - student_loss: 0.4325 - distillation_loss: 0.7177 - loss: 0.6322 - val_accuracy: 0.7844 - val_student_loss: 1.1341\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8474 - student_loss: 0.4660 - distillation_loss: 0.7480 - loss: 0.6634 - val_accuracy: 0.7257 - val_student_loss: 1.2639\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8973 - student_loss: 0.3441 - distillation_loss: 0.6434 - loss: 0.5536 - val_accuracy: 0.6334 - val_student_loss: 4.5109\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9330 - student_loss: 0.2140 - distillation_loss: 0.5282 - loss: 0.4340 - val_accuracy: 0.8364 - val_student_loss: 0.8796\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9386 - student_loss: 0.1959 - distillation_loss: 0.5000 - loss: 0.4088 - val_accuracy: 0.8054 - val_student_loss: 3.5847\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9466 - student_loss: 0.1753 - distillation_loss: 0.4804 - loss: 0.3889 - val_accuracy: 0.8112 - val_student_loss: 0.5457\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9582 - student_loss: 0.1375 - distillation_loss: 0.4449 - loss: 0.3527 - val_accuracy: 0.8280 - val_student_loss: 0.7958\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9592 - student_loss: 0.1389 - distillation_loss: 0.4286 - loss: 0.3417 - val_accuracy: 0.8591 - val_student_loss: 1.9808\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9713 - student_loss: 0.1097 - distillation_loss: 0.4160 - loss: 0.3241 - val_accuracy: 0.8482 - val_student_loss: 0.6961\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9743 - student_loss: 0.1012 - distillation_loss: 0.3989 - loss: 0.3096 - val_accuracy: 0.8482 - val_student_loss: 1.3274\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9698 - student_loss: 0.1010 - distillation_loss: 0.3943 - loss: 0.3063 - val_accuracy: 0.8591 - val_student_loss: 1.1523\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9743 - student_loss: 0.0957 - distillation_loss: 0.3910 - loss: 0.3024 - val_accuracy: 0.8540 - val_student_loss: 1.1731\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9768 - student_loss: 0.0750 - distillation_loss: 0.3669 - loss: 0.2793 - val_accuracy: 0.8582 - val_student_loss: 1.1438\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9728 - student_loss: 0.0854 - distillation_loss: 0.3703 - loss: 0.2849 - val_accuracy: 0.8616 - val_student_loss: 1.1814\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9753 - student_loss: 0.0832 - distillation_loss: 0.3695 - loss: 0.2836 - val_accuracy: 0.8599 - val_student_loss: 1.2545\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9794 - student_loss: 0.0779 - distillation_loss: 0.3638 - loss: 0.2780 - val_accuracy: 0.8633 - val_student_loss: 1.0771\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9839 - student_loss: 0.0709 - distillation_loss: 0.3595 - loss: 0.2729 - val_accuracy: 0.8716 - val_student_loss: 1.5827\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9844 - student_loss: 0.0662 - distillation_loss: 0.3499 - loss: 0.2648 - val_accuracy: 0.8700 - val_student_loss: 1.2411\n",
      "\n",
      "\n",
      "00:25:11 train_time\n",
      "\n",
      "1511.87282204628 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|██████████████████████████████▉                                             | 11/27 [4:30:59<6:42:54, 1510.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.3, 'lr': 0.001, 'temperature': 10}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 56s 101ms/step - accuracy: 0.0403 - student_loss: 4.9756 - distillation_loss: 0.0406 - loss: 1.5211 - val_accuracy: 0.0159 - val_student_loss: 34.0605\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.1349 - student_loss: 3.8195 - distillation_loss: 0.0399 - loss: 1.1738 - val_accuracy: 0.0134 - val_student_loss: 44.6209\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.3087 - student_loss: 2.8410 - distillation_loss: 0.0415 - loss: 0.8814 - val_accuracy: 0.0126 - val_student_loss: 35.2633\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.5468 - student_loss: 1.8320 - distillation_loss: 0.0440 - loss: 0.5804 - val_accuracy: 0.2039 - val_student_loss: 6.4356\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.6219 - student_loss: 1.4584 - distillation_loss: 0.0457 - loss: 0.4695 - val_accuracy: 0.3867 - val_student_loss: 3.4829\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.6999 - student_loss: 1.1996 - distillation_loss: 0.0475 - loss: 0.3931 - val_accuracy: 0.3859 - val_student_loss: 3.5446\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.7467 - student_loss: 0.9970 - distillation_loss: 0.0485 - loss: 0.3330 - val_accuracy: 0.5654 - val_student_loss: 4.1441\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8031 - student_loss: 0.8376 - distillation_loss: 0.0497 - loss: 0.2861 - val_accuracy: 0.5579 - val_student_loss: 3.6746\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.8449 - student_loss: 0.7124 - distillation_loss: 0.0509 - loss: 0.2493 - val_accuracy: 0.5302 - val_student_loss: 6.0124\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.8781 - student_loss: 0.5504 - distillation_loss: 0.0525 - loss: 0.2019 - val_accuracy: 0.7559 - val_student_loss: 1.3323\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9094 - student_loss: 0.4319 - distillation_loss: 0.0521 - loss: 0.1661 - val_accuracy: 0.7735 - val_student_loss: 1.6308\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9008 - student_loss: 0.4526 - distillation_loss: 0.0524 - loss: 0.1725 - val_accuracy: 0.8104 - val_student_loss: 0.9761\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9245 - student_loss: 0.3759 - distillation_loss: 0.0530 - loss: 0.1498 - val_accuracy: 0.8020 - val_student_loss: 0.3136\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9340 - student_loss: 0.3491 - distillation_loss: 0.0528 - loss: 0.1417 - val_accuracy: 0.8398 - val_student_loss: 0.4643\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9320 - student_loss: 0.3578 - distillation_loss: 0.0528 - loss: 0.1443 - val_accuracy: 0.7928 - val_student_loss: 0.1028\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9491 - student_loss: 0.3076 - distillation_loss: 0.0536 - loss: 0.1298 - val_accuracy: 0.8532 - val_student_loss: 0.3817\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9522 - student_loss: 0.2940 - distillation_loss: 0.0533 - loss: 0.1255 - val_accuracy: 0.8037 - val_student_loss: 0.0259\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9436 - student_loss: 0.3017 - distillation_loss: 0.0533 - loss: 0.1279 - val_accuracy: 0.8154 - val_student_loss: 0.7591\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9517 - student_loss: 0.2483 - distillation_loss: 0.0537 - loss: 0.1121 - val_accuracy: 0.8247 - val_student_loss: 0.1687\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9703 - student_loss: 0.2045 - distillation_loss: 0.0534 - loss: 0.0987 - val_accuracy: 0.8314 - val_student_loss: 0.5002\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9738 - student_loss: 0.1881 - distillation_loss: 0.0533 - loss: 0.0937 - val_accuracy: 0.8305 - val_student_loss: 0.4694\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9773 - student_loss: 0.1888 - distillation_loss: 0.0533 - loss: 0.0940 - val_accuracy: 0.8440 - val_student_loss: 0.3216\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9728 - student_loss: 0.1865 - distillation_loss: 0.0532 - loss: 0.0932 - val_accuracy: 0.8482 - val_student_loss: 0.4665\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9758 - student_loss: 0.1762 - distillation_loss: 0.0526 - loss: 0.0897 - val_accuracy: 0.8616 - val_student_loss: 0.4661\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9799 - student_loss: 0.1663 - distillation_loss: 0.0530 - loss: 0.0870 - val_accuracy: 0.8582 - val_student_loss: 0.3758\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9799 - student_loss: 0.1637 - distillation_loss: 0.0526 - loss: 0.0859 - val_accuracy: 0.8532 - val_student_loss: 0.3871\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9748 - student_loss: 0.1725 - distillation_loss: 0.0526 - loss: 0.0886 - val_accuracy: 0.8616 - val_student_loss: 0.4293\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9829 - student_loss: 0.1601 - distillation_loss: 0.0532 - loss: 0.0853 - val_accuracy: 0.8616 - val_student_loss: 0.4304\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9778 - student_loss: 0.1783 - distillation_loss: 0.0526 - loss: 0.0903 - val_accuracy: 0.8607 - val_student_loss: 0.4607\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9799 - student_loss: 0.1560 - distillation_loss: 0.0526 - loss: 0.0836 - val_accuracy: 0.8641 - val_student_loss: 0.5137\n",
      "\n",
      "\n",
      "00:25:09 train_time\n",
      "\n",
      "1509.120048046112 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|█████████████████████████████████▊                                          | 12/27 [4:56:09<6:17:39, 1510.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.3, 'lr': 0.01, 'temperature': 5}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 57s 101ms/step - accuracy: 0.0121 - student_loss: 5.3249 - distillation_loss: 0.3730 - loss: 1.8586 - val_accuracy: 0.0050 - val_student_loss: 110.2013\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.0358 - student_loss: 4.7674 - distillation_loss: 0.3590 - loss: 1.6815 - val_accuracy: 0.0050 - val_student_loss: 137.7155\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.0806 - student_loss: 4.2278 - distillation_loss: 0.3512 - loss: 1.5142 - val_accuracy: 0.0050 - val_student_loss: 89.1716\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 50s 102ms/step - accuracy: 0.1697 - student_loss: 3.4127 - distillation_loss: 0.3419 - loss: 1.2632 - val_accuracy: 0.0050 - val_student_loss: 37.3024\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.2467 - student_loss: 2.9392 - distillation_loss: 0.3390 - loss: 1.1190 - val_accuracy: 0.0294 - val_student_loss: 23.9744\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.3162 - student_loss: 2.6085 - distillation_loss: 0.3345 - loss: 1.0167 - val_accuracy: 0.0227 - val_student_loss: 7.0492\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.3842 - student_loss: 2.2535 - distillation_loss: 0.3308 - loss: 0.9076 - val_accuracy: 0.0268 - val_student_loss: 9.6491\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 51s 101ms/step - accuracy: 0.5081 - student_loss: 1.7938 - distillation_loss: 0.3258 - loss: 0.7662 - val_accuracy: 0.0990 - val_student_loss: 9.5258\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.5871 - student_loss: 1.5383 - distillation_loss: 0.3217 - loss: 0.6867 - val_accuracy: 0.1418 - val_student_loss: 12.0271\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.6042 - student_loss: 1.4117 - distillation_loss: 0.3207 - loss: 0.6480 - val_accuracy: 0.1560 - val_student_loss: 11.9066\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.6561 - student_loss: 1.2402 - distillation_loss: 0.3166 - loss: 0.5937 - val_accuracy: 0.1904 - val_student_loss: 10.0252\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6631 - student_loss: 1.2246 - distillation_loss: 0.3133 - loss: 0.5867 - val_accuracy: 0.2424 - val_student_loss: 8.4096\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7387 - student_loss: 1.0141 - distillation_loss: 0.3093 - loss: 0.5208 - val_accuracy: 0.1963 - val_student_loss: 5.8147\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7397 - student_loss: 0.9809 - distillation_loss: 0.3067 - loss: 0.5089 - val_accuracy: 0.2164 - val_student_loss: 8.3172\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7946 - student_loss: 0.8099 - distillation_loss: 0.2971 - loss: 0.4510 - val_accuracy: 0.3767 - val_student_loss: 6.1597\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8051 - student_loss: 0.7324 - distillation_loss: 0.2922 - loss: 0.4243 - val_accuracy: 0.3205 - val_student_loss: 5.4481\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8414 - student_loss: 0.6300 - distillation_loss: 0.2878 - loss: 0.3905 - val_accuracy: 0.3205 - val_student_loss: 6.4758\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8570 - student_loss: 0.5780 - distillation_loss: 0.2834 - loss: 0.3718 - val_accuracy: 0.4530 - val_student_loss: 4.4066\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8736 - student_loss: 0.5621 - distillation_loss: 0.2813 - loss: 0.3655 - val_accuracy: 0.5461 - val_student_loss: 2.3502\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8741 - student_loss: 0.5209 - distillation_loss: 0.2824 - loss: 0.3539 - val_accuracy: 0.5378 - val_student_loss: 2.0884\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8771 - student_loss: 0.5298 - distillation_loss: 0.2776 - loss: 0.3532 - val_accuracy: 0.5638 - val_student_loss: 2.3881\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8807 - student_loss: 0.5176 - distillation_loss: 0.2757 - loss: 0.3483 - val_accuracy: 0.5914 - val_student_loss: 3.7460\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8797 - student_loss: 0.5071 - distillation_loss: 0.2739 - loss: 0.3439 - val_accuracy: 0.5671 - val_student_loss: 2.4227\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9023 - student_loss: 0.4571 - distillation_loss: 0.2721 - loss: 0.3276 - val_accuracy: 0.5847 - val_student_loss: 2.5393\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9255 - student_loss: 0.4004 - distillation_loss: 0.2680 - loss: 0.3077 - val_accuracy: 0.6426 - val_student_loss: 2.5488\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9114 - student_loss: 0.4289 - distillation_loss: 0.2676 - loss: 0.3160 - val_accuracy: 0.6292 - val_student_loss: 2.2303\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9240 - student_loss: 0.3977 - distillation_loss: 0.2644 - loss: 0.3044 - val_accuracy: 0.6619 - val_student_loss: 2.5666\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9159 - student_loss: 0.4250 - distillation_loss: 0.2673 - loss: 0.3146 - val_accuracy: 0.6879 - val_student_loss: 2.2506\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9255 - student_loss: 0.4020 - distillation_loss: 0.2647 - loss: 0.3059 - val_accuracy: 0.6686 - val_student_loss: 3.0166\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.9184 - student_loss: 0.3706 - distillation_loss: 0.2642 - loss: 0.2961 - val_accuracy: 0.6644 - val_student_loss: 2.9855\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "\n",
      "\n",
      "00:25:21 train_time\n",
      "\n",
      "1521.3631279468536 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████████████████████████████████████▌                                       | 13/27 [5:21:31<5:53:18, 1514.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.3, 'lr': 0.01, 'temperature': 2}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 56s 101ms/step - accuracy: 0.0111 - student_loss: 5.4791 - distillation_loss: 4.6658 - loss: 4.9098 - val_accuracy: 0.0050 - val_student_loss: 247.2189\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.0312 - student_loss: 5.0097 - distillation_loss: 4.2527 - loss: 4.4798 - val_accuracy: 0.0050 - val_student_loss: 128.6740\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.0670 - student_loss: 4.5716 - distillation_loss: 3.8630 - loss: 4.0756 - val_accuracy: 0.0050 - val_student_loss: 167.4587\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.1455 - student_loss: 3.7334 - distillation_loss: 3.2702 - loss: 3.4092 - val_accuracy: 0.0050 - val_student_loss: 95.1102\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.2080 - student_loss: 3.2584 - distillation_loss: 2.8851 - loss: 2.9971 - val_accuracy: 0.0050 - val_student_loss: 110.7729\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.3409 - student_loss: 2.5685 - distillation_loss: 2.4012 - loss: 2.4514 - val_accuracy: 0.0344 - val_student_loss: 22.7227\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.3953 - student_loss: 2.2484 - distillation_loss: 2.1579 - loss: 2.1851 - val_accuracy: 0.1191 - val_student_loss: 10.9440\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.4627 - student_loss: 1.9856 - distillation_loss: 1.9550 - loss: 1.9642 - val_accuracy: 0.1728 - val_student_loss: 10.8613\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.5050 - student_loss: 1.7642 - distillation_loss: 1.7823 - loss: 1.7769 - val_accuracy: 0.2232 - val_student_loss: 8.0250\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.5629 - student_loss: 1.5994 - distillation_loss: 1.6495 - loss: 1.6345 - val_accuracy: 0.1921 - val_student_loss: 12.1456\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.6128 - student_loss: 1.3787 - distillation_loss: 1.4829 - loss: 1.4516 - val_accuracy: 0.2458 - val_student_loss: 5.5949\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6294 - student_loss: 1.3211 - distillation_loss: 1.4251 - loss: 1.3939 - val_accuracy: 0.3213 - val_student_loss: 2.2503\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6742 - student_loss: 1.1403 - distillation_loss: 1.2933 - loss: 1.2474 - val_accuracy: 0.2592 - val_student_loss: 3.8598\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.6712 - student_loss: 1.1631 - distillation_loss: 1.2800 - loss: 1.2450 - val_accuracy: 0.1971 - val_student_loss: 3.8517\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7543 - student_loss: 0.8289 - distillation_loss: 1.0714 - loss: 0.9987 - val_accuracy: 0.3935 - val_student_loss: 1.8138\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7719 - student_loss: 0.7392 - distillation_loss: 0.9897 - loss: 0.9145 - val_accuracy: 0.3884 - val_student_loss: 3.7062\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7840 - student_loss: 0.7005 - distillation_loss: 0.9598 - loss: 0.8820 - val_accuracy: 0.4371 - val_student_loss: 3.8092\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8046 - student_loss: 0.6723 - distillation_loss: 0.9377 - loss: 0.8581 - val_accuracy: 0.4362 - val_student_loss: 2.0856\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8087 - student_loss: 0.6248 - distillation_loss: 0.8953 - loss: 0.8142 - val_accuracy: 0.5310 - val_student_loss: 2.7689\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8152 - student_loss: 0.6146 - distillation_loss: 0.8754 - loss: 0.7972 - val_accuracy: 0.5352 - val_student_loss: 3.5904\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8379 - student_loss: 0.5397 - distillation_loss: 0.8207 - loss: 0.7364 - val_accuracy: 0.4396 - val_student_loss: 9.2118\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8424 - student_loss: 0.5287 - distillation_loss: 0.8143 - loss: 0.7286 - val_accuracy: 0.5134 - val_student_loss: 8.2765\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8651 - student_loss: 0.4374 - distillation_loss: 0.7502 - loss: 0.6564 - val_accuracy: 0.5797 - val_student_loss: 7.5707\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8711 - student_loss: 0.4429 - distillation_loss: 0.7555 - loss: 0.6617 - val_accuracy: 0.5847 - val_student_loss: 6.7068\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8792 - student_loss: 0.3700 - distillation_loss: 0.6941 - loss: 0.5969 - val_accuracy: 0.5940 - val_student_loss: 4.8339\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8701 - student_loss: 0.3890 - distillation_loss: 0.7005 - loss: 0.6071 - val_accuracy: 0.5436 - val_student_loss: 4.0001\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.8862 - student_loss: 0.3689 - distillation_loss: 0.6896 - loss: 0.5934 - val_accuracy: 0.6275 - val_student_loss: 6.0253\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8922 - student_loss: 0.3628 - distillation_loss: 0.6743 - loss: 0.5809 - val_accuracy: 0.6804 - val_student_loss: 2.9594\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 50s 102ms/step - accuracy: 0.8912 - student_loss: 0.3598 - distillation_loss: 0.6783 - loss: 0.5828 - val_accuracy: 0.6686 - val_student_loss: 3.6963\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8922 - student_loss: 0.3312 - distillation_loss: 0.6523 - loss: 0.5560 - val_accuracy: 0.6779 - val_student_loss: 6.7388\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "\n",
      "00:25:17 train_time\n",
      "\n",
      "1517.5258524417877 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|███████████████████████████████████████▍                                    | 14/27 [5:46:50<5:28:21, 1515.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.3, 'lr': 0.01, 'temperature': 10}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 57s 102ms/step - accuracy: 0.0176 - student_loss: 5.3020 - distillation_loss: 0.0419 - loss: 1.6200 - val_accuracy: 0.0050 - val_student_loss: 168.5627\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.0342 - student_loss: 4.8216 - distillation_loss: 0.0432 - loss: 1.4767 - val_accuracy: 0.0050 - val_student_loss: 177.3052\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.0650 - student_loss: 4.3709 - distillation_loss: 0.0460 - loss: 1.3435 - val_accuracy: 0.0050 - val_student_loss: 102.0014\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.1198 - student_loss: 3.7764 - distillation_loss: 0.0496 - loss: 1.1677 - val_accuracy: 0.0151 - val_student_loss: 10.4304\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.2069 - student_loss: 3.2277 - distillation_loss: 0.0549 - loss: 1.0067 - val_accuracy: 0.0050 - val_student_loss: 29.5276\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.2915 - student_loss: 2.7716 - distillation_loss: 0.0591 - loss: 0.8728 - val_accuracy: 0.0117 - val_student_loss: 28.5868\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.4169 - student_loss: 2.1884 - distillation_loss: 0.0638 - loss: 0.7012 - val_accuracy: 0.0352 - val_student_loss: 9.3615\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.4980 - student_loss: 1.8528 - distillation_loss: 0.0670 - loss: 0.6027 - val_accuracy: 0.0461 - val_student_loss: 9.1904\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.5519 - student_loss: 1.6751 - distillation_loss: 0.0694 - loss: 0.5511 - val_accuracy: 0.1032 - val_student_loss: 6.3651\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.5796 - student_loss: 1.5052 - distillation_loss: 0.0716 - loss: 0.5016 - val_accuracy: 0.1309 - val_student_loss: 2.9596\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.6400 - student_loss: 1.2836 - distillation_loss: 0.0748 - loss: 0.4374 - val_accuracy: 0.1611 - val_student_loss: 0.7823\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.6526 - student_loss: 1.2669 - distillation_loss: 0.0751 - loss: 0.4326 - val_accuracy: 0.1242 - val_student_loss: 6.8169\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.6934 - student_loss: 1.0756 - distillation_loss: 0.0763 - loss: 0.3761 - val_accuracy: 0.2282 - val_student_loss: 2.1987\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.7185 - student_loss: 1.0013 - distillation_loss: 0.0774 - loss: 0.3546 - val_accuracy: 0.2911 - val_student_loss: 3.2143\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.7442 - student_loss: 0.9124 - distillation_loss: 0.0769 - loss: 0.3275 - val_accuracy: 0.3800 - val_student_loss: 1.7168\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.7633 - student_loss: 0.8425 - distillation_loss: 0.0779 - loss: 0.3073 - val_accuracy: 0.1904 - val_student_loss: 12.6904\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.7956 - student_loss: 0.7391 - distillation_loss: 0.0791 - loss: 0.2771 - val_accuracy: 0.2366 - val_student_loss: 7.8943\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.8338 - student_loss: 0.6012 - distillation_loss: 0.0786 - loss: 0.2354 - val_accuracy: 0.4010 - val_student_loss: 2.7527\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.8590 - student_loss: 0.5450 - distillation_loss: 0.0786 - loss: 0.2185 - val_accuracy: 0.3708 - val_student_loss: 4.1939\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.8570 - student_loss: 0.5190 - distillation_loss: 0.0781 - loss: 0.2104 - val_accuracy: 0.4606 - val_student_loss: 1.8419\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.8651 - student_loss: 0.4858 - distillation_loss: 0.0774 - loss: 0.1999 - val_accuracy: 0.4270 - val_student_loss: 0.5966\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.8771 - student_loss: 0.4665 - distillation_loss: 0.0776 - loss: 0.1943 - val_accuracy: 0.4698 - val_student_loss: 1.6646\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.8726 - student_loss: 0.4833 - distillation_loss: 0.0775 - loss: 0.1992 - val_accuracy: 0.4471 - val_student_loss: 0.1032\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.8882 - student_loss: 0.4249 - distillation_loss: 0.0779 - loss: 0.1820 - val_accuracy: 0.5940 - val_student_loss: 1.5397\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.8968 - student_loss: 0.4055 - distillation_loss: 0.0771 - loss: 0.1756 - val_accuracy: 0.5856 - val_student_loss: 1.7860\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.8917 - student_loss: 0.3967 - distillation_loss: 0.0783 - loss: 0.1738 - val_accuracy: 0.5646 - val_student_loss: 0.2538\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 48s 97ms/step - accuracy: 0.9134 - student_loss: 0.3471 - distillation_loss: 0.0767 - loss: 0.1578 - val_accuracy: 0.6074 - val_student_loss: 2.0392\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.9184 - student_loss: 0.3261 - distillation_loss: 0.0759 - loss: 0.1509 - val_accuracy: 0.6686 - val_student_loss: 0.4615\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.9260 - student_loss: 0.3265 - distillation_loss: 0.0748 - loss: 0.1503 - val_accuracy: 0.6896 - val_student_loss: 0.3924\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9421 - student_loss: 0.2798 - distillation_loss: 0.0746 - loss: 0.1361 - val_accuracy: 0.7055 - val_student_loss: 0.8199\n",
      "\n",
      "\n",
      "00:24:44 train_time\n",
      "\n",
      "1484.07199883461 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|██████████████████████████████████████████▏                                 | 15/27 [6:11:35<5:01:16, 1506.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.3, 'lr': 0.0001, 'temperature': 5}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 57s 102ms/step - accuracy: 0.0070 - student_loss: 5.2839 - distillation_loss: 0.3718 - loss: 1.8455 - val_accuracy: 0.0059 - val_student_loss: 5.2168\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.0504 - student_loss: 4.9157 - distillation_loss: 0.3610 - loss: 1.7274 - val_accuracy: 0.0327 - val_student_loss: 3.7949\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 51s 103ms/step - accuracy: 0.0901 - student_loss: 4.5548 - distillation_loss: 0.3508 - loss: 1.6120 - val_accuracy: 0.0143 - val_student_loss: 3.5971\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.1420 - student_loss: 4.2102 - distillation_loss: 0.3408 - loss: 1.5017 - val_accuracy: 0.0730 - val_student_loss: 3.1522\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.1969 - student_loss: 3.8530 - distillation_loss: 0.3313 - loss: 1.3878 - val_accuracy: 0.1703 - val_student_loss: 2.5271\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.2669 - student_loss: 3.5252 - distillation_loss: 0.3222 - loss: 1.2831 - val_accuracy: 0.0570 - val_student_loss: 5.3309\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.3238 - student_loss: 3.2242 - distillation_loss: 0.3145 - loss: 1.1874 - val_accuracy: 0.1720 - val_student_loss: 3.2150til\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.3681 - student_loss: 2.9738 - distillation_loss: 0.3074 - loss: 1.1073 - val_accuracy: 0.3381 - val_student_loss: 1.8659\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.4486 - student_loss: 2.6587 - distillation_loss: 0.2989 - loss: 1.0068 - val_accuracy: 0.4379 - val_student_loss: 2.1247\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.4955 - student_loss: 2.4584 - distillation_loss: 0.2934 - loss: 0.9429 - val_accuracy: 0.2978 - val_student_loss: 3.0912\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.5584 - student_loss: 2.1622 - distillation_loss: 0.2846 - loss: 0.8479 - val_accuracy: 0.1871 - val_student_loss: 5.8362\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6078 - student_loss: 2.0018 - distillation_loss: 0.2803 - loss: 0.7967 - val_accuracy: 0.4648 - val_student_loss: 1.3892\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.6551 - student_loss: 1.8338 - distillation_loss: 0.2754 - loss: 0.7429 - val_accuracy: 0.4983 - val_student_loss: 1.2776\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6692 - student_loss: 1.7531 - distillation_loss: 0.2724 - loss: 0.7166 - val_accuracy: 0.5646 - val_student_loss: 1.0299\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6908 - student_loss: 1.6304 - distillation_loss: 0.2688 - loss: 0.6773 - val_accuracy: 0.4295 - val_student_loss: 1.6536\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7236 - student_loss: 1.5391 - distillation_loss: 0.2666 - loss: 0.6484 - val_accuracy: 0.5562 - val_student_loss: 1.3991\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7367 - student_loss: 1.4426 - distillation_loss: 0.2626 - loss: 0.6166 - val_accuracy: 0.6342 - val_student_loss: 1.1239\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.7513 - student_loss: 1.4071 - distillation_loss: 0.2618 - loss: 0.6054 - val_accuracy: 0.6367 - val_student_loss: 0.8857\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7633 - student_loss: 1.3601 - distillation_loss: 0.2608 - loss: 0.5906 - val_accuracy: 0.6711 - val_student_loss: 1.1862\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7769 - student_loss: 1.3169 - distillation_loss: 0.2588 - loss: 0.5762 - val_accuracy: 0.6720 - val_student_loss: 1.1763\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7986 - student_loss: 1.2401 - distillation_loss: 0.2565 - loss: 0.5516 - val_accuracy: 0.6040 - val_student_loss: 1.3677\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7764 - student_loss: 1.2675 - distillation_loss: 0.2561 - loss: 0.5595 - val_accuracy: 0.5453 - val_student_loss: 1.7473\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8122 - student_loss: 1.2084 - distillation_loss: 0.2555 - loss: 0.5413 - val_accuracy: 0.6787 - val_student_loss: 1.1720\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8021 - student_loss: 1.2094 - distillation_loss: 0.2557 - loss: 0.5418 - val_accuracy: 0.6770 - val_student_loss: 1.1206\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8142 - student_loss: 1.1587 - distillation_loss: 0.2535 - loss: 0.5250 - val_accuracy: 0.6820 - val_student_loss: 1.1502\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8142 - student_loss: 1.1467 - distillation_loss: 0.2531 - loss: 0.5212 - val_accuracy: 0.6862 - val_student_loss: 0.8321\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8212 - student_loss: 1.1401 - distillation_loss: 0.2527 - loss: 0.5189 - val_accuracy: 0.6871 - val_student_loss: 1.2259\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8243 - student_loss: 1.1659 - distillation_loss: 0.2537 - loss: 0.5274 - val_accuracy: 0.6921 - val_student_loss: 0.9104\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8293 - student_loss: 1.0845 - distillation_loss: 0.2507 - loss: 0.5008 - val_accuracy: 0.6795 - val_student_loss: 0.9328\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8343 - student_loss: 1.0754 - distillation_loss: 0.2509 - loss: 0.4982 - val_accuracy: 0.6737 - val_student_loss: 1.1664\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "\n",
      "00:25:17 train_time\n",
      "\n",
      "1517.3204109668732 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████████████████████████████████████████████                               | 16/27 [6:36:53<4:36:49, 1509.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.3, 'lr': 0.0001, 'temperature': 2}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 57s 103ms/step - accuracy: 0.0146 - student_loss: 5.2823 - distillation_loss: 4.6363 - loss: 4.8301 - val_accuracy: 0.0101 - val_student_loss: 5.2177\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.0468 - student_loss: 4.9022 - distillation_loss: 4.4474 - loss: 4.5839 - val_accuracy: 0.0201 - val_student_loss: 6.3818\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.0791 - student_loss: 4.5806 - distillation_loss: 4.2614 - loss: 4.3572 - val_accuracy: 0.0361 - val_student_loss: 5.4318\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.1183 - student_loss: 4.2243 - distillation_loss: 4.0521 - loss: 4.1038 - val_accuracy: 0.0428 - val_student_loss: 5.6192\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.1616 - student_loss: 3.8908 - distillation_loss: 3.8478 - loss: 3.8607 - val_accuracy: 0.1401 - val_student_loss: 2.2194\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 51s 101ms/step - accuracy: 0.2014 - student_loss: 3.5500 - distillation_loss: 3.6311 - loss: 3.6067 - val_accuracy: 0.1703 - val_student_loss: 1.9984\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.2805 - student_loss: 3.2267 - distillation_loss: 3.4267 - loss: 3.3667 - val_accuracy: 0.1686 - val_student_loss: 3.8276\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.3248 - student_loss: 2.9435 - distillation_loss: 3.2374 - loss: 3.1492 - val_accuracy: 0.1468 - val_student_loss: 4.2115\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.3837 - student_loss: 2.6326 - distillation_loss: 3.0314 - loss: 2.9118 - val_accuracy: 0.3515 - val_student_loss: 1.9128\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.4179 - student_loss: 2.5098 - distillation_loss: 2.9486 - loss: 2.8170 - val_accuracy: 0.3070 - val_student_loss: 3.0396\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.4325 - student_loss: 2.3609 - distillation_loss: 2.8371 - loss: 2.6942 - val_accuracy: 0.3993 - val_student_loss: 2.7492\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.4713 - student_loss: 2.2548 - distillation_loss: 2.7603 - loss: 2.6086 - val_accuracy: 0.4388 - val_student_loss: 2.2732\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.4924 - student_loss: 2.1317 - distillation_loss: 2.6682 - loss: 2.5073 - val_accuracy: 0.3851 - val_student_loss: 3.0204\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.5171 - student_loss: 2.0483 - distillation_loss: 2.5977 - loss: 2.4329 - val_accuracy: 0.3658 - val_student_loss: 2.5786\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.5524 - student_loss: 1.8855 - distillation_loss: 2.4828 - loss: 2.3036 - val_accuracy: 0.5227 - val_student_loss: 1.3110\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.5478 - student_loss: 1.8617 - distillation_loss: 2.4686 - loss: 2.2865 - val_accuracy: 0.5050 - val_student_loss: 1.9047\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.5710 - student_loss: 1.7772 - distillation_loss: 2.3969 - loss: 2.2110 - val_accuracy: 0.5554 - val_student_loss: 1.5795\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6002 - student_loss: 1.7446 - distillation_loss: 2.3901 - loss: 2.1965 - val_accuracy: 0.5319 - val_student_loss: 1.9724\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 50s 102ms/step - accuracy: 0.5992 - student_loss: 1.7009 - distillation_loss: 2.3348 - loss: 2.1446 - val_accuracy: 0.4924 - val_student_loss: 1.7926\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.6128 - student_loss: 1.6217 - distillation_loss: 2.2907 - loss: 2.0900 - val_accuracy: 0.5470 - val_student_loss: 1.5597\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6007 - student_loss: 1.5869 - distillation_loss: 2.2581 - loss: 2.0567 - val_accuracy: 0.5814 - val_student_loss: 1.4074\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.6375 - student_loss: 1.5515 - distillation_loss: 2.2302 - loss: 2.0266 - val_accuracy: 0.5805 - val_student_loss: 1.5483\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6294 - student_loss: 1.5223 - distillation_loss: 2.2004 - loss: 1.9970 - val_accuracy: 0.5982 - val_student_loss: 1.9625\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6395 - student_loss: 1.5045 - distillation_loss: 2.1875 - loss: 1.9826 - val_accuracy: 0.6007 - val_student_loss: 1.6562\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6470 - student_loss: 1.4836 - distillation_loss: 2.1654 - loss: 1.9609 - val_accuracy: 0.6049 - val_student_loss: 2.0647\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6460 - student_loss: 1.4767 - distillation_loss: 2.1508 - loss: 1.9486 - val_accuracy: 0.5956 - val_student_loss: 1.7673\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6551 - student_loss: 1.4506 - distillation_loss: 2.1410 - loss: 1.9339 - val_accuracy: 0.6040 - val_student_loss: 2.0200\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.6516 - student_loss: 1.4540 - distillation_loss: 2.1370 - loss: 1.9321 - val_accuracy: 0.6015 - val_student_loss: 2.0591\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6636 - student_loss: 1.3974 - distillation_loss: 2.0911 - loss: 1.8830 - val_accuracy: 0.6082 - val_student_loss: 1.8040\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6561 - student_loss: 1.4470 - distillation_loss: 2.1275 - loss: 1.9233 - val_accuracy: 0.6149 - val_student_loss: 1.5767\n",
      "\n",
      "\n",
      "00:25:24 train_time\n",
      "\n",
      "1524.5021846294403 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|███████████████████████████████████████████████▊                            | 17/27 [7:02:19<4:12:26, 1514.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.3, 'lr': 0.0001, 'temperature': 10}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 56s 102ms/step - accuracy: 0.0151 - student_loss: 5.2952 - distillation_loss: 0.0411 - loss: 1.6173 - val_accuracy: 0.0109 - val_student_loss: 4.5375\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.0438 - student_loss: 4.9297 - distillation_loss: 0.0399 - loss: 1.5068 - val_accuracy: 0.0210 - val_student_loss: 4.0621\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.0861 - student_loss: 4.5937 - distillation_loss: 0.0394 - loss: 1.4057 - val_accuracy: 0.0159 - val_student_loss: 3.4188\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.1314 - student_loss: 4.2512 - distillation_loss: 0.0389 - loss: 1.3026 - val_accuracy: 0.1292 - val_student_loss: 4.2559\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 50s 102ms/step - accuracy: 0.2024 - student_loss: 3.8930 - distillation_loss: 0.0386 - loss: 1.1949 - val_accuracy: 0.1376 - val_student_loss: 4.1525\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.2442 - student_loss: 3.5914 - distillation_loss: 0.0383 - loss: 1.1042 - val_accuracy: 0.1820 - val_student_loss: 3.5478\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 51s 101ms/step - accuracy: 0.3061 - student_loss: 3.2610 - distillation_loss: 0.0381 - loss: 1.0049 - val_accuracy: 0.2584 - val_student_loss: 3.7182\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.3630 - student_loss: 3.0292 - distillation_loss: 0.0381 - loss: 0.9354 - val_accuracy: 0.3154 - val_student_loss: 3.8997\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.4345 - student_loss: 2.7073 - distillation_loss: 0.0380 - loss: 0.8388 - val_accuracy: 0.2945 - val_student_loss: 3.6523\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.4622 - student_loss: 2.5624 - distillation_loss: 0.0380 - loss: 0.7953 - val_accuracy: 0.4228 - val_student_loss: 3.4311\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.5332 - student_loss: 2.2479 - distillation_loss: 0.0379 - loss: 0.7009 - val_accuracy: 0.3960 - val_student_loss: 2.7554\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.5745 - student_loss: 2.0651 - distillation_loss: 0.0382 - loss: 0.6462 - val_accuracy: 0.5570 - val_student_loss: 2.2617\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6314 - student_loss: 1.8602 - distillation_loss: 0.0383 - loss: 0.5849 - val_accuracy: 0.4941 - val_student_loss: 2.7697\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.6843 - student_loss: 1.6773 - distillation_loss: 0.0382 - loss: 0.5300 - val_accuracy: 0.3079 - val_student_loss: 2.8175\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7175 - student_loss: 1.5005 - distillation_loss: 0.0384 - loss: 0.4771 - val_accuracy: 0.5017 - val_student_loss: 2.4460\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.7442 - student_loss: 1.4259 - distillation_loss: 0.0384 - loss: 0.4546 - val_accuracy: 0.5831 - val_student_loss: 2.7342\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7603 - student_loss: 1.3727 - distillation_loss: 0.0384 - loss: 0.4387 - val_accuracy: 0.6015 - val_student_loss: 1.4996\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7885 - student_loss: 1.2437 - distillation_loss: 0.0386 - loss: 0.4002 - val_accuracy: 0.6611 - val_student_loss: 1.5444\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7860 - student_loss: 1.2147 - distillation_loss: 0.0389 - loss: 0.3916 - val_accuracy: 0.6216 - val_student_loss: 2.3738\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8051 - student_loss: 1.1572 - distillation_loss: 0.0389 - loss: 0.3743 - val_accuracy: 0.6812 - val_student_loss: 1.7037\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8137 - student_loss: 1.0817 - distillation_loss: 0.0389 - loss: 0.3518 - val_accuracy: 0.6602 - val_student_loss: 1.2356\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 50s 102ms/step - accuracy: 0.8228 - student_loss: 1.0650 - distillation_loss: 0.0389 - loss: 0.3468 - val_accuracy: 0.7307 - val_student_loss: 1.2571\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8434 - student_loss: 0.9996 - distillation_loss: 0.0393 - loss: 0.3274 - val_accuracy: 0.6351 - val_student_loss: 2.4216\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8535 - student_loss: 0.9218 - distillation_loss: 0.0393 - loss: 0.3041 - val_accuracy: 0.6116 - val_student_loss: 3.6750\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8651 - student_loss: 0.8835 - distillation_loss: 0.0392 - loss: 0.2925 - val_accuracy: 0.6795 - val_student_loss: 1.5660\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 50s 102ms/step - accuracy: 0.8666 - student_loss: 0.8627 - distillation_loss: 0.0396 - loss: 0.2865 - val_accuracy: 0.7458 - val_student_loss: 1.1634\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8832 - student_loss: 0.8096 - distillation_loss: 0.0393 - loss: 0.2704 - val_accuracy: 0.7039 - val_student_loss: 0.7840\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8817 - student_loss: 0.7970 - distillation_loss: 0.0396 - loss: 0.2668 - val_accuracy: 0.6695 - val_student_loss: 1.0883\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8892 - student_loss: 0.7910 - distillation_loss: 0.0396 - loss: 0.2651 - val_accuracy: 0.7366 - val_student_loss: 1.0285\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8792 - student_loss: 0.7513 - distillation_loss: 0.0395 - loss: 0.2531 - val_accuracy: 0.7693 - val_student_loss: 1.0386\n",
      "\n",
      "\n",
      "00:25:23 train_time\n",
      "\n",
      "1523.9268362522125 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████████████████████████▋                         | 18/27 [7:27:44<3:47:39, 1517.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.5, 'lr': 0.001, 'temperature': 5}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 57s 102ms/step - accuracy: 0.0327 - student_loss: 4.9628 - distillation_loss: 0.3617 - loss: 2.6623 - val_accuracy: 0.0227 - val_student_loss: 16.4213\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.1329 - student_loss: 3.8186 - distillation_loss: 0.3294 - loss: 2.0740 - val_accuracy: 0.0151 - val_student_loss: 32.5788\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.3066 - student_loss: 2.8373 - distillation_loss: 0.3065 - loss: 1.5719 - val_accuracy: 0.0554 - val_student_loss: 30.2287\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.4688 - student_loss: 2.0656 - distillation_loss: 0.2894 - loss: 1.1775 - val_accuracy: 0.1745 - val_student_loss: 11.8760\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.6007 - student_loss: 1.5089 - distillation_loss: 0.2801 - loss: 0.8945 - val_accuracy: 0.2248 - val_student_loss: 8.5213\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6813 - student_loss: 1.2051 - distillation_loss: 0.2753 - loss: 0.7402 - val_accuracy: 0.2139 - val_student_loss: 9.8428\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7508 - student_loss: 0.9717 - distillation_loss: 0.2719 - loss: 0.6218 - val_accuracy: 0.3465 - val_student_loss: 6.6876\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.7764 - student_loss: 0.8416 - distillation_loss: 0.2710 - loss: 0.5563 - val_accuracy: 0.4094 - val_student_loss: 0.4943\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8243 - student_loss: 0.6858 - distillation_loss: 0.2671 - loss: 0.4764 - val_accuracy: 0.6628 - val_student_loss: 3.6264\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8404 - student_loss: 0.6349 - distillation_loss: 0.2669 - loss: 0.4509 - val_accuracy: 0.6753 - val_student_loss: 2.4075\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8872 - student_loss: 0.4829 - distillation_loss: 0.2595 - loss: 0.3712 - val_accuracy: 0.7894 - val_student_loss: 0.5903\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8746 - student_loss: 0.5095 - distillation_loss: 0.2615 - loss: 0.3855 - val_accuracy: 0.7475 - val_student_loss: 0.1327\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8897 - student_loss: 0.4316 - distillation_loss: 0.2612 - loss: 0.3464 - val_accuracy: 0.7232 - val_student_loss: 1.5133\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 50s 102ms/step - accuracy: 0.9290 - student_loss: 0.3260 - distillation_loss: 0.2534 - loss: 0.2897 - val_accuracy: 0.8247 - val_student_loss: 2.4117\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9471 - student_loss: 0.2498 - distillation_loss: 0.2471 - loss: 0.2485 - val_accuracy: 0.8389 - val_student_loss: 0.9574\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9491 - student_loss: 0.2446 - distillation_loss: 0.2432 - loss: 0.2439 - val_accuracy: 0.8255 - val_student_loss: 0.0190\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9668 - student_loss: 0.1988 - distillation_loss: 0.2431 - loss: 0.2210 - val_accuracy: 0.8138 - val_student_loss: 0.1191\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9663 - student_loss: 0.1875 - distillation_loss: 0.2378 - loss: 0.2126 - val_accuracy: 0.8540 - val_student_loss: 0.0948\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9713 - student_loss: 0.1602 - distillation_loss: 0.2342 - loss: 0.1972 - val_accuracy: 0.8649 - val_student_loss: 0.1051\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.9794 - student_loss: 0.1464 - distillation_loss: 0.2301 - loss: 0.1882 - val_accuracy: 0.8565 - val_student_loss: 0.3544\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.9804 - student_loss: 0.1416 - distillation_loss: 0.2284 - loss: 0.1850 - val_accuracy: 0.8683 - val_student_loss: 0.5419\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9814 - student_loss: 0.1428 - distillation_loss: 0.2273 - loss: 0.1851 - val_accuracy: 0.8725 - val_student_loss: 0.4313\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9829 - student_loss: 0.1324 - distillation_loss: 0.2250 - loss: 0.1787 - val_accuracy: 0.8641 - val_student_loss: 0.2334\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9859 - student_loss: 0.1217 - distillation_loss: 0.2230 - loss: 0.1723 - val_accuracy: 0.8792 - val_student_loss: 0.1623\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.9869 - student_loss: 0.1210 - distillation_loss: 0.2221 - loss: 0.1716 - val_accuracy: 0.8809 - val_student_loss: 0.0391\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.9864 - student_loss: 0.1183 - distillation_loss: 0.2218 - loss: 0.1701 - val_accuracy: 0.8775 - val_student_loss: 0.2131\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.9809 - student_loss: 0.1208 - distillation_loss: 0.2174 - loss: 0.1691 - val_accuracy: 0.8767 - val_student_loss: 0.4031\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9869 - student_loss: 0.1099 - distillation_loss: 0.2173 - loss: 0.1636 - val_accuracy: 0.8867 - val_student_loss: 0.7345\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9894 - student_loss: 0.0968 - distillation_loss: 0.2157 - loss: 0.1563 - val_accuracy: 0.8993 - val_student_loss: 0.2874\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 50s 102ms/step - accuracy: 0.9950 - student_loss: 0.0868 - distillation_loss: 0.2126 - loss: 0.1497 - val_accuracy: 0.9077 - val_student_loss: 0.2286\n",
      "\n",
      "\n",
      "00:25:25 train_time\n",
      "\n",
      "1525.8753836154938 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████████▍                      | 19/27 [7:53:11<3:22:44, 1520.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.5, 'lr': 0.001, 'temperature': 2}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 57s 102ms/step - accuracy: 0.0297 - student_loss: 4.9758 - distillation_loss: 4.4408 - loss: 4.7083 - val_accuracy: 0.0227 - val_student_loss: 40.3527\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.1450 - student_loss: 3.7684 - distillation_loss: 3.6592 - loss: 3.7138 - val_accuracy: 0.0378 - val_student_loss: 33.7060\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.2986 - student_loss: 2.7742 - distillation_loss: 2.9220 - loss: 2.8481 - val_accuracy: 0.0252 - val_student_loss: 42.0472\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.4637 - student_loss: 2.0025 - distillation_loss: 2.3086 - loss: 2.1555 - val_accuracy: 0.0587 - val_student_loss: 41.8215\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.5514 - student_loss: 1.5569 - distillation_loss: 1.9143 - loss: 1.7356 - val_accuracy: 0.1988 - val_student_loss: 18.7977\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6697 - student_loss: 1.1767 - distillation_loss: 1.5543 - loss: 1.3655 - val_accuracy: 0.3658 - val_student_loss: 15.0018\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7190 - student_loss: 0.9355 - distillation_loss: 1.3019 - loss: 1.1187 - val_accuracy: 0.4438 - val_student_loss: 9.7978\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.7437 - student_loss: 0.8648 - distillation_loss: 1.2029 - loss: 1.0339 - val_accuracy: 0.3758 - val_student_loss: 5.3908\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8092 - student_loss: 0.6481 - distillation_loss: 1.0199 - loss: 0.8340 - val_accuracy: 0.5831 - val_student_loss: 6.4935\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8077 - student_loss: 0.6212 - distillation_loss: 0.9712 - loss: 0.7962 - val_accuracy: 0.5763 - val_student_loss: 6.4407\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 50s 102ms/step - accuracy: 0.8585 - student_loss: 0.4718 - distillation_loss: 0.8125 - loss: 0.6422 - val_accuracy: 0.6107 - val_student_loss: 6.2719\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8258 - student_loss: 0.5536 - distillation_loss: 0.8602 - loss: 0.7069 - val_accuracy: 0.5998 - val_student_loss: 1.4199\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8575 - student_loss: 0.4308 - distillation_loss: 0.7604 - loss: 0.5956 - val_accuracy: 0.6535 - val_student_loss: 4.3812\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8706 - student_loss: 0.4145 - distillation_loss: 0.7275 - loss: 0.5710 - val_accuracy: 0.6820 - val_student_loss: 0.9669\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8827 - student_loss: 0.3738 - distillation_loss: 0.6751 - loss: 0.5244 - val_accuracy: 0.5956 - val_student_loss: 2.4186\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.9008 - student_loss: 0.3397 - distillation_loss: 0.6464 - loss: 0.4931 - val_accuracy: 0.6309 - val_student_loss: 5.3127\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9310 - student_loss: 0.2226 - distillation_loss: 0.5437 - loss: 0.3831 - val_accuracy: 0.8054 - val_student_loss: 1.4288\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.9436 - student_loss: 0.1836 - distillation_loss: 0.4978 - loss: 0.3407 - val_accuracy: 0.8289 - val_student_loss: 0.1035\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9547 - student_loss: 0.1619 - distillation_loss: 0.4732 - loss: 0.3176 - val_accuracy: 0.8238 - val_student_loss: 0.6609\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9532 - student_loss: 0.1611 - distillation_loss: 0.4604 - loss: 0.3107 - val_accuracy: 0.8305 - val_student_loss: 0.1740\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9466 - student_loss: 0.1649 - distillation_loss: 0.4726 - loss: 0.3188 - val_accuracy: 0.7970 - val_student_loss: 0.3848\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9532 - student_loss: 0.1505 - distillation_loss: 0.4532 - loss: 0.3018 - val_accuracy: 0.8574 - val_student_loss: 0.6133\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9572 - student_loss: 0.1391 - distillation_loss: 0.4415 - loss: 0.2903 - val_accuracy: 0.7987 - val_student_loss: 0.5318\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9537 - student_loss: 0.1559 - distillation_loss: 0.4532 - loss: 0.3046 - val_accuracy: 0.8725 - val_student_loss: 0.0958\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.9602 - student_loss: 0.1313 - distillation_loss: 0.4228 - loss: 0.2770 - val_accuracy: 0.8389 - val_student_loss: 0.0737\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.9748 - student_loss: 0.1054 - distillation_loss: 0.4043 - loss: 0.2548 - val_accuracy: 0.8565 - val_student_loss: 0.0448\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9799 - student_loss: 0.0851 - distillation_loss: 0.3786 - loss: 0.2319 - val_accuracy: 0.8658 - val_student_loss: 0.4240\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9804 - student_loss: 0.0713 - distillation_loss: 0.3632 - loss: 0.2172 - val_accuracy: 0.8733 - val_student_loss: 0.7872\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9768 - student_loss: 0.0848 - distillation_loss: 0.3697 - loss: 0.2272 - val_accuracy: 0.8683 - val_student_loss: 0.4713\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.9819 - student_loss: 0.0698 - distillation_loss: 0.3552 - loss: 0.2125 - val_accuracy: 0.8784 - val_student_loss: 1.0622tillatio\n",
      "\n",
      "\n",
      "00:25:20 train_time\n",
      "\n",
      "1520.031887769699 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|████████████████████████████████████████████████████████▎                   | 20/27 [8:18:32<2:57:24, 1520.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.5, 'lr': 0.001, 'temperature': 10}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 56s 102ms/step - accuracy: 0.0322 - student_loss: 4.9829 - distillation_loss: 0.0405 - loss: 2.5117 - val_accuracy: 0.0092 - val_student_loss: 35.9857\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.1490 - student_loss: 3.9094 - distillation_loss: 0.0400 - loss: 1.9747 - val_accuracy: 0.0285 - val_student_loss: 29.0968\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.2951 - student_loss: 2.8566 - distillation_loss: 0.0422 - loss: 1.4494 - val_accuracy: 0.0143 - val_student_loss: 26.4235\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.4562 - student_loss: 2.1022 - distillation_loss: 0.0453 - loss: 1.0737 - val_accuracy: 0.1007 - val_student_loss: 13.2663\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.5755 - student_loss: 1.6092 - distillation_loss: 0.0486 - loss: 0.8289 - val_accuracy: 0.2450 - val_student_loss: 17.7520\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.6828 - student_loss: 1.2242 - distillation_loss: 0.0522 - loss: 0.6382 - val_accuracy: 0.2257 - val_student_loss: 10.6434\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7236 - student_loss: 1.0294 - distillation_loss: 0.0546 - loss: 0.5420 - val_accuracy: 0.4077 - val_student_loss: 6.6914\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7709 - student_loss: 0.8688 - distillation_loss: 0.0566 - loss: 0.4627 - val_accuracy: 0.4690 - val_student_loss: 1.8682\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7936 - student_loss: 0.7640 - distillation_loss: 0.0586 - loss: 0.4113 - val_accuracy: 0.4916 - val_student_loss: 1.7462\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8233 - student_loss: 0.6737 - distillation_loss: 0.0600 - loss: 0.3668 - val_accuracy: 0.4471 - val_student_loss: 4.3793\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8565 - student_loss: 0.5468 - distillation_loss: 0.0624 - loss: 0.3046 - val_accuracy: 0.5319 - val_student_loss: 6.8919\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8585 - student_loss: 0.5353 - distillation_loss: 0.0646 - loss: 0.2999 - val_accuracy: 0.4673 - val_student_loss: 7.3235\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8646 - student_loss: 0.4851 - distillation_loss: 0.0638 - loss: 0.2745 - val_accuracy: 0.2424 - val_student_loss: 14.2523\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.9320 - student_loss: 0.3097 - distillation_loss: 0.0669 - loss: 0.1883 - val_accuracy: 0.7550 - val_student_loss: 2.7860\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9295 - student_loss: 0.2736 - distillation_loss: 0.0680 - loss: 0.1708 - val_accuracy: 0.8289 - val_student_loss: 2.3878\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9381 - student_loss: 0.2546 - distillation_loss: 0.0689 - loss: 0.1617 - val_accuracy: 0.7961 - val_student_loss: 0.9556\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.9486 - student_loss: 0.2278 - distillation_loss: 0.0681 - loss: 0.1480 - val_accuracy: 0.8389 - val_student_loss: 1.7533\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9502 - student_loss: 0.2430 - distillation_loss: 0.0680 - loss: 0.1555 - val_accuracy: 0.7878 - val_student_loss: 1.2744\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.9451 - student_loss: 0.2332 - distillation_loss: 0.0678 - loss: 0.1505 - val_accuracy: 0.8062 - val_student_loss: 1.1258\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9582 - student_loss: 0.1780 - distillation_loss: 0.0691 - loss: 0.1235 - val_accuracy: 0.8507 - val_student_loss: 1.2045\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.9597 - student_loss: 0.1637 - distillation_loss: 0.0690 - loss: 0.1163 - val_accuracy: 0.8314 - val_student_loss: 1.9515\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.9728 - student_loss: 0.1404 - distillation_loss: 0.0693 - loss: 0.1049 - val_accuracy: 0.8255 - val_student_loss: 2.7981\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9763 - student_loss: 0.1330 - distillation_loss: 0.0702 - loss: 0.1016 - val_accuracy: 0.8356 - val_student_loss: 2.7261\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.9794 - student_loss: 0.1226 - distillation_loss: 0.0695 - loss: 0.0960 - val_accuracy: 0.8633 - val_student_loss: 2.0507\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.9794 - student_loss: 0.1092 - distillation_loss: 0.0685 - loss: 0.0888 - val_accuracy: 0.8733 - val_student_loss: 1.3312\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9804 - student_loss: 0.1079 - distillation_loss: 0.0684 - loss: 0.0881 - val_accuracy: 0.8666 - val_student_loss: 1.3752\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.9794 - student_loss: 0.1149 - distillation_loss: 0.0684 - loss: 0.0917 - val_accuracy: 0.8624 - val_student_loss: 1.7129\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9844 - student_loss: 0.0971 - distillation_loss: 0.0685 - loss: 0.0828 - val_accuracy: 0.8683 - val_student_loss: 0.9325\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9804 - student_loss: 0.1091 - distillation_loss: 0.0677 - loss: 0.0884 - val_accuracy: 0.8733 - val_student_loss: 1.2965\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9869 - student_loss: 0.0856 - distillation_loss: 0.0675 - loss: 0.0765 - val_accuracy: 0.8842 - val_student_loss: 1.1770\n",
      "\n",
      "\n",
      "00:25:26 train_time\n",
      "\n",
      "1526.8041002750397 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████████████████████████████████████████████████████████                 | 21/27 [8:44:00<2:32:17, 1522.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.5, 'lr': 0.01, 'temperature': 5}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 57s 103ms/step - accuracy: 0.0045 - student_loss: 5.4538 - distillation_loss: 0.3764 - loss: 2.9151 - val_accuracy: 0.0059 - val_student_loss: 337.0293\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.0166 - student_loss: 5.1048 - distillation_loss: 0.3680 - loss: 2.7364 - val_accuracy: 0.0050 - val_student_loss: 136.9997\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.0403 - student_loss: 4.6687 - distillation_loss: 0.3617 - loss: 2.5152 - val_accuracy: 0.0050 - val_student_loss: 99.8722\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.1138 - student_loss: 3.9411 - distillation_loss: 0.3511 - loss: 2.1461 - val_accuracy: 0.0050 - val_student_loss: 46.5833\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.1687 - student_loss: 3.4834 - distillation_loss: 0.3481 - loss: 1.9157 - val_accuracy: 0.0101 - val_student_loss: 51.4141\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.2316 - student_loss: 3.0598 - distillation_loss: 0.3456 - loss: 1.7027 - val_accuracy: 0.0201 - val_student_loss: 62.4183\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.3192 - student_loss: 2.6088 - distillation_loss: 0.3441 - loss: 1.4764 - val_accuracy: 0.0218 - val_student_loss: 40.1360\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.3927 - student_loss: 2.2518 - distillation_loss: 0.3465 - loss: 1.2991 - val_accuracy: 0.0092 - val_student_loss: 48.1783\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 51s 103ms/step - accuracy: 0.4728 - student_loss: 1.9283 - distillation_loss: 0.3462 - loss: 1.1373 - val_accuracy: 0.0612 - val_student_loss: 31.5075\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.5342 - student_loss: 1.7238 - distillation_loss: 0.3455 - loss: 1.0346 - val_accuracy: 0.0503 - val_student_loss: 20.6283\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.5725 - student_loss: 1.4799 - distillation_loss: 0.3519 - loss: 0.9159 - val_accuracy: 0.0260 - val_student_loss: 12.3062\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.6556 - student_loss: 1.1988 - distillation_loss: 0.3398 - loss: 0.7693 - val_accuracy: 0.3087 - val_student_loss: 7.1254\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.7477 - student_loss: 0.9109 - distillation_loss: 0.3386 - loss: 0.6247 - val_accuracy: 0.3280 - val_student_loss: 8.9271\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.7533 - student_loss: 0.8896 - distillation_loss: 0.3349 - loss: 0.6122 - val_accuracy: 0.3440 - val_student_loss: 8.1296\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7790 - student_loss: 0.7907 - distillation_loss: 0.3391 - loss: 0.5649 - val_accuracy: 0.2685 - val_student_loss: 4.6350\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.7865 - student_loss: 0.7683 - distillation_loss: 0.3346 - loss: 0.5515 - val_accuracy: 0.3767 - val_student_loss: 2.4011\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8011 - student_loss: 0.7265 - distillation_loss: 0.3310 - loss: 0.5288 - val_accuracy: 0.2785 - val_student_loss: 1.5126\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8122 - student_loss: 0.6860 - distillation_loss: 0.3276 - loss: 0.5068 - val_accuracy: 0.3826 - val_student_loss: 4.3176\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8374 - student_loss: 0.6037 - distillation_loss: 0.3242 - loss: 0.4639 - val_accuracy: 0.4547 - val_student_loss: 1.1155\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8389 - student_loss: 0.5889 - distillation_loss: 0.3228 - loss: 0.4559 - val_accuracy: 0.4069 - val_student_loss: 3.0175\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8681 - student_loss: 0.5121 - distillation_loss: 0.3244 - loss: 0.4182 - val_accuracy: 0.3884 - val_student_loss: 3.7564\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8711 - student_loss: 0.4870 - distillation_loss: 0.3135 - loss: 0.4003 - val_accuracy: 0.4539 - val_student_loss: 2.6308\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 50s 102ms/step - accuracy: 0.8988 - student_loss: 0.4081 - distillation_loss: 0.3088 - loss: 0.3585 - val_accuracy: 0.4471 - val_student_loss: 3.0954\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.9179 - student_loss: 0.3497 - distillation_loss: 0.3029 - loss: 0.3263 - val_accuracy: 0.6200 - val_student_loss: 4.1036\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9300 - student_loss: 0.3192 - distillation_loss: 0.3026 - loss: 0.3109 - val_accuracy: 0.6116 - val_student_loss: 3.0424\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9215 - student_loss: 0.3336 - distillation_loss: 0.2998 - loss: 0.3167 - val_accuracy: 0.5847 - val_student_loss: 3.4417\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.9189 - student_loss: 0.3066 - distillation_loss: 0.2987 - loss: 0.3026 - val_accuracy: 0.6208 - val_student_loss: 3.1913\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9361 - student_loss: 0.2850 - distillation_loss: 0.2939 - loss: 0.2894 - val_accuracy: 0.6745 - val_student_loss: 2.9476\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9396 - student_loss: 0.2934 - distillation_loss: 0.2948 - loss: 0.2941 - val_accuracy: 0.7030 - val_student_loss: 2.0896\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.9371 - student_loss: 0.2771 - distillation_loss: 0.2888 - loss: 0.2829 - val_accuracy: 0.6795 - val_student_loss: 1.9086\n",
      "\n",
      "\n",
      "00:25:27 train_time\n",
      "\n",
      "1527.5117831230164 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|█████████████████████████████████████████████████████████████▉              | 22/27 [9:09:29<2:07:02, 1524.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.5, 'lr': 0.01, 'temperature': 2}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 56s 101ms/step - accuracy: 0.0166 - student_loss: 5.3822 - distillation_loss: 4.6265 - loss: 5.0043 - val_accuracy: 0.0050 - val_student_loss: 158.0955\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.0297 - student_loss: 4.9413 - distillation_loss: 4.2726 - loss: 4.6070 - val_accuracy: 0.0050 - val_student_loss: 146.9702\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.0639 - student_loss: 4.5041 - distillation_loss: 3.9112 - loss: 4.2076 - val_accuracy: 0.0050 - val_student_loss: 148.9325\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.1390 - student_loss: 3.6722 - distillation_loss: 3.3375 - loss: 3.5048 - val_accuracy: 0.0050 - val_student_loss: 66.3634\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.2200 - student_loss: 3.2398 - distillation_loss: 2.9744 - loss: 3.1071 - val_accuracy: 0.0159 - val_student_loss: 46.6875\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.3061 - student_loss: 2.8099 - distillation_loss: 2.6351 - loss: 2.7225 - val_accuracy: 0.0050 - val_student_loss: 57.9779\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.3691 - student_loss: 2.3945 - distillation_loss: 2.3103 - loss: 2.3524 - val_accuracy: 0.0436 - val_student_loss: 31.6539\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 50s 102ms/step - accuracy: 0.4381 - student_loss: 2.0892 - distillation_loss: 2.0675 - loss: 2.0783 - val_accuracy: 0.0159 - val_student_loss: 35.3420\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.4919 - student_loss: 1.8723 - distillation_loss: 1.8705 - loss: 1.8714 - val_accuracy: 0.0352 - val_student_loss: 15.7458\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.6002 - student_loss: 1.3382 - distillation_loss: 1.5204 - loss: 1.4293 - val_accuracy: 0.1049 - val_student_loss: 19.2756\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6788 - student_loss: 1.0839 - distillation_loss: 1.2942 - loss: 1.1891 - val_accuracy: 0.2349 - val_student_loss: 4.1195\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6999 - student_loss: 1.0629 - distillation_loss: 1.2560 - loss: 1.1595 - val_accuracy: 0.2508 - val_student_loss: 10.7497\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7205 - student_loss: 0.9361 - distillation_loss: 1.1754 - loss: 1.0558 - val_accuracy: 0.2500 - val_student_loss: 5.1593\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.7432 - student_loss: 0.8177 - distillation_loss: 1.0776 - loss: 0.9477 - val_accuracy: 0.4178 - val_student_loss: 7.3329\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7518 - student_loss: 0.8344 - distillation_loss: 1.0570 - loss: 0.9457 - val_accuracy: 0.2181 - val_student_loss: 0.1175\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7664 - student_loss: 0.7607 - distillation_loss: 1.0116 - loss: 0.8862 - val_accuracy: 0.3414 - val_student_loss: 3.0762\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8197 - student_loss: 0.6132 - distillation_loss: 0.8932 - loss: 0.7532 - val_accuracy: 0.4807 - val_student_loss: 2.4431\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8379 - student_loss: 0.5398 - distillation_loss: 0.8436 - loss: 0.6917 - val_accuracy: 0.4849 - val_student_loss: 6.1339\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 51s 103ms/step - accuracy: 0.8434 - student_loss: 0.5065 - distillation_loss: 0.8099 - loss: 0.6582 - val_accuracy: 0.5218 - val_student_loss: 2.3666\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8550 - student_loss: 0.4491 - distillation_loss: 0.7670 - loss: 0.6081 - val_accuracy: 0.6065 - val_student_loss: 1.8178\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8671 - student_loss: 0.4460 - distillation_loss: 0.7602 - loss: 0.6031 - val_accuracy: 0.5671 - val_student_loss: 4.9008\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8600 - student_loss: 0.4442 - distillation_loss: 0.7615 - loss: 0.6028 - val_accuracy: 0.5210 - val_student_loss: 4.9619\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8766 - student_loss: 0.4103 - distillation_loss: 0.7207 - loss: 0.5655 - val_accuracy: 0.6191 - val_student_loss: 6.2410\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8802 - student_loss: 0.3925 - distillation_loss: 0.7006 - loss: 0.5465 - val_accuracy: 0.6216 - val_student_loss: 3.0235\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8902 - student_loss: 0.3385 - distillation_loss: 0.6622 - loss: 0.5003 - val_accuracy: 0.6502 - val_student_loss: 3.0663\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8867 - student_loss: 0.3868 - distillation_loss: 0.6904 - loss: 0.5386 - val_accuracy: 0.6015 - val_student_loss: 1.2030\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8948 - student_loss: 0.3120 - distillation_loss: 0.6494 - loss: 0.4807 - val_accuracy: 0.6938 - val_student_loss: 2.6884\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9028 - student_loss: 0.3252 - distillation_loss: 0.6518 - loss: 0.4885 - val_accuracy: 0.6879 - val_student_loss: 4.2056\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.9179 - student_loss: 0.2825 - distillation_loss: 0.6170 - loss: 0.4498 - val_accuracy: 0.6334 - val_student_loss: 5.1436\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9144 - student_loss: 0.2770 - distillation_loss: 0.6115 - loss: 0.4442 - val_accuracy: 0.7022 - val_student_loss: 3.9971\n",
      "\n",
      "\n",
      "00:25:22 train_time\n",
      "\n",
      "1522.347653388977 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████████████████████████████████████████████████████████████▋           | 23/27 [9:34:52<1:41:37, 1524.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.5, 'lr': 0.01, 'temperature': 10}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 57s 103ms/step - accuracy: 0.0081 - student_loss: 5.3888 - distillation_loss: 0.0420 - loss: 2.7154 - val_accuracy: 0.0050 - val_student_loss: 260.7854\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.0277 - student_loss: 4.9429 - distillation_loss: 0.0430 - loss: 2.4929 - val_accuracy: 0.0050 - val_student_loss: 230.3529\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.0493 - student_loss: 4.5100 - distillation_loss: 0.0456 - loss: 2.2778 - val_accuracy: 0.0067 - val_student_loss: 175.1052\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.0942 - student_loss: 4.0780 - distillation_loss: 0.0492 - loss: 2.0636 - val_accuracy: 0.0050 - val_student_loss: 175.9406\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.1410 - student_loss: 3.6830 - distillation_loss: 0.0543 - loss: 1.8686 - val_accuracy: 0.0050 - val_student_loss: 73.9052\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.2674 - student_loss: 2.8724 - distillation_loss: 0.0597 - loss: 1.4660 - val_accuracy: 0.0285 - val_student_loss: 25.8044\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.3359 - student_loss: 2.5158 - distillation_loss: 0.0650 - loss: 1.2904 - val_accuracy: 0.0419 - val_student_loss: 15.7631\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.3933 - student_loss: 2.2242 - distillation_loss: 0.0703 - loss: 1.1473 - val_accuracy: 0.0805 - val_student_loss: 0.2046\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.4632 - student_loss: 1.9538 - distillation_loss: 0.0747 - loss: 1.0143 - val_accuracy: 0.1300 - val_student_loss: 5.9080\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.5156 - student_loss: 1.7603 - distillation_loss: 0.0791 - loss: 0.9197 - val_accuracy: 0.1351 - val_student_loss: 1.0847\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.5539 - student_loss: 1.5793 - distillation_loss: 0.0814 - loss: 0.8303 - val_accuracy: 0.0965 - val_student_loss: 5.5383\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.5614 - student_loss: 1.5553 - distillation_loss: 0.0840 - loss: 0.8196 - val_accuracy: 0.0797 - val_student_loss: 0.0867\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.6798 - student_loss: 1.1101 - distillation_loss: 0.0859 - loss: 0.5980 - val_accuracy: 0.3213 - val_student_loss: 0.5354\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7075 - student_loss: 1.0229 - distillation_loss: 0.0903 - loss: 0.5566 - val_accuracy: 0.3599 - val_student_loss: 1.4706\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.7382 - student_loss: 0.9073 - distillation_loss: 0.0913 - loss: 0.4993 - val_accuracy: 0.3465 - val_student_loss: 0.5423\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7538 - student_loss: 0.8656 - distillation_loss: 0.0944 - loss: 0.4800 - val_accuracy: 0.4698 - val_student_loss: 2.8292\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7644 - student_loss: 0.7848 - distillation_loss: 0.0974 - loss: 0.4411 - val_accuracy: 0.4413 - val_student_loss: 5.0136\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.7800 - student_loss: 0.7610 - distillation_loss: 0.0966 - loss: 0.4288 - val_accuracy: 0.0789 - val_student_loss: 14.7716\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8238 - student_loss: 0.6134 - distillation_loss: 0.0958 - loss: 0.3546 - val_accuracy: 0.3666 - val_student_loss: 7.7226\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8414 - student_loss: 0.5610 - distillation_loss: 0.0971 - loss: 0.3291 - val_accuracy: 0.5268 - val_student_loss: 3.0501\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8535 - student_loss: 0.5212 - distillation_loss: 0.0988 - loss: 0.3100 - val_accuracy: 0.4841 - val_student_loss: 4.3195\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8464 - student_loss: 0.5255 - distillation_loss: 0.0983 - loss: 0.3119 - val_accuracy: 0.6326 - val_student_loss: 1.6910\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8404 - student_loss: 0.5207 - distillation_loss: 0.0992 - loss: 0.3099 - val_accuracy: 0.5176 - val_student_loss: 4.0339\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8535 - student_loss: 0.4977 - distillation_loss: 0.0995 - loss: 0.2986 - val_accuracy: 0.5663 - val_student_loss: 1.4144\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8731 - student_loss: 0.4528 - distillation_loss: 0.0988 - loss: 0.2758 - val_accuracy: 0.7030 - val_student_loss: 2.0517\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8822 - student_loss: 0.4224 - distillation_loss: 0.0989 - loss: 0.2607 - val_accuracy: 0.6862 - val_student_loss: 0.9538\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8912 - student_loss: 0.3793 - distillation_loss: 0.0980 - loss: 0.2386 - val_accuracy: 0.6946 - val_student_loss: 2.2612\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8993 - student_loss: 0.3711 - distillation_loss: 0.0997 - loss: 0.2354 - val_accuracy: 0.6963 - val_student_loss: 2.8294\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.9013 - student_loss: 0.3561 - distillation_loss: 0.0990 - loss: 0.2276 - val_accuracy: 0.7366 - val_student_loss: 3.1238\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8993 - student_loss: 0.3538 - distillation_loss: 0.0992 - loss: 0.2265 - val_accuracy: 0.7592 - val_student_loss: 3.1359\n",
      "\n",
      "\n",
      "00:25:25 train_time\n",
      "\n",
      "1525.2493464946747 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|██████████████████████████████████████████████████████████████████▋        | 24/27 [10:00:18<1:16:14, 1524.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.5, 'lr': 0.0001, 'temperature': 5}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 57s 102ms/step - accuracy: 0.0166 - student_loss: 5.2639 - distillation_loss: 0.3713 - loss: 2.8176 - val_accuracy: 0.0143 - val_student_loss: 4.1794\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 50s 102ms/step - accuracy: 0.0524 - student_loss: 4.8962 - distillation_loss: 0.3605 - loss: 2.6284 - val_accuracy: 0.0084 - val_student_loss: 3.9659\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.0906 - student_loss: 4.5830 - distillation_loss: 0.3517 - loss: 2.4673 - val_accuracy: 0.0495 - val_student_loss: 4.4192\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.1425 - student_loss: 4.2093 - distillation_loss: 0.3413 - loss: 2.2753 - val_accuracy: 0.0738 - val_student_loss: 3.8894\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 50s 102ms/step - accuracy: 0.1969 - student_loss: 3.8956 - distillation_loss: 0.3326 - loss: 2.1141 - val_accuracy: 0.1015 - val_student_loss: 4.4612\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.2533 - student_loss: 3.5585 - distillation_loss: 0.3232 - loss: 1.9408 - val_accuracy: 0.0730 - val_student_loss: 6.4047\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.3102 - student_loss: 3.2488 - distillation_loss: 0.3161 - loss: 1.7825 - val_accuracy: 0.1376 - val_student_loss: 5.3657\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.3731 - student_loss: 2.9890 - distillation_loss: 0.3081 - loss: 1.6485 - val_accuracy: 0.1023 - val_student_loss: 5.4269\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.4345 - student_loss: 2.7048 - distillation_loss: 0.3011 - loss: 1.5029 - val_accuracy: 0.1820 - val_student_loss: 4.9385\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.4930 - student_loss: 2.4683 - distillation_loss: 0.2943 - loss: 1.3813 - val_accuracy: 0.3255 - val_student_loss: 2.8341\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.5423 - student_loss: 2.2015 - distillation_loss: 0.2864 - loss: 1.2440 - val_accuracy: 0.4329 - val_student_loss: 2.4333\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6078 - student_loss: 1.9847 - distillation_loss: 0.2810 - loss: 1.1329 - val_accuracy: 0.3087 - val_student_loss: 4.8664\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.6526 - student_loss: 1.8088 - distillation_loss: 0.2756 - loss: 1.0422 - val_accuracy: 0.5503 - val_student_loss: 2.6301\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.6788 - student_loss: 1.6490 - distillation_loss: 0.2710 - loss: 0.9600 - val_accuracy: 0.4421 - val_student_loss: 3.4351\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6923 - student_loss: 1.5548 - distillation_loss: 0.2680 - loss: 0.9114 - val_accuracy: 0.6602 - val_student_loss: 2.5977\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7331 - student_loss: 1.3799 - distillation_loss: 0.2632 - loss: 0.8215 - val_accuracy: 0.4924 - val_student_loss: 4.8299\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.7699 - student_loss: 1.2695 - distillation_loss: 0.2591 - loss: 0.7643 - val_accuracy: 0.5604 - val_student_loss: 3.5233\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7941 - student_loss: 1.1332 - distillation_loss: 0.2553 - loss: 0.6943 - val_accuracy: 0.6040 - val_student_loss: 1.8831\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8273 - student_loss: 0.9994 - distillation_loss: 0.2496 - loss: 0.6245 - val_accuracy: 0.7081 - val_student_loss: 1.2783\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8439 - student_loss: 0.9769 - distillation_loss: 0.2496 - loss: 0.6132 - val_accuracy: 0.6409 - val_student_loss: 2.2525\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8499 - student_loss: 0.9171 - distillation_loss: 0.2475 - loss: 0.5823 - val_accuracy: 0.6636 - val_student_loss: 1.6138\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8620 - student_loss: 0.8647 - distillation_loss: 0.2448 - loss: 0.5547 - val_accuracy: 0.6988 - val_student_loss: 1.6856\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8635 - student_loss: 0.8461 - distillation_loss: 0.2445 - loss: 0.5453 - val_accuracy: 0.7181 - val_student_loss: 2.0204\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8902 - student_loss: 0.7801 - distillation_loss: 0.2427 - loss: 0.5114 - val_accuracy: 0.7013 - val_student_loss: 1.7373\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8797 - student_loss: 0.7819 - distillation_loss: 0.2426 - loss: 0.5122 - val_accuracy: 0.7097 - val_student_loss: 1.8080\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8867 - student_loss: 0.7617 - distillation_loss: 0.2409 - loss: 0.5013 - val_accuracy: 0.7458 - val_student_loss: 1.5285\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8892 - student_loss: 0.7291 - distillation_loss: 0.2396 - loss: 0.4843 - val_accuracy: 0.7433 - val_student_loss: 1.4632\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8897 - student_loss: 0.7515 - distillation_loss: 0.2408 - loss: 0.4962 - val_accuracy: 0.7433 - val_student_loss: 1.3053\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9023 - student_loss: 0.6935 - distillation_loss: 0.2379 - loss: 0.4657 - val_accuracy: 0.7483 - val_student_loss: 1.3220\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.9023 - student_loss: 0.6890 - distillation_loss: 0.2382 - loss: 0.4636 - val_accuracy: 0.7416 - val_student_loss: 1.5384\n",
      "\n",
      "\n",
      "00:25:22 train_time\n",
      "\n",
      "1522.7268521785736 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|███████████████████████████████████████████████████████████████████████▎     | 25/27 [10:25:42<50:49, 1524.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.5, 'lr': 0.0001, 'temperature': 2}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 56s 102ms/step - accuracy: 0.0171 - student_loss: 5.2694 - distillation_loss: 4.6332 - loss: 4.9513 - val_accuracy: 0.0134 - val_student_loss: 4.5133\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.0463 - student_loss: 4.8880 - distillation_loss: 4.4403 - loss: 4.6642 - val_accuracy: 0.0277 - val_student_loss: 3.7015\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.0801 - student_loss: 4.5725 - distillation_loss: 4.2667 - loss: 4.4196 - val_accuracy: 0.0336 - val_student_loss: 3.7453\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.1274 - student_loss: 4.2072 - distillation_loss: 4.0580 - loss: 4.1326 - val_accuracy: 0.1023 - val_student_loss: 4.8592\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.1798 - student_loss: 3.8661 - distillation_loss: 3.8556 - loss: 3.8609 - val_accuracy: 0.0654 - val_student_loss: 5.4654\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.2281 - student_loss: 3.5184 - distillation_loss: 3.6470 - loss: 3.5827 - val_accuracy: 0.1384 - val_student_loss: 4.2483\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.3092 - student_loss: 3.1776 - distillation_loss: 3.4365 - loss: 3.3071 - val_accuracy: 0.1158 - val_student_loss: 3.6842\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.3374 - student_loss: 2.9436 - distillation_loss: 3.2779 - loss: 3.1108 - val_accuracy: 0.1938 - val_student_loss: 3.3229\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 52s 104ms/step - accuracy: 0.4104 - student_loss: 2.6533 - distillation_loss: 3.0872 - loss: 2.8702 - val_accuracy: 0.2483 - val_student_loss: 2.8648\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.4466 - student_loss: 2.4595 - distillation_loss: 2.9597 - loss: 2.7096 - val_accuracy: 0.2005 - val_student_loss: 3.2915\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.4879 - student_loss: 2.1944 - distillation_loss: 2.7661 - loss: 2.4802 - val_accuracy: 0.3876 - val_student_loss: 1.4164\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 53s 106ms/step - accuracy: 0.5237 - student_loss: 2.0384 - distillation_loss: 2.6393 - loss: 2.3388 - val_accuracy: 0.3389 - val_student_loss: 2.4453\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.5831 - student_loss: 1.8121 - distillation_loss: 2.4857 - loss: 2.1489 - val_accuracy: 0.3423 - val_student_loss: 3.0194\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 49s 100ms/step - accuracy: 0.6506 - student_loss: 1.5777 - distillation_loss: 2.3113 - loss: 1.9445 - val_accuracy: 0.4891 - val_student_loss: 1.7853\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.6782 - student_loss: 1.4588 - distillation_loss: 2.2047 - loss: 1.8317 - val_accuracy: 0.4690 - val_student_loss: 2.0671\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.6833 - student_loss: 1.4419 - distillation_loss: 2.1828 - loss: 1.8124 - val_accuracy: 0.5285 - val_student_loss: 1.9192\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.6873 - student_loss: 1.3295 - distillation_loss: 2.0927 - loss: 1.7111 - val_accuracy: 0.5092 - val_student_loss: 3.3033\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.7085 - student_loss: 1.2705 - distillation_loss: 2.0412 - loss: 1.6558 - val_accuracy: 0.6032 - val_student_loss: 1.8001\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.7336 - student_loss: 1.1708 - distillation_loss: 1.9541 - loss: 1.5625 - val_accuracy: 0.5705 - val_student_loss: 2.3128\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.7503 - student_loss: 1.1193 - distillation_loss: 1.9067 - loss: 1.5130 - val_accuracy: 0.6544 - val_student_loss: 1.8755\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.7674 - student_loss: 1.0375 - distillation_loss: 1.8198 - loss: 1.4287 - val_accuracy: 0.4958 - val_student_loss: 3.5553\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.7790 - student_loss: 1.0032 - distillation_loss: 1.7841 - loss: 1.3937 - val_accuracy: 0.5579 - val_student_loss: 3.4122\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.7810 - student_loss: 0.9649 - distillation_loss: 1.7311 - loss: 1.3480 - val_accuracy: 0.6846 - val_student_loss: 1.2533\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 49s 98ms/step - accuracy: 0.8046 - student_loss: 0.9149 - distillation_loss: 1.7015 - loss: 1.3082 - val_accuracy: 0.6728 - val_student_loss: 1.7088\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 49s 99ms/step - accuracy: 0.8112 - student_loss: 0.8514 - distillation_loss: 1.6345 - loss: 1.2429 - val_accuracy: 0.6997 - val_student_loss: 1.4219\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 54s 109ms/step - accuracy: 0.8233 - student_loss: 0.8502 - distillation_loss: 1.6275 - loss: 1.2388 - val_accuracy: 0.6938 - val_student_loss: 1.5024\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 54s 109ms/step - accuracy: 0.8177 - student_loss: 0.8400 - distillation_loss: 1.6031 - loss: 1.2216 - val_accuracy: 0.7072 - val_student_loss: 1.3729\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 54s 109ms/step - accuracy: 0.8268 - student_loss: 0.8045 - distillation_loss: 1.5681 - loss: 1.1863 - val_accuracy: 0.7097 - val_student_loss: 2.0523\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 59s 119ms/step - accuracy: 0.8273 - student_loss: 0.7866 - distillation_loss: 1.5524 - loss: 1.1695 - val_accuracy: 0.6971 - val_student_loss: 1.8252\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 54s 109ms/step - accuracy: 0.8424 - student_loss: 0.7457 - distillation_loss: 1.5157 - loss: 1.1307 - val_accuracy: 0.6904 - val_student_loss: 1.4372\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "\n",
      "00:25:31 train_time\n",
      "\n",
      "1531.8441197872162 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|██████████████████████████████████████████████████████████████████████████▏  | 26/27 [10:51:15<25:27, 1527.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT PARAMETERS: {'alpha': 0.5, 'lr': 0.0001, 'temperature': 10}\n",
      "TEACHER MODEL LOADED SUCCESSFULLY!\n",
      "STUDENT MODEL SUCESSFULLY BUILT!\n",
      "\n",
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n",
      "Epoch 1/30\n",
      "497/497 [==============================] - 61s 110ms/step - accuracy: 0.0131 - student_loss: 5.2748 - distillation_loss: 0.0411 - loss: 2.6580 - val_accuracy: 0.0134 - val_student_loss: 4.3775\n",
      "Epoch 2/30\n",
      "497/497 [==============================] - 55s 110ms/step - accuracy: 0.0514 - student_loss: 4.9254 - distillation_loss: 0.0399 - loss: 2.4827 - val_accuracy: 0.0201 - val_student_loss: 4.2174\n",
      "Epoch 3/30\n",
      "497/497 [==============================] - 54s 108ms/step - accuracy: 0.0856 - student_loss: 4.5858 - distillation_loss: 0.0393 - loss: 2.3126 - val_accuracy: 0.0529 - val_student_loss: 4.3537\n",
      "Epoch 4/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.1475 - student_loss: 4.2399 - distillation_loss: 0.0387 - loss: 2.1393 - val_accuracy: 0.0688 - val_student_loss: 3.1097\n",
      "Epoch 5/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.1757 - student_loss: 3.9186 - distillation_loss: 0.0385 - loss: 1.9786 - val_accuracy: 0.1107 - val_student_loss: 4.2556\n",
      "Epoch 6/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.2518 - student_loss: 3.5374 - distillation_loss: 0.0381 - loss: 1.7877 - val_accuracy: 0.1443 - val_student_loss: 2.9896\n",
      "Epoch 7/30\n",
      "497/497 [==============================] - 49s 100ms/step - accuracy: 0.3177 - student_loss: 3.2581 - distillation_loss: 0.0380 - loss: 1.6481 - val_accuracy: 0.1669 - val_student_loss: 4.0211\n",
      "Epoch 8/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.3661 - student_loss: 2.9651 - distillation_loss: 0.0380 - loss: 1.5015 - val_accuracy: 0.1770 - val_student_loss: 4.3903\n",
      "Epoch 9/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.4361 - student_loss: 2.6815 - distillation_loss: 0.0378 - loss: 1.3596 - val_accuracy: 0.3582 - val_student_loss: 3.0305\n",
      "Epoch 10/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.4990 - student_loss: 2.4520 - distillation_loss: 0.0378 - loss: 1.2449 - val_accuracy: 0.3129 - val_student_loss: 2.7424\n",
      "Epoch 11/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.5418 - student_loss: 2.2043 - distillation_loss: 0.0379 - loss: 1.1211 - val_accuracy: 0.3616 - val_student_loss: 3.7751\n",
      "Epoch 12/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.5670 - student_loss: 2.0402 - distillation_loss: 0.0382 - loss: 1.0392 - val_accuracy: 0.3683 - val_student_loss: 5.6165\n",
      "Epoch 13/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6380 - student_loss: 1.8361 - distillation_loss: 0.0382 - loss: 0.9372 - val_accuracy: 0.2466 - val_student_loss: 4.3999\n",
      "Epoch 14/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.6843 - student_loss: 1.6456 - distillation_loss: 0.0384 - loss: 0.8420 - val_accuracy: 0.6107 - val_student_loss: 2.5071\n",
      "Epoch 15/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7130 - student_loss: 1.4782 - distillation_loss: 0.0388 - loss: 0.7585 - val_accuracy: 0.5889 - val_student_loss: 2.9141\n",
      "Epoch 16/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7326 - student_loss: 1.3870 - distillation_loss: 0.0392 - loss: 0.7131 - val_accuracy: 0.4069 - val_student_loss: 4.4844\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 17/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7694 - student_loss: 1.2223 - distillation_loss: 0.0394 - loss: 0.6308 - val_accuracy: 0.5982 - val_student_loss: 1.7814\n",
      "Epoch 18/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.7971 - student_loss: 1.1539 - distillation_loss: 0.0393 - loss: 0.5966 - val_accuracy: 0.5856 - val_student_loss: 2.3970\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 19/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8182 - student_loss: 1.0752 - distillation_loss: 0.0393 - loss: 0.5573 - val_accuracy: 0.7164 - val_student_loss: 1.7855\n",
      "Epoch 20/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8323 - student_loss: 1.0255 - distillation_loss: 0.0392 - loss: 0.5324 - val_accuracy: 0.6669 - val_student_loss: 1.6639\n",
      "Epoch 21/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8474 - student_loss: 0.9482 - distillation_loss: 0.0391 - loss: 0.4937 - val_accuracy: 0.6988 - val_student_loss: 1.3709\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 22/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8479 - student_loss: 0.9588 - distillation_loss: 0.0393 - loss: 0.4990 - val_accuracy: 0.7223 - val_student_loss: 1.2937\n",
      "Epoch 23/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8469 - student_loss: 0.9661 - distillation_loss: 0.0394 - loss: 0.5028 - val_accuracy: 0.7240 - val_student_loss: 1.3339\n",
      "Epoch 24/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8575 - student_loss: 0.9198 - distillation_loss: 0.0395 - loss: 0.4797 - val_accuracy: 0.7215 - val_student_loss: 1.4244\n",
      "Epoch 25/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8676 - student_loss: 0.8681 - distillation_loss: 0.0394 - loss: 0.4538 - val_accuracy: 0.7156 - val_student_loss: 1.5336\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 26/30\n",
      "497/497 [==============================] - 50s 100ms/step - accuracy: 0.8666 - student_loss: 0.8887 - distillation_loss: 0.0397 - loss: 0.4642 - val_accuracy: 0.7399 - val_student_loss: 1.5333\n",
      "Epoch 27/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8610 - student_loss: 0.9073 - distillation_loss: 0.0394 - loss: 0.4734 - val_accuracy: 0.7290 - val_student_loss: 1.6568\n",
      "Epoch 28/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8676 - student_loss: 0.8852 - distillation_loss: 0.0395 - loss: 0.4624 - val_accuracy: 0.7399 - val_student_loss: 1.5079\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 29/30\n",
      "497/497 [==============================] - 50s 101ms/step - accuracy: 0.8600 - student_loss: 0.8787 - distillation_loss: 0.0395 - loss: 0.4591 - val_accuracy: 0.7366 - val_student_loss: 1.5288\n",
      "Epoch 30/30\n",
      "497/497 [==============================] - 51s 102ms/step - accuracy: 0.8721 - student_loss: 0.8635 - distillation_loss: 0.0394 - loss: 0.4514 - val_accuracy: 0.7408 - val_student_loss: 1.4433\n",
      "\n",
      "\n",
      "00:25:33 train_time\n",
      "\n",
      "1533.4774825572968 Seconds\n",
      "\n",
      "\n",
      "MODEL SERIALIZING WAIT FOR A MOMENT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 27/27 [11:16:50<00:00, 1504.10s/it]\n"
     ]
    }
   ],
   "source": [
    "dummy_x = []\n",
    "dummy_y = []\n",
    "\n",
    "# HPO PARAMETERS\n",
    "p = {\n",
    "    'temperature':TEMPERATURE,\n",
    "    'alpha':ALPHA,\n",
    "    'lr':LEARNING_RATE\n",
    "    }\n",
    "\n",
    "def distiller_model(x_train, y_train, x_val, y_val, params):\n",
    "    print(\"\\nCURRENT PARAMETERS:\", params)\n",
    "\n",
    "    #START TIMER\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #GET NEW TEACHER AND STUDENT MODEL\n",
    "    teacher = get_teacher()\n",
    "    student = get_student(MODEL_INPUT)\n",
    "\n",
    "    #SET CALLBACK\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                              factor=0.5, \n",
    "                              patience=2,\n",
    "                              verbose=1, \n",
    "                              mode='max', \n",
    "                              min_lr=0.000001)\n",
    "\n",
    "    callbacks = [reduce_lr]\n",
    "\n",
    "    #CREATE KNOWLEDGE DISTILLER\n",
    "    distiller = KDistiller(\n",
    "        student=student,teacher=teacher,\n",
    "        student_preprocess=student_preprocess,\n",
    "        teacher_preprocess=teacher_preprocess\n",
    "    )\n",
    "\n",
    "    #COMPILE KNOWLEDGE DISTILLER\n",
    "    distiller.compile(\n",
    "        optimizer = OPTIMIZER(learning_rate=params['lr']),\n",
    "        metrics=['accuracy'],\n",
    "        student_loss_fn=CategoricalCrossentropy(from_logits=True),\n",
    "        distillation_loss_fn= KLDivergence(),\n",
    "        alpha=params['alpha'],\n",
    "        temperature=params['temperature'],\n",
    "    )\n",
    "\n",
    "    print()\n",
    "    (train_generator, nb_train_samples), (validation_generator, nb_validation_samples) = create_data_generator()\n",
    "\n",
    "    #DISTILLING\n",
    "    distiller_history = distiller.fit(train_generator,\n",
    "                                        validation_data = validation_generator,\n",
    "                                        steps_per_epoch = nb_train_samples // BATCH_SIZE,\n",
    "                                        validation_steps = nb_validation_samples // BATCH_SIZE,\n",
    "                                        epochs=EPOCHS,\n",
    "                                        callbacks=callbacks, \n",
    "                                      )\n",
    "    #STOP TIMER\n",
    "    elapsed_time = time.time() - start_time\n",
    "    train_time = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n",
    "    print('\\n\\n' + train_time, 'train_time\\n')\n",
    "    print(elapsed_time, 'Seconds\\n\\n')\n",
    "\n",
    "    print(\"MODEL SERIALIZING WAIT FOR A MOMENT...\\n\")\n",
    "    save_m(distiller.student, HPO_PATH + '/HPO(t={0},a={1},l={2})'.format(params['temperature'],params['alpha'],params['lr']), MODEL_NAME)\n",
    "    save_h(distiller_history.history, HPO_PATH + '/HPO(t={0},a={1},l={2})'.format(params['temperature'],params['alpha'],params['lr']), MODEL_NAME)\n",
    "\n",
    "    return distiller_history, distiller.student\n",
    "\n",
    "scan_object = talos.Scan(dummy_x, dummy_y,\n",
    "                         x_val=dummy_x, y_val=dummy_y, \n",
    "                         model=distiller_model,\n",
    "                         experiment_name='logs/',\n",
    "                         params=p,\n",
    "                         print_params=False,\n",
    "                         save_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qZp-sCjlEuYK",
   "metadata": {
    "id": "qZp-sCjlEuYK"
   },
   "source": [
    "**Select Best Student**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "A5yU3-F0DauE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5yU3-F0DauE",
    "outputId": "d88e81ca-3c88-487c-ffa6-b4676edb00f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD TRAIN SAMPLES...\n",
      "Found 1990 images belonging to 199 classes.\n",
      "\n",
      "LOAD VALIDATION SAMPLES...\n",
      "Found 1194 images belonging to 199 classes.\n",
      "\n",
      "GENERATER ARE SET!\n",
      "CLASSES TO TRAIN 199 classes\n"
     ]
    }
   ],
   "source": [
    "#Re-Create Data Generator\n",
    "_, (validation_generator, nb_validation_samples)  = create_data_generator(pre_process=student_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "UHjmbQQaA3Q2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHjmbQQaA3Q2",
    "outputId": "5fde7e24-e783-4e87-bbd5-906b9a0c0859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For Temperature = 5 & alpha= 0.1 & lr=0.001\n",
      "299/299 [==============================] - 610s 2s/step - loss: 0.3667 - accuracy: 0.8928\n",
      "\n",
      "For Temperature = 5 & alpha= 0.1 & lr=0.01\n",
      "299/299 [==============================] - 43s 138ms/step - loss: 0.6484 - accuracy: 0.8258\n",
      "\n",
      "For Temperature = 5 & alpha= 0.1 & lr=0.0001\n",
      "299/299 [==============================] - 42s 136ms/step - loss: 1.1775 - accuracy: 0.7228\n",
      "\n",
      "For Temperature = 2 & alpha= 0.1 & lr=0.001\n",
      "299/299 [==============================] - 42s 138ms/step - loss: 0.5775 - accuracy: 0.8635\n",
      "\n",
      "For Temperature = 2 & alpha= 0.1 & lr=0.01\n",
      "299/299 [==============================] - 43s 139ms/step - loss: 1.4883 - accuracy: 0.7010\n",
      "\n",
      "For Temperature = 2 & alpha= 0.1 & lr=0.0001\n",
      "299/299 [==============================] - 42s 138ms/step - loss: 1.5397 - accuracy: 0.6072\n",
      "\n",
      "For Temperature = 10 & alpha= 0.1 & lr=0.001\n",
      "299/299 [==============================] - 43s 139ms/step - loss: 0.3709 - accuracy: 0.8936\n",
      "\n",
      "For Temperature = 10 & alpha= 0.1 & lr=0.01\n",
      "299/299 [==============================] - 43s 138ms/step - loss: 1.0784 - accuracy: 0.7169\n",
      "\n",
      "For Temperature = 10 & alpha= 0.1 & lr=0.0001\n",
      "299/299 [==============================] - 43s 141ms/step - loss: 1.1825 - accuracy: 0.7345\n",
      "\n",
      "For Temperature = 5 & alpha= 0.3 & lr=0.001\n",
      "299/299 [==============================] - 44s 141ms/step - loss: 0.3777 - accuracy: 0.8878\n",
      "\n",
      "For Temperature = 5 & alpha= 0.3 & lr=0.01\n",
      "299/299 [==============================] - 43s 139ms/step - loss: 1.2554 - accuracy: 0.6633\n",
      "\n",
      "For Temperature = 5 & alpha= 0.3 & lr=0.0001\n",
      "299/299 [==============================] - 44s 143ms/step - loss: 1.3429 - accuracy: 0.6742\n",
      "\n",
      "For Temperature = 2 & alpha= 0.3 & lr=0.001\n",
      "299/299 [==============================] - 44s 142ms/step - loss: 0.5977 - accuracy: 0.8702\n",
      "\n",
      "For Temperature = 2 & alpha= 0.3 & lr=0.01\n",
      "299/299 [==============================] - 43s 140ms/step - loss: 1.5746 - accuracy: 0.6767\n",
      "\n",
      "For Temperature = 2 & alpha= 0.3 & lr=0.0001\n",
      "299/299 [==============================] - 43s 140ms/step - loss: 1.5230 - accuracy: 0.6139\n",
      "\n",
      "For Temperature = 10 & alpha= 0.3 & lr=0.001\n",
      "299/299 [==============================] - 44s 141ms/step - loss: 0.4734 - accuracy: 0.8643\n",
      "\n",
      "For Temperature = 10 & alpha= 0.3 & lr=0.01\n",
      "299/299 [==============================] - 44s 140ms/step - loss: 1.1711 - accuracy: 0.7052\n",
      "\n",
      "For Temperature = 10 & alpha= 0.3 & lr=0.0001\n",
      "299/299 [==============================] - 43s 141ms/step - loss: 1.0048 - accuracy: 0.7697\n",
      "\n",
      "For Temperature = 5 & alpha= 0.5 & lr=0.001\n",
      "299/299 [==============================] - 43s 141ms/step - loss: 0.3358 - accuracy: 0.9079\n",
      "\n",
      "For Temperature = 5 & alpha= 0.5 & lr=0.01\n",
      "299/299 [==============================] - 43s 139ms/step - loss: 1.1863 - accuracy: 0.6792\n",
      "\n",
      "For Temperature = 5 & alpha= 0.5 & lr=0.0001\n",
      "299/299 [==============================] - 43s 141ms/step - loss: 1.0359 - accuracy: 0.7404\n",
      "\n",
      "For Temperature = 2 & alpha= 0.5 & lr=0.001\n",
      "299/299 [==============================] - 43s 140ms/step - loss: 0.5249 - accuracy: 0.8777\n",
      "\n",
      "For Temperature = 2 & alpha= 0.5 & lr=0.01\n",
      "299/299 [==============================] - 44s 143ms/step - loss: 1.4169 - accuracy: 0.7010\n",
      "\n",
      "For Temperature = 2 & alpha= 0.5 & lr=0.0001\n",
      "299/299 [==============================] - 44s 143ms/step - loss: 1.1875 - accuracy: 0.6901\n",
      "\n",
      "For Temperature = 10 & alpha= 0.5 & lr=0.001\n",
      "299/299 [==============================] - 44s 141ms/step - loss: 0.4598 - accuracy: 0.8844\n",
      "\n",
      "For Temperature = 10 & alpha= 0.5 & lr=0.01\n",
      "299/299 [==============================] - 44s 142ms/step - loss: 0.9239 - accuracy: 0.7580\n",
      "\n",
      "For Temperature = 10 & alpha= 0.5 & lr=0.0001\n",
      "299/299 [==============================] - 43s 140ms/step - loss: 1.1137 - accuracy: 0.7404\n",
      "\n",
      "Best Temperature: 5\n",
      "Best Alpha: 0.5\n",
      "Best Learning Rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "#Select the model with highest validation accuracy\n",
    "def ChooseBest():\n",
    "    best_model = 0\n",
    "    best_temp = 0\n",
    "    best_alpha = 0\n",
    "    best_lr = 0\n",
    "    max_val_acc = 0\n",
    "\n",
    "    for a in ALPHA:\n",
    "        for t in TEMPERATURE:\n",
    "          for l in LEARNING_RATE:\n",
    "              print(\"\\nFor Temperature = {0} & alpha= {1} & lr={2}\".format(t,a,l))\n",
    "              #load trained model with temp t and alpha a\n",
    "              model_path = HPO_PATH + '/HPO(t={0},a={1},l={2})'.format(t,a,l)\n",
    "              student_model = load_m(model_path, MODEL_NAME)\n",
    "              student_model.compile(metrics=['accuracy'], loss=CategoricalCrossentropy(from_logits=True))\n",
    "              #validate model\n",
    "              val_acc = student_model.evaluate(validation_generator)[1]\n",
    "\n",
    "              #update best parameters\n",
    "              if val_acc > max_val_acc:\n",
    "                  max_val_acc = val_acc\n",
    "                  best_model = student_model\n",
    "                  best_alpha = a\n",
    "                  best_temp = t\n",
    "                  best_lr = l\n",
    "                \n",
    "    return best_alpha, best_temp, best_lr, best_model\n",
    "\n",
    "best_alpha, best_temp, best_lr, best_model = ChooseBest()\n",
    "\n",
    "print('\\nBest Temperature:', best_temp)\n",
    "print('Best Alpha:', best_alpha)\n",
    "print('Best Learning Rate:', best_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iifTjvy9SjhZ",
   "metadata": {
    "id": "iifTjvy9SjhZ"
   },
   "source": [
    "**Evaluating best student model on Validation and Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "XJE1qQMzDrMu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XJE1qQMzDrMu",
    "outputId": "18b53dad-3d4c-45a2-c1d5-22794fb6f0da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD TEST SAMPLES...\n",
      "Found 796 images belonging to 199 classes.\n"
     ]
    }
   ],
   "source": [
    "#LOAD TEST DATA\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=student_preprocess)\n",
    "\n",
    "if not os.path.exists(TEST_DATA_DIR):\n",
    "    print(\"TEST DATA DOES NOT EXITS!\")\n",
    "else:\n",
    "    print(\"LOAD TEST SAMPLES...\")\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "                TEST_DATA_DIR,\n",
    "                target_size=(img_rows,img_cols),\n",
    "                batch_size=BATCH_SIZE,\n",
    "                class_mode='categorical',\n",
    "                seed=42,\n",
    "                shuffle=False)\n",
    "\n",
    "    #CHECK  THE NUMBER OF SAMPLES\n",
    "    nb_test_samples = len(test_generator.filenames)\n",
    "    if nb_test_samples == 0:\n",
    "        print(\"NO DATA TEST FOUND IN TEST FOLDER!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7boQFDTBZUed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7boQFDTBZUed",
    "outputId": "dd8da43a-4712-4f8a-8b70-3b7a61aa7196"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Best Student on validation dataset\n",
      "299/299 [==============================] - 43s 138ms/step - loss: 0.3358 - accuracy: 0.9079\n",
      "\n",
      "Evaluating Best Student on test dataset\n",
      "199/199 [==============================] - 426s 2s/step - loss: 0.3420 - accuracy: 0.9095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34196093678474426, 0.909547746181488]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate Best Student model against Teacher model on test set\n",
    "print(\"Evaluating Best Student on validation dataset\")\n",
    "best_model.evaluate(validation_generator)\n",
    "\n",
    "print(\"\\nEvaluating Best Student on test dataset\")\n",
    "best_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EIx2PO6s9fcg",
   "metadata": {
    "id": "EIx2PO6s9fcg"
   },
   "source": [
    "**Saving Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "vZMCJpbMj-Td",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vZMCJpbMj-Td",
    "outputId": "a8ffcf3e-4358-4925-866f-09cf121af46a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] BEST STUDENT MODEL AND HISTORY SAVED\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "des = PROPOSED_MODEL_PATH + '-KD'\n",
    "\n",
    "#save models\n",
    "shutil.copytree(HPO_PATH + '/HPO(t={0},a={1},l={2})'.format(best_temp,best_alpha,best_lr), des)\n",
    "\n",
    "print(\"[INFO] BEST STUDENT MODEL AND HISTORY SAVED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "AVOoUtenVOJv",
   "metadata": {
    "id": "AVOoUtenVOJv"
   },
   "outputs": [],
   "source": [
    "#Figure\n",
    "dpi = 1000\n",
    "plt.rcParams.update({'figure.dpi': dpi})\n",
    "figsize = (12, 12)\n",
    "\n",
    "history = load_h(PROPOSED_MODEL_PATH + '-KD', MODEL_NAME)\n",
    "\n",
    "#Markers\n",
    "marker_train_accuracy = 's'\n",
    "marker_validation_accuracy = 'x'\n",
    "marker_train_loss = 'o'\n",
    "marker_validation_loss = '|'\n",
    "marker_fillstyle_train = 'none'\n",
    "marker_fillstyle_validation = 'none'\n",
    "marker_plot_markersize = 25\n",
    "marker_plot_markerwidth = 3\n",
    "\n",
    "#Lines\n",
    "line_style_train = '-' \n",
    "line_style_validation = '--'\n",
    "line_width_train = '5'\n",
    "line_width_val = line_width_train\n",
    "line_color_train_accuracy = 'black'\n",
    "line_color_val_accuracy = 'black'\n",
    "line_color_train_loss = 'black'\n",
    "line_color_val_loss = 'black'\n",
    "\n",
    "#Labels\n",
    "train_accuracy_label = 'Train ' + 'Acc'\n",
    "validation_accuracy_label = 'Val ' + 'Acc'\n",
    "train_loss_label = 'Train ' + 'Loss'\n",
    "validation_loss_label = 'Val ' 'Loss'\n",
    "x_label_font_size = 56\n",
    "y_label_font_size = x_label_font_size\n",
    "x_label_font = 'Tahoma'\n",
    "y_label_font = x_label_font\n",
    "# x_label_fontweight = 'bold'\n",
    "# y_label_fontweight = x_label_fontweight\n",
    "\n",
    "#Ticks\n",
    "spine_axis_thickness = 4\n",
    "tick_font_size = 42\n",
    "tick_length = 12\n",
    "tick_width = spine_axis_thickness\n",
    "\n",
    "#Legend\n",
    "legend_border_pad = 0.35\n",
    "legend_line_width = 5\n",
    "legend_font_size = 50\n",
    "legend_edge_color = 'black'\n",
    "legend_label_spacing = 0.5\n",
    "legend_location = 'best'\n",
    "legend_ncol = 1\n",
    "legend_font = 'Tahoma'\n",
    "legend_has_frame = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3NGN9xplbXf4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3NGN9xplbXf4",
    "outputId": "4918584b-dcd4-4f81-966c-6423e67b06c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 7200x7200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Accuracy and Loss Graph\n",
    "epochs = EPOCHS\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plt.figure(figsize = figsize, \n",
    "           dpi = 600, \n",
    "           edgecolor = 'black', \n",
    "           facecolor = 'white', \n",
    "           linewidth = 0)\n",
    "plt.tight_layout()\n",
    "plt.rc('xtick', labelsize = tick_font_size, direction=\"in\") \n",
    "plt.rc('ytick', labelsize = tick_font_size, direction=\"in\") \n",
    "\n",
    "fig, ax = plt.subplots(figsize = figsize)\n",
    "plt.gcf().subplots_adjust(bottom = 0.15)\n",
    "plt.setp(ax.spines.values(), linewidth = spine_axis_thickness)\n",
    "\n",
    "plt.tick_params(length = tick_length, \n",
    "                width = tick_width, \n",
    "                right = True, \n",
    "                top = True)\n",
    "\n",
    "plt.plot(np.arange(1, epochs + 1), \n",
    "         history[\"accuracy\"], \n",
    "         mew = marker_plot_markerwidth, \n",
    "         color = line_color_train_accuracy, \n",
    "         lw = line_width_train, \n",
    "         marker = marker_train_accuracy, \n",
    "         markersize = marker_plot_markersize, \n",
    "         fillstyle = marker_fillstyle_train, \n",
    "         ls = line_style_train, \n",
    "         label = train_accuracy_label)\n",
    "\n",
    "plt.plot(np.arange(1, epochs + 1), \n",
    "         history[\"val_accuracy\"], \n",
    "         mew = marker_plot_markerwidth, \n",
    "         color = line_color_val_accuracy, \n",
    "         lw = line_width_val, \n",
    "         marker = marker_validation_accuracy, \n",
    "         markersize = marker_plot_markersize, \n",
    "         fillstyle = marker_fillstyle_validation, \n",
    "         ls = line_style_validation,  \n",
    "         label = validation_accuracy_label)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_fig(FIG_PATH, MODEL_NAME + '-AccuracyGraph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "yDNtFoRAIfPt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yDNtFoRAIfPt",
    "outputId": "dc22aacb-4abd-404d-fcfe-e986fdd21aa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 7200x7200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Accuracy and Loss Graph\n",
    "epochs = EPOCHS\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "plt.figure(figsize = figsize, \n",
    "           dpi = 600, \n",
    "           edgecolor = 'black', \n",
    "           facecolor = 'white', \n",
    "           linewidth = 0)\n",
    "plt.tight_layout()\n",
    "plt.rc('xtick', labelsize = tick_font_size, direction=\"in\") \n",
    "plt.rc('ytick', labelsize = tick_font_size, direction=\"in\") \n",
    "\n",
    "fig, ax = plt.subplots(figsize = figsize)\n",
    "plt.gcf().subplots_adjust(bottom = 0.15)\n",
    "plt.setp(ax.spines.values(), linewidth = spine_axis_thickness)\n",
    "\n",
    "plt.tick_params(length = tick_length, \n",
    "                width = tick_width, \n",
    "                right = True, \n",
    "                top = True)\n",
    "\n",
    "plt.plot(np.arange(1, epochs + 1), \n",
    "         history[\"loss\"], \n",
    "         mew = marker_plot_markerwidth, \n",
    "         color = line_color_train_loss, \n",
    "         lw = line_width_train, \n",
    "         marker = marker_train_loss, \n",
    "         markersize = marker_plot_markersize, \n",
    "         fillstyle = marker_fillstyle_train, \n",
    "         ls = line_style_train, label = train_loss_label)\n",
    "\n",
    "plt.plot(np.arange(1, epochs + 1), \n",
    "         history[\"val_student_loss\"], \n",
    "         mew = marker_plot_markerwidth, \n",
    "         color = line_color_val_loss, \n",
    "         lw = line_width_val, \n",
    "         marker = marker_validation_loss, \n",
    "         markersize = marker_plot_markersize, \n",
    "         fillstyle = marker_fillstyle_validation, \n",
    "         ls = line_style_validation,  \n",
    "         label = validation_loss_label)\n",
    "\n",
    "plt.xlabel(\"Epochs\", fontfamily = x_label_font, fontsize = x_label_font_size, color ='black')\n",
    "plt.ylabel(\"Accuracy/Loss\", fontfamily = y_label_font, fontsize = y_label_font_size, color = 'black')\n",
    "\n",
    "legend = plt.legend(loc = legend_location, \n",
    "                    ncol = legend_ncol, \n",
    "                    frameon = legend_has_frame, \n",
    "                    fontsize=legend_font_size, \n",
    "                    edgecolor=legend_edge_color, \n",
    "                    borderpad=legend_border_pad, \n",
    "                    labelspacing=legend_label_spacing)\n",
    "\n",
    "frame = legend.get_frame()\n",
    "legend.get_frame().set_linewidth(legend_line_width)\n",
    "legend.get_frame().set_edgecolor(legend_edge_color)\n",
    "plt.setp(legend.texts, family = legend_font)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_fig(FIG_PATH, MODEL_NAME + '-LossGraph')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Distiller_MiniMobileNetV2_cb.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
